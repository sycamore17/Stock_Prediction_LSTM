{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0842c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tushare as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb0a8e",
   "metadata": {},
   "source": [
    "# 沪深300指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77f42bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n",
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n",
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n",
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n",
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>code</th>\n",
       "      <th>Log_Return_ShangZheng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>3725.86</td>\n",
       "      <td>3470.41</td>\n",
       "      <td>3726.24</td>\n",
       "      <td>3469.01</td>\n",
       "      <td>115370674.0</td>\n",
       "      <td>hs300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>3382.18</td>\n",
       "      <td>3478.78</td>\n",
       "      <td>3518.22</td>\n",
       "      <td>3377.28</td>\n",
       "      <td>162116984.0</td>\n",
       "      <td>hs300</td>\n",
       "      <td>0.002409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>3482.41</td>\n",
       "      <td>3539.81</td>\n",
       "      <td>3543.74</td>\n",
       "      <td>3468.47</td>\n",
       "      <td>145966144.0</td>\n",
       "      <td>hs300</td>\n",
       "      <td>0.017391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>3481.15</td>\n",
       "      <td>3294.38</td>\n",
       "      <td>3481.15</td>\n",
       "      <td>3284.74</td>\n",
       "      <td>44102641.0</td>\n",
       "      <td>hs300</td>\n",
       "      <td>-0.071855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>3371.87</td>\n",
       "      <td>3361.56</td>\n",
       "      <td>3418.85</td>\n",
       "      <td>3237.93</td>\n",
       "      <td>185959451.0</td>\n",
       "      <td>hs300</td>\n",
       "      <td>0.020187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open    close     high      low       volume   code  \\\n",
       "0  2016-01-04  3725.86  3470.41  3726.24  3469.01  115370674.0  hs300   \n",
       "1  2016-01-05  3382.18  3478.78  3518.22  3377.28  162116984.0  hs300   \n",
       "2  2016-01-06  3482.41  3539.81  3543.74  3468.47  145966144.0  hs300   \n",
       "3  2016-01-07  3481.15  3294.38  3481.15  3284.74   44102641.0  hs300   \n",
       "4  2016-01-08  3371.87  3361.56  3418.85  3237.93  185959451.0  hs300   \n",
       "\n",
       "   Log_Return_ShangZheng  \n",
       "0                    NaN  \n",
       "1               0.002409  \n",
       "2               0.017391  \n",
       "3              -0.071855  \n",
       "4               0.020187  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HS = ts.get_k_data('hs300',start = '2016-01-04',end='2024-04-29')\n",
    "HS['Log_Return_ShangZheng'] = np.log(HS['close'] /HS['close'].shift(1))\n",
    "HS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a3ab6",
   "metadata": {},
   "source": [
    "# 茅台数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1fc57",
   "metadata": {},
   "source": [
    "选用技术特征的原因：由于我们要预测的是股票的收益率，而收益率有正有负，分别表示股票上涨和下跌；股票的技术指标能够很好的捕捉股票的涨跌趋势，因此对于预测股票收益率可以预见能够产生帮助"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9928fbf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n",
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n",
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n",
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n",
      "d:\\anaconda\\envs\\py3-9\\lib\\site-packages\\tushare\\stock\\trading.py:706: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(_get_k_data(url, dataflag,\n"
     ]
    }
   ],
   "source": [
    "import tushare as ts\n",
    "df = ts.get_k_data('600519',start = '2016-01-04',end='2024-04-29')\n",
    "df.to_csv('stock_daily/600519.csv')\n",
    "data = pd.read_csv('stock_daily/600519.csv')\n",
    "del(data['Unnamed: 0'])\n",
    "del(data['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf8be90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>54.584</td>\n",
       "      <td>46.604</td>\n",
       "      <td>54.584</td>\n",
       "      <td>46.574</td>\n",
       "      <td>17349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>46.584</td>\n",
       "      <td>49.404</td>\n",
       "      <td>50.554</td>\n",
       "      <td>44.094</td>\n",
       "      <td>31908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>49.364</td>\n",
       "      <td>48.764</td>\n",
       "      <td>50.244</td>\n",
       "      <td>45.884</td>\n",
       "      <td>23760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>45.574</td>\n",
       "      <td>38.814</td>\n",
       "      <td>45.574</td>\n",
       "      <td>36.614</td>\n",
       "      <td>8148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>40.754</td>\n",
       "      <td>41.214</td>\n",
       "      <td>44.584</td>\n",
       "      <td>36.584</td>\n",
       "      <td>44510.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open   Close    High     Low   Volume\n",
       "0  2016-01-04  54.584  46.604  54.584  46.574  17349.0\n",
       "1  2016-01-05  46.584  49.404  50.554  44.094  31908.0\n",
       "2  2016-01-06  49.364  48.764  50.244  45.884  23760.0\n",
       "3  2016-01-07  45.574  38.814  45.574  36.614   8148.0\n",
       "4  2016-01-08  40.754  41.214  44.584  36.584  44510.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['Date', 'Open', 'Close', 'High', 'Low', 'Volume']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "125d25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 计算移动平均线和指数移动平均线\n",
    "df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "# 计算MACD\n",
    "df['MACD_Line'] = df['EMA12'] - df['EMA26']\n",
    "df['Signal_Line'] = df['MACD_Line'].ewm(span=9, adjust=False).mean()\n",
    "df['MACD_Histogram'] = df['MACD_Line'] - df['Signal_Line']\n",
    "\n",
    "# 计算RSI\n",
    "delta = df['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "avg_gain = gain.rolling(window=14).mean()\n",
    "avg_loss = loss.rolling(window=14).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# 计算Stochastic\n",
    "low_min = df['Low'].rolling(window=14).min()\n",
    "high_max = df['High'].rolling(window=14).max()\n",
    "df['Stochastic'] = 100 * ((df['Close'] - low_min) / (high_max - low_min))\n",
    "\n",
    "# 计算OBV\n",
    "df['OBV'] = 0\n",
    "df.loc[df['Close'] > df['Close'].shift(1), 'OBV'] = df['Volume']\n",
    "df.loc[df['Close'] < df['Close'].shift(1), 'OBV'] = -df['Volume']\n",
    "df['OBV'] = df['OBV'].cumsum()\n",
    "\n",
    "# 计算Williams %R\n",
    "lookback_period = 14\n",
    "df['High_14'] = df['High'].rolling(window=lookback_period).max()\n",
    "df['Low_14'] = df['Low'].rolling(window=lookback_period).min()\n",
    "df['Williams_%R'] = -100 * ((df['High_14'] - df['Close']) / (df['High_14'] - df['Low_14']))\n",
    "del df['High_14']\n",
    "del df['Low_14']\n",
    "\n",
    "# 沪深300对数收益率\n",
    "df['Log_Return_ShangZheng'] = np.log(HS['close'].shift(1) /HS['close'].shift(2))\n",
    "'''\n",
    "# 茅台前1天的对数收益率\n",
    "df['Log_Return_Lag1'] = np.log(df['Close'].shift(1) / df['Close'].shift(2))\n",
    "\n",
    "# 茅台前2天的对数收益率\n",
    "df['Log_Return_Lag2'] = np.log(df['Close'].shift(1) / df['Close'].shift(3))\n",
    "\n",
    "# 茅台前3天的对数收益率\n",
    "df['Log_Return_Lag3'] = np.log(df['Close'].shift(1) / df['Close'].shift(4))\n",
    "\n",
    "# 茅台前4天的对数收益率\n",
    "df['Log_Return_Lag4'] = np.log(df['Close'].shift(1) / df['Close'].shift(5))\n",
    "\n",
    "# 茅台前5天的对数收益率\n",
    "df['Log_Return_Lag5'] = np.log(df['Close'].shift(1) / df['Close'].shift(6))\n",
    "\n",
    "# 茅台前6天的对数收益率\n",
    "df['Log_Return_Lag6'] = np.log(df['Close'].shift(1) / df['Close'].shift(7))\n",
    "\n",
    "# 茅台前7天的对数收益率\n",
    "df['Log_Return_Lag7'] = np.log(df['Close'].shift(1) / df['Close'].shift(8))\n",
    "\n",
    "# 茅台前14天的对数收益率\n",
    "df['Log_Return_Lag14'] = np.log(df['Close'].shift(1) / df['Close'].shift(14))\n",
    "'''\n",
    "# 计算对数收益率(茅台)\n",
    "df['Log_Return'] = np.log(df['Open'] / df['Open'].shift(1))\n",
    "\n",
    "del df[\"Date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa9a25c",
   "metadata": {},
   "source": [
    "# 预测的目标是Log_Return，每一行就是一个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df5d147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'Close', 'High', 'Low', 'Volume', 'MA10', 'EMA12', 'EMA26',\n",
       "       'MACD_Line', 'Signal_Line', 'MACD_Histogram', 'RSI', 'Stochastic',\n",
       "       'OBV', 'Williams_%R', 'Log_Return_ShangZheng', 'Log_Return'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70bd7f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MA10</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA26</th>\n",
       "      <th>MACD_Line</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>MACD_Histogram</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Stochastic</th>\n",
       "      <th>OBV</th>\n",
       "      <th>Williams_%R</th>\n",
       "      <th>Log_Return_ShangZheng</th>\n",
       "      <th>Log_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>37.844</td>\n",
       "      <td>36.844</td>\n",
       "      <td>41.174</td>\n",
       "      <td>36.484</td>\n",
       "      <td>21832.0</td>\n",
       "      <td>38.297</td>\n",
       "      <td>40.001201</td>\n",
       "      <td>42.109576</td>\n",
       "      <td>-2.108375</td>\n",
       "      <td>-1.892538</td>\n",
       "      <td>-0.215837</td>\n",
       "      <td>41.686542</td>\n",
       "      <td>21.120498</td>\n",
       "      <td>35498</td>\n",
       "      <td>-78.879502</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>-0.141218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39.694</td>\n",
       "      <td>39.324</td>\n",
       "      <td>39.984</td>\n",
       "      <td>35.394</td>\n",
       "      <td>22733.0</td>\n",
       "      <td>38.108</td>\n",
       "      <td>39.897017</td>\n",
       "      <td>41.903237</td>\n",
       "      <td>-2.006221</td>\n",
       "      <td>-1.915274</td>\n",
       "      <td>-0.090946</td>\n",
       "      <td>44.050343</td>\n",
       "      <td>39.165764</td>\n",
       "      <td>58231</td>\n",
       "      <td>-60.834236</td>\n",
       "      <td>-0.029745</td>\n",
       "      <td>0.047728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>39.584</td>\n",
       "      <td>39.354</td>\n",
       "      <td>40.074</td>\n",
       "      <td>38.084</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>38.399</td>\n",
       "      <td>39.813476</td>\n",
       "      <td>41.714405</td>\n",
       "      <td>-1.900929</td>\n",
       "      <td>-1.912405</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>41.397021</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>71981</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>-0.002775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37.574</td>\n",
       "      <td>35.594</td>\n",
       "      <td>41.054</td>\n",
       "      <td>35.084</td>\n",
       "      <td>22280.0</td>\n",
       "      <td>38.621</td>\n",
       "      <td>39.164325</td>\n",
       "      <td>41.261042</td>\n",
       "      <td>-2.096716</td>\n",
       "      <td>-1.949267</td>\n",
       "      <td>-0.147449</td>\n",
       "      <td>39.297903</td>\n",
       "      <td>23.616734</td>\n",
       "      <td>49701</td>\n",
       "      <td>-76.383266</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>-0.052113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.564</td>\n",
       "      <td>36.514</td>\n",
       "      <td>37.474</td>\n",
       "      <td>32.284</td>\n",
       "      <td>29840.0</td>\n",
       "      <td>38.636</td>\n",
       "      <td>38.756583</td>\n",
       "      <td>40.909409</td>\n",
       "      <td>-2.152826</td>\n",
       "      <td>-1.989979</td>\n",
       "      <td>-0.162847</td>\n",
       "      <td>47.809524</td>\n",
       "      <td>29.824561</td>\n",
       "      <td>79541</td>\n",
       "      <td>-70.175439</td>\n",
       "      <td>-0.062095</td>\n",
       "      <td>-0.027248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open   Close    High     Low   Volume    MA10      EMA12      EMA26  \\\n",
       "13  37.844  36.844  41.174  36.484  21832.0  38.297  40.001201  42.109576   \n",
       "14  39.694  39.324  39.984  35.394  22733.0  38.108  39.897017  41.903237   \n",
       "15  39.584  39.354  40.074  38.084  13750.0  38.399  39.813476  41.714405   \n",
       "16  37.574  35.594  41.054  35.084  22280.0  38.621  39.164325  41.261042   \n",
       "17  36.564  36.514  37.474  32.284  29840.0  38.636  38.756583  40.909409   \n",
       "\n",
       "    MACD_Line  Signal_Line  MACD_Histogram        RSI  Stochastic    OBV  \\\n",
       "13  -2.108375    -1.892538       -0.215837  41.686542   21.120498  35498   \n",
       "14  -2.006221    -1.915274       -0.090946  44.050343   39.165764  58231   \n",
       "15  -1.900929    -1.912405        0.011476  41.397021   40.000000  71981   \n",
       "16  -2.096716    -1.949267       -0.147449  39.297903   23.616734  49701   \n",
       "17  -2.152826    -1.989979       -0.162847  47.809524   29.824561  79541   \n",
       "\n",
       "    Williams_%R  Log_Return_ShangZheng  Log_Return  \n",
       "13   -78.879502              -0.015237   -0.141218  \n",
       "14   -60.834236              -0.029745    0.047728  \n",
       "15   -60.000000               0.010367   -0.002775  \n",
       "16   -76.383266               0.004944   -0.052113  \n",
       "17   -70.175439              -0.062095   -0.027248  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c277299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "# 计算各个切分点\n",
    "train_size = int(len(df) * 0.8)\n",
    "test_size = len(df) - train_size   # 确保全部数据被合理分配\n",
    "\n",
    "train_data = df[:train_size]\n",
    "train_data.to_csv('./stock_daily/stock_train.csv',header = False, index=False)\n",
    "train_data = pd.read_csv('./stock_daily/stock_train.csv')\n",
    "\n",
    "test_data = df[train_size:]\n",
    "test_data.to_csv('./stock_daily/stock_test.csv',header = False, index=False)\n",
    "test_data = pd.read_csv('./stock_daily/stock_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d10bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8018593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_WEIGHT=0.9\n",
    "SEQ_LEN=59\n",
    "LEARNING_RATE=0.00001\n",
    "BATCH_SIZE=32\n",
    "\n",
    "mean_list=[]\n",
    "std_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "085466b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#完成数据集类\n",
    "class Stock_Data(Dataset):\n",
    "    def __init__(self,train=True,transform=None):        \n",
    "        if train==True:\n",
    "            train_path=\"stock_daily/stock_train.csv\"\n",
    "            with open(train_path) as f:\n",
    "                self.data = np.loadtxt(f,delimiter = \",\")\n",
    "                num_cols = self.data.shape[1]\n",
    "                #可以注释\n",
    "                #addi=np.zeros((self.data.shape[0],1))\n",
    "                #self.data=np.concatenate((self.data,addi),axis=1)\n",
    "                self.data=self.data[:,0:num_cols]\n",
    "                \n",
    "            # 对每一个特征进行归一化，类似BatchNorm\n",
    "            # 不对target进行归一化，方便后面和ARMA得到的结果进行对比\n",
    "            for i in range(len(self.data[0])-1):\n",
    "                mean_list.append(np.mean(self.data[:,i]))\n",
    "                std_list.append(np.std(self.data[:,i]))\n",
    "                self.data[:,i]=(self.data[:,i]-np.mean(self.data[:,i]))/(np.std(self.data[:,i])+1e-8)\n",
    "            self.value=torch.rand(self.data.shape[0]-SEQ_LEN, SEQ_LEN, self.data.shape[1])\n",
    "            self.label=torch.rand(self.data.shape[0]-SEQ_LEN,1)\n",
    "            for i in range(self.data.shape[0]-SEQ_LEN):                  \n",
    "                self.value[i,:,:]=torch.from_numpy(self.data[i:i+SEQ_LEN,:].reshape(SEQ_LEN,self.data.shape[1]))    \n",
    "                self.label[i,:]=self.data[i+SEQ_LEN,-1]\n",
    "            self.data=self.value\n",
    "        else:\n",
    "            test_path=\"stock_daily/stock_test.csv\"\n",
    "            with open(test_path) as f:\n",
    "                self.data = np.loadtxt(f,delimiter = \",\")\n",
    "                #addi=np.zeros((self.data.shape[0],1))\n",
    "                #self.data=np.concatenate((self.data,addi),axis=1)\n",
    "                num_cols = self.data.shape[1]\n",
    "                self.data=self.data[:,0:num_cols]\n",
    "            for i in range(len(self.data[0])-1):\n",
    "                self.data[:,i]=(self.data[:,i]-mean_list[i])/(std_list[i]+1e-8)\n",
    "            self.value=torch.rand(self.data.shape[0]-SEQ_LEN,SEQ_LEN,self.data.shape[1])\n",
    "            self.label=torch.rand(self.data.shape[0]-SEQ_LEN,1)\n",
    "            for i in range(self.data.shape[0]-SEQ_LEN):                  \n",
    "                self.value[i,:,:]=torch.from_numpy(self.data[i:i+SEQ_LEN,:].reshape(SEQ_LEN,self.data.shape[1]))    \n",
    "                self.label[i,:]=self.data[i+SEQ_LEN,-1]\n",
    "            self.data=self.value\n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index],self.label[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c6860fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_train=Stock_Data(train=True)\n",
    "stock_test=Stock_Data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45f9900c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.3681e+00, -1.3712e+00, -1.3663e+00,  ..., -1.3118e+00,\n",
       "          -1.2659e+00, -1.4122e-01],\n",
       "         [-1.3653e+00, -1.3675e+00, -1.3681e+00,  ..., -6.7867e-01,\n",
       "          -2.4593e+00,  4.7728e-02],\n",
       "         [-1.3654e+00, -1.3674e+00, -1.3680e+00,  ..., -6.4940e-01,\n",
       "           8.4040e-01, -2.7750e-03],\n",
       "         ...,\n",
       "         [-1.3049e+00, -1.3052e+00, -1.3042e+00,  ..., -1.4863e+00,\n",
       "          -1.0337e-01,  2.0176e-03],\n",
       "         [-1.3022e+00, -1.3060e+00, -1.3055e+00,  ..., -1.5920e+00,\n",
       "          -1.1200e+00,  2.2298e-02],\n",
       "         [-1.3043e+00, -1.3132e+00, -1.3066e+00,  ..., -1.6279e+00,\n",
       "           2.3819e-01, -1.7397e-02]]),\n",
       " tensor([-0.0343]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "236ac309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.3653, -1.3675, -1.3681,  ..., -0.6787, -2.4593,  0.0477],\n",
       "         [-1.3654, -1.3674, -1.3680,  ..., -0.6494,  0.8404, -0.0028],\n",
       "         [-1.3685, -1.3731, -1.3665,  ..., -1.2242,  0.3943, -0.0521],\n",
       "         ...,\n",
       "         [-1.3022, -1.3060, -1.3055,  ..., -1.5920, -1.1200,  0.0223],\n",
       "         [-1.3043, -1.3132, -1.3066,  ..., -1.6279,  0.2382, -0.0174],\n",
       "         [-1.3084, -1.3103, -1.3098,  ..., -1.3173, -1.4803, -0.0343]]),\n",
       " tensor([0.0065]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_train.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25f29efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1548, 59, 17])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18cb2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,dimension):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.lstm=nn.LSTM(input_size=dimension,hidden_size=128,num_layers=3,batch_first=True)\n",
    "        self.linear1=nn.Linear(in_features=128,out_features=16)\n",
    "        self.linear2=nn.Linear(16,1)\n",
    "    def forward(self,x):\n",
    "        out,_=self.lstm(x)\n",
    "        x=out[:,-1,:]        \n",
    "        x=self.linear1(x)\n",
    "        x=self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a66b0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x维度实例化模型\n",
    "model=LSTM(dimension=17)\n",
    "model=model.to(device)\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "31732c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):    \n",
    "    model.train()\n",
    "    global loss_list\n",
    "    global iteration\n",
    "    dataloader=DataLoader(dataset=stock_train,batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
    "    for i,(data,label) in enumerate(dataloader):\n",
    "        iteration=iteration+1\n",
    "        data,label = data.to(device),label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(data)\n",
    "        loss=criterion(output,label)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        if i%20==0:\n",
    "            loss_list.append(loss.item())\n",
    "            print(\"epoch=\",epoch,\"iteration=\",iteration,\"loss=\",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c257673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    global accuracy_list\n",
    "    global predict_list\n",
    "    dataloader=DataLoader(dataset=stock_test,batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
    "    for i,(data,label) in enumerate(dataloader):\n",
    "        with torch.no_grad():            \n",
    "            data,label=data.to(device),label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predict=model.forward(data)\n",
    "            predict_list.append(predict)\n",
    "            loss=criterion(predict,label)\n",
    "            accuracy_fn=nn.MSELoss()\n",
    "            accuracy=accuracy_fn(predict,label)\n",
    "            accuracy_list.append(accuracy.item())\n",
    "    print(\"test_data MSELoss:(pred-real)/real=\",np.mean(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4f34ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_curve(loss_list):\n",
    "    x=np.linspace(1,len(loss_list),len(loss_list))\n",
    "    x=20*x\n",
    "    plt.plot(x,np.array(loss_list),label=\"train_loss\")\n",
    "    plt.ylabel(\"MSELoss\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.savefig(\"train_loss.png\",dpi=3000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3e6dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_lines(predict_list):\n",
    "    real_list = []\n",
    "    prediction_list = []\n",
    "    dataloader = DataLoader(dataset=stock_test, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "    \n",
    "    for i, (data, label) in enumerate(dataloader):\n",
    "        for idx in range(BATCH_SIZE):\n",
    "            real_list.append(label[idx].numpy())\n",
    "    \n",
    "    for item in predict_list:\n",
    "        item = item.to(\"cpu\")\n",
    "        for idx in range(BATCH_SIZE):\n",
    "            prediction_list.append(item[idx].numpy())\n",
    "\n",
    "    x = np.linspace(1, len(real_list), len(real_list))\n",
    "    plt.plot(x, np.array(real_list), label=\"real\")\n",
    "    plt.plot(x, np.array(prediction_list), label=\"prediction\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"_Pre.png\", dpi=3000)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e31bbd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 iteration= 1 loss= 0.02113965153694153\n",
      "epoch= 0 iteration= 21 loss= 0.015373941510915756\n",
      "epoch= 0 iteration= 41 loss= 0.013057139702141285\n",
      "test_data MSELoss:(pred-real)/real= 0.011569725535809993\n",
      "epoch= 1 iteration= 49 loss= 0.016048520803451538\n",
      "epoch= 1 iteration= 69 loss= 0.011373456567525864\n",
      "epoch= 1 iteration= 89 loss= 0.009407861158251762\n",
      "test_data MSELoss:(pred-real)/real= 0.008065866911783815\n",
      "epoch= 2 iteration= 97 loss= 0.012201040983200073\n",
      "epoch= 2 iteration= 117 loss= 0.008114608004689217\n",
      "epoch= 2 iteration= 137 loss= 0.006519700400531292\n",
      "test_data MSELoss:(pred-real)/real= 0.005277191521599889\n",
      "epoch= 3 iteration= 145 loss= 0.00901227816939354\n",
      "epoch= 3 iteration= 165 loss= 0.005489971023052931\n",
      "epoch= 3 iteration= 185 loss= 0.004299866035580635\n",
      "test_data MSELoss:(pred-real)/real= 0.003147901641204953\n",
      "epoch= 4 iteration= 193 loss= 0.006461625453084707\n",
      "epoch= 4 iteration= 213 loss= 0.003490170929580927\n",
      "epoch= 4 iteration= 233 loss= 0.002727250102907419\n",
      "test_data MSELoss:(pred-real)/real= 0.001669166749343276\n",
      "epoch= 5 iteration= 241 loss= 0.004566771909594536\n",
      "epoch= 5 iteration= 261 loss= 0.0021190077532082796\n",
      "epoch= 5 iteration= 281 loss= 0.001766906469129026\n",
      "test_data MSELoss:(pred-real)/real= 0.0007988928351551295\n",
      "epoch= 6 iteration= 289 loss= 0.003327449318021536\n",
      "epoch= 6 iteration= 309 loss= 0.001324877724982798\n",
      "epoch= 6 iteration= 329 loss= 0.0013080236967653036\n",
      "test_data MSELoss:(pred-real)/real= 0.000402996783668641\n",
      "epoch= 7 iteration= 337 loss= 0.002654626965522766\n",
      "epoch= 7 iteration= 357 loss= 0.0009601247147656977\n",
      "epoch= 7 iteration= 377 loss= 0.0011579478159546852\n",
      "test_data MSELoss:(pred-real)/real= 0.0002761188094154932\n",
      "epoch= 8 iteration= 385 loss= 0.0023616491816937923\n",
      "epoch= 8 iteration= 405 loss= 0.0008297745371237397\n",
      "epoch= 8 iteration= 425 loss= 0.0011320756748318672\n",
      "test_data MSELoss:(pred-real)/real= 0.00024910454521887004\n",
      "epoch= 9 iteration= 433 loss= 0.0022551575675606728\n",
      "epoch= 9 iteration= 453 loss= 0.0007905228994786739\n",
      "epoch= 9 iteration= 473 loss= 0.0011340717319399118\n",
      "test_data MSELoss:(pred-real)/real= 0.0002448162209475413\n",
      "epoch= 10 iteration= 481 loss= 0.0022181393578648567\n",
      "epoch= 10 iteration= 501 loss= 0.0007786572095938027\n",
      "epoch= 10 iteration= 521 loss= 0.0011372687295079231\n",
      "test_data MSELoss:(pred-real)/real= 0.0002436185081023723\n",
      "epoch= 11 iteration= 529 loss= 0.002203800017014146\n",
      "epoch= 11 iteration= 549 loss= 0.0007744054892100394\n",
      "epoch= 11 iteration= 569 loss= 0.0011389920255169272\n",
      "test_data MSELoss:(pred-real)/real= 0.00024275022151414304\n",
      "epoch= 12 iteration= 577 loss= 0.002196884946897626\n",
      "epoch= 12 iteration= 597 loss= 0.0007723844610154629\n",
      "epoch= 12 iteration= 617 loss= 0.001140254782512784\n",
      "test_data MSELoss:(pred-real)/real= 0.00024200196203310042\n",
      "epoch= 13 iteration= 625 loss= 0.002192586660385132\n",
      "epoch= 13 iteration= 645 loss= 0.0007711444632150233\n",
      "epoch= 13 iteration= 665 loss= 0.0011414809850975871\n",
      "test_data MSELoss:(pred-real)/real= 0.00024136665306286886\n",
      "epoch= 14 iteration= 673 loss= 0.0021895624231547117\n",
      "epoch= 14 iteration= 693 loss= 0.0007702203001827002\n",
      "epoch= 14 iteration= 713 loss= 0.0011428615543991327\n",
      "test_data MSELoss:(pred-real)/real= 0.0002408463362371549\n",
      "epoch= 15 iteration= 721 loss= 0.002187221311032772\n",
      "epoch= 15 iteration= 741 loss= 0.0007695111562497914\n",
      "epoch= 15 iteration= 761 loss= 0.001144355395808816\n",
      "test_data MSELoss:(pred-real)/real= 0.00024039878917392343\n",
      "epoch= 16 iteration= 769 loss= 0.002185272052884102\n",
      "epoch= 16 iteration= 789 loss= 0.0007689498597756028\n",
      "epoch= 16 iteration= 809 loss= 0.0011458371300250292\n",
      "test_data MSELoss:(pred-real)/real= 0.00024002456921152772\n",
      "epoch= 17 iteration= 817 loss= 0.0021837553940713406\n",
      "epoch= 17 iteration= 837 loss= 0.0007684694137424231\n",
      "epoch= 17 iteration= 857 loss= 0.0011472862679511309\n",
      "test_data MSELoss:(pred-real)/real= 0.00023970788606675342\n",
      "epoch= 18 iteration= 865 loss= 0.0021824799478054047\n",
      "epoch= 18 iteration= 885 loss= 0.0007680157432332635\n",
      "epoch= 18 iteration= 905 loss= 0.0011484755668789148\n",
      "test_data MSELoss:(pred-real)/real= 0.00023944211279740556\n",
      "epoch= 19 iteration= 913 loss= 0.0021813521161675453\n",
      "epoch= 19 iteration= 933 loss= 0.0007676812238059938\n",
      "epoch= 19 iteration= 953 loss= 0.0011496241204440594\n",
      "test_data MSELoss:(pred-real)/real= 0.00023921088577480987\n",
      "epoch= 20 iteration= 961 loss= 0.00218045711517334\n",
      "epoch= 20 iteration= 981 loss= 0.0007673444924876094\n",
      "epoch= 20 iteration= 1001 loss= 0.0011506065493449569\n",
      "test_data MSELoss:(pred-real)/real= 0.0002390244830166921\n",
      "epoch= 21 iteration= 1009 loss= 0.0021795944776386023\n",
      "epoch= 21 iteration= 1029 loss= 0.0007670394261367619\n",
      "epoch= 21 iteration= 1049 loss= 0.0011512652272358537\n",
      "test_data MSELoss:(pred-real)/real= 0.00023884817346697673\n",
      "epoch= 22 iteration= 1057 loss= 0.002178933471441269\n",
      "epoch= 22 iteration= 1077 loss= 0.0007667631143704057\n",
      "epoch= 22 iteration= 1097 loss= 0.001151741947978735\n",
      "test_data MSELoss:(pred-real)/real= 0.0002387115455348976\n",
      "epoch= 23 iteration= 1105 loss= 0.0021783015690743923\n",
      "epoch= 23 iteration= 1125 loss= 0.000766496523283422\n",
      "epoch= 23 iteration= 1145 loss= 0.0011521353153511882\n",
      "test_data MSELoss:(pred-real)/real= 0.00023858873028075321\n",
      "epoch= 24 iteration= 1153 loss= 0.002177627757191658\n",
      "epoch= 24 iteration= 1173 loss= 0.0007662245770916343\n",
      "epoch= 24 iteration= 1193 loss= 0.0011522810673341155\n",
      "test_data MSELoss:(pred-real)/real= 0.00023848380660638214\n",
      "epoch= 25 iteration= 1201 loss= 0.0021770743187516928\n",
      "epoch= 25 iteration= 1221 loss= 0.000765942269936204\n",
      "epoch= 25 iteration= 1241 loss= 0.0011522099375724792\n",
      "test_data MSELoss:(pred-real)/real= 0.00023839269706513733\n",
      "epoch= 26 iteration= 1249 loss= 0.0021765115670859814\n",
      "epoch= 26 iteration= 1269 loss= 0.0007656643283553421\n",
      "epoch= 26 iteration= 1289 loss= 0.001152020413428545\n",
      "test_data MSELoss:(pred-real)/real= 0.0002383133105468005\n",
      "epoch= 27 iteration= 1297 loss= 0.0021759681403636932\n",
      "epoch= 27 iteration= 1317 loss= 0.0007653599022887647\n",
      "epoch= 27 iteration= 1337 loss= 0.0011517559178173542\n",
      "test_data MSELoss:(pred-real)/real= 0.00023825341631891205\n",
      "epoch= 28 iteration= 1345 loss= 0.002175482688471675\n",
      "epoch= 28 iteration= 1365 loss= 0.0007650913903489709\n",
      "epoch= 28 iteration= 1385 loss= 0.0011513476492837071\n",
      "test_data MSELoss:(pred-real)/real= 0.00023819251800887286\n",
      "epoch= 29 iteration= 1393 loss= 0.002174992114305496\n",
      "epoch= 29 iteration= 1413 loss= 0.0007647849852219224\n",
      "epoch= 29 iteration= 1433 loss= 0.0011508632451295853\n",
      "test_data MSELoss:(pred-real)/real= 0.00023815127788111566\n",
      "epoch= 30 iteration= 1441 loss= 0.0021744619589298964\n",
      "epoch= 30 iteration= 1461 loss= 0.0007644622819498181\n",
      "epoch= 30 iteration= 1481 loss= 0.0011502718552947044\n",
      "test_data MSELoss:(pred-real)/real= 0.00023810736747691407\n",
      "epoch= 31 iteration= 1489 loss= 0.002173959743231535\n",
      "epoch= 31 iteration= 1509 loss= 0.0007641637930646539\n",
      "epoch= 31 iteration= 1529 loss= 0.0011496588122099638\n",
      "test_data MSELoss:(pred-real)/real= 0.000238075660308823\n",
      "epoch= 32 iteration= 1537 loss= 0.0021734745241701603\n",
      "epoch= 32 iteration= 1557 loss= 0.0007638384704478085\n",
      "epoch= 32 iteration= 1577 loss= 0.0011489738244563341\n",
      "test_data MSELoss:(pred-real)/real= 0.00023804655065760017\n",
      "epoch= 33 iteration= 1585 loss= 0.0021729974541813135\n",
      "epoch= 33 iteration= 1605 loss= 0.0007635116926394403\n",
      "epoch= 33 iteration= 1625 loss= 0.0011483370326459408\n",
      "test_data MSELoss:(pred-real)/real= 0.00023801899078534916\n",
      "epoch= 34 iteration= 1633 loss= 0.0021724591497331858\n",
      "epoch= 34 iteration= 1653 loss= 0.000763158081099391\n",
      "epoch= 34 iteration= 1673 loss= 0.0011474293423816562\n",
      "test_data MSELoss:(pred-real)/real= 0.00023799796035746114\n",
      "epoch= 35 iteration= 1681 loss= 0.00217198533937335\n",
      "epoch= 35 iteration= 1701 loss= 0.0007628129096701741\n",
      "epoch= 35 iteration= 1721 loss= 0.0011466701980680227\n",
      "test_data MSELoss:(pred-real)/real= 0.00023797937319613993\n",
      "epoch= 36 iteration= 1729 loss= 0.002171449363231659\n",
      "epoch= 36 iteration= 1749 loss= 0.0007624400313943624\n",
      "epoch= 36 iteration= 1769 loss= 0.0011458646040409803\n",
      "test_data MSELoss:(pred-real)/real= 0.00023796621535439045\n",
      "epoch= 37 iteration= 1777 loss= 0.002170900348573923\n",
      "epoch= 37 iteration= 1797 loss= 0.0007620769902132452\n",
      "epoch= 37 iteration= 1817 loss= 0.0011451223399490118\n",
      "test_data MSELoss:(pred-real)/real= 0.00023795711022103205\n",
      "epoch= 38 iteration= 1825 loss= 0.002170475898310542\n",
      "epoch= 38 iteration= 1845 loss= 0.0007617278024554253\n",
      "epoch= 38 iteration= 1865 loss= 0.0011442028917372227\n",
      "test_data MSELoss:(pred-real)/real= 0.00023794384323991836\n",
      "epoch= 39 iteration= 1873 loss= 0.002169919665902853\n",
      "epoch= 39 iteration= 1893 loss= 0.0007613464258611202\n",
      "epoch= 39 iteration= 1913 loss= 0.001143410219810903\n",
      "test_data MSELoss:(pred-real)/real= 0.0002379429730353877\n",
      "epoch= 40 iteration= 1921 loss= 0.0021693704184144735\n",
      "epoch= 40 iteration= 1941 loss= 0.0007609807653352618\n",
      "epoch= 40 iteration= 1961 loss= 0.001142586930654943\n",
      "test_data MSELoss:(pred-real)/real= 0.00023792821157258003\n",
      "epoch= 41 iteration= 1969 loss= 0.002168830716982484\n",
      "epoch= 41 iteration= 1989 loss= 0.0007605910650454462\n",
      "epoch= 41 iteration= 2009 loss= 0.0011417069472372532\n",
      "test_data MSELoss:(pred-real)/real= 0.00023792880529072136\n",
      "epoch= 42 iteration= 2017 loss= 0.002168389270082116\n",
      "epoch= 42 iteration= 2037 loss= 0.000760206370614469\n",
      "epoch= 42 iteration= 2057 loss= 0.0011409296421334147\n",
      "test_data MSELoss:(pred-real)/real= 0.00023792659485479816\n",
      "epoch= 43 iteration= 2065 loss= 0.0021678681951016188\n",
      "epoch= 43 iteration= 2085 loss= 0.0007598318043164909\n",
      "epoch= 43 iteration= 2105 loss= 0.001140101347118616\n",
      "test_data MSELoss:(pred-real)/real= 0.00023791884304955602\n",
      "epoch= 44 iteration= 2113 loss= 0.0021672570146620274\n",
      "epoch= 44 iteration= 2133 loss= 0.0007594864582642913\n",
      "epoch= 44 iteration= 2153 loss= 0.0011392626911401749\n",
      "test_data MSELoss:(pred-real)/real= 0.00023793027648935094\n",
      "epoch= 45 iteration= 2161 loss= 0.0021666698157787323\n",
      "epoch= 45 iteration= 2181 loss= 0.0007590972818434238\n",
      "epoch= 45 iteration= 2201 loss= 0.001138463499955833\n",
      "test_data MSELoss:(pred-real)/real= 0.00023791697312844918\n",
      "epoch= 46 iteration= 2209 loss= 0.0021661289501935244\n",
      "epoch= 46 iteration= 2229 loss= 0.0007587185828015208\n",
      "epoch= 46 iteration= 2249 loss= 0.001137527753598988\n",
      "test_data MSELoss:(pred-real)/real= 0.00023792216525180264\n",
      "epoch= 47 iteration= 2257 loss= 0.0021655946038663387\n",
      "epoch= 47 iteration= 2277 loss= 0.0007583397091366351\n",
      "epoch= 47 iteration= 2297 loss= 0.00113680271897465\n",
      "test_data MSELoss:(pred-real)/real= 0.0002379211931838654\n",
      "epoch= 48 iteration= 2305 loss= 0.0021650376729667187\n",
      "epoch= 48 iteration= 2325 loss= 0.0007579553639516234\n",
      "epoch= 48 iteration= 2345 loss= 0.001136002829298377\n",
      "test_data MSELoss:(pred-real)/real= 0.00023792195424903183\n",
      "epoch= 49 iteration= 2353 loss= 0.0021645021624863148\n",
      "epoch= 49 iteration= 2373 loss= 0.0007575744530186057\n",
      "epoch= 49 iteration= 2393 loss= 0.001135207829065621\n",
      "test_data MSELoss:(pred-real)/real= 0.00023791930871084333\n",
      "epoch= 50 iteration= 2401 loss= 0.0021639522165060043\n",
      "epoch= 50 iteration= 2421 loss= 0.0007571952301077545\n",
      "epoch= 50 iteration= 2441 loss= 0.00113440933637321\n",
      "test_data MSELoss:(pred-real)/real= 0.0002379176381509751\n",
      "epoch= 51 iteration= 2449 loss= 0.00216332683339715\n",
      "epoch= 51 iteration= 2469 loss= 0.0007568163564428687\n",
      "epoch= 51 iteration= 2489 loss= 0.001133624347858131\n",
      "test_data MSELoss:(pred-real)/real= 0.00023791269777575507\n",
      "epoch= 52 iteration= 2497 loss= 0.0021627447567880154\n",
      "epoch= 52 iteration= 2517 loss= 0.0007564436527900398\n",
      "epoch= 52 iteration= 2537 loss= 0.0011329255066812038\n",
      "test_data MSELoss:(pred-real)/real= 0.0002379167824983597\n",
      "epoch= 53 iteration= 2545 loss= 0.002162157092243433\n",
      "epoch= 53 iteration= 2565 loss= 0.0007560966769233346\n",
      "epoch= 53 iteration= 2585 loss= 0.0011322094360366464\n",
      "test_data MSELoss:(pred-real)/real= 0.00023790596169419586\n",
      "epoch= 54 iteration= 2593 loss= 0.0021615680307149887\n",
      "epoch= 54 iteration= 2613 loss= 0.0007557139033451676\n",
      "epoch= 54 iteration= 2633 loss= 0.0011314688017591834\n",
      "test_data MSELoss:(pred-real)/real= 0.00023791387648088857\n",
      "epoch= 55 iteration= 2641 loss= 0.0021609726827591658\n",
      "epoch= 55 iteration= 2661 loss= 0.0007553260657005012\n",
      "epoch= 55 iteration= 2681 loss= 0.0011307941749691963\n",
      "test_data MSELoss:(pred-real)/real= 0.00023789920815033838\n",
      "epoch= 56 iteration= 2689 loss= 0.002160347532480955\n",
      "epoch= 56 iteration= 2709 loss= 0.0007549576694145799\n",
      "epoch= 56 iteration= 2729 loss= 0.0011300088372081518\n",
      "test_data MSELoss:(pred-real)/real= 0.00023789923579897732\n",
      "epoch= 57 iteration= 2737 loss= 0.0021597458980977535\n",
      "epoch= 57 iteration= 2757 loss= 0.000754623964894563\n",
      "epoch= 57 iteration= 2777 loss= 0.0011293464340269566\n",
      "test_data MSELoss:(pred-real)/real= 0.00023789987462805585\n",
      "epoch= 58 iteration= 2785 loss= 0.002159078372642398\n",
      "epoch= 58 iteration= 2805 loss= 0.0007542623206973076\n",
      "epoch= 58 iteration= 2825 loss= 0.0011286800727248192\n",
      "test_data MSELoss:(pred-real)/real= 0.00023790461127646268\n",
      "epoch= 59 iteration= 2833 loss= 0.0021584471687674522\n",
      "epoch= 59 iteration= 2853 loss= 0.0007539035868830979\n",
      "epoch= 59 iteration= 2873 loss= 0.0011279345490038395\n",
      "test_data MSELoss:(pred-real)/real= 0.0002378951874561608\n",
      "epoch= 60 iteration= 2881 loss= 0.002157811541110277\n",
      "epoch= 60 iteration= 2901 loss= 0.0007535453187301755\n",
      "epoch= 60 iteration= 2921 loss= 0.0011272924020886421\n",
      "test_data MSELoss:(pred-real)/real= 0.0002378961944486946\n",
      "epoch= 61 iteration= 2929 loss= 0.0021571144461631775\n",
      "epoch= 61 iteration= 2949 loss= 0.0007532074232585728\n",
      "epoch= 61 iteration= 2969 loss= 0.001126666902564466\n",
      "test_data MSELoss:(pred-real)/real= 0.00023787934915162623\n",
      "epoch= 62 iteration= 2977 loss= 0.0021565344650298357\n",
      "epoch= 62 iteration= 2997 loss= 0.0007528556743636727\n",
      "epoch= 62 iteration= 3017 loss= 0.0011259864550083876\n",
      "test_data MSELoss:(pred-real)/real= 0.00023786020901752635\n",
      "epoch= 63 iteration= 3025 loss= 0.002155753318220377\n",
      "epoch= 63 iteration= 3045 loss= 0.0007524987449869514\n",
      "epoch= 63 iteration= 3065 loss= 0.0011253911070525646\n",
      "test_data MSELoss:(pred-real)/real= 0.00023786595556885004\n",
      "epoch= 64 iteration= 3073 loss= 0.002155069261789322\n",
      "epoch= 64 iteration= 3093 loss= 0.0007521483348682523\n",
      "epoch= 64 iteration= 3113 loss= 0.0011247129878029227\n",
      "test_data MSELoss:(pred-real)/real= 0.00023785944358678535\n",
      "epoch= 65 iteration= 3121 loss= 0.002154301619157195\n",
      "epoch= 65 iteration= 3141 loss= 0.0007518360507674515\n",
      "epoch= 65 iteration= 3161 loss= 0.0011241002939641476\n",
      "test_data MSELoss:(pred-real)/real= 0.00023785171506460757\n",
      "epoch= 66 iteration= 3169 loss= 0.0021535479463636875\n",
      "epoch= 66 iteration= 3189 loss= 0.0007515000179409981\n",
      "epoch= 66 iteration= 3209 loss= 0.0011234527919441462\n",
      "test_data MSELoss:(pred-real)/real= 0.00023783984361216425\n",
      "epoch= 67 iteration= 3217 loss= 0.0021527817007154226\n",
      "epoch= 67 iteration= 3237 loss= 0.0007511473377235234\n",
      "epoch= 67 iteration= 3257 loss= 0.0011228632647544146\n",
      "test_data MSELoss:(pred-real)/real= 0.00023782535427017138\n",
      "epoch= 68 iteration= 3265 loss= 0.0021520997397601604\n",
      "epoch= 68 iteration= 3285 loss= 0.000750852283090353\n",
      "epoch= 68 iteration= 3305 loss= 0.0011222788598388433\n",
      "test_data MSELoss:(pred-real)/real= 0.00023780489718774333\n",
      "epoch= 69 iteration= 3313 loss= 0.002151316963136196\n",
      "epoch= 69 iteration= 3333 loss= 0.0007505163084715605\n",
      "epoch= 69 iteration= 3353 loss= 0.001121640671044588\n",
      "test_data MSELoss:(pred-real)/real= 0.00023779077018843965\n",
      "epoch= 70 iteration= 3361 loss= 0.0021505479235202074\n",
      "epoch= 70 iteration= 3381 loss= 0.000750197796151042\n",
      "epoch= 70 iteration= 3401 loss= 0.0011210517259314656\n",
      "test_data MSELoss:(pred-real)/real= 0.00023778116446919738\n",
      "epoch= 71 iteration= 3409 loss= 0.002149702049791813\n",
      "epoch= 71 iteration= 3429 loss= 0.0007498686318285763\n",
      "epoch= 71 iteration= 3449 loss= 0.0011204108595848083\n",
      "test_data MSELoss:(pred-real)/real= 0.0002377467113547027\n",
      "epoch= 72 iteration= 3457 loss= 0.0021489239297807217\n",
      "epoch= 72 iteration= 3477 loss= 0.0007495427271351218\n",
      "epoch= 72 iteration= 3497 loss= 0.0011198405409231782\n",
      "test_data MSELoss:(pred-real)/real= 0.00023772955755703152\n",
      "epoch= 73 iteration= 3505 loss= 0.0021480885334312916\n",
      "epoch= 73 iteration= 3525 loss= 0.0007492468575946987\n",
      "epoch= 73 iteration= 3545 loss= 0.0011192489182576537\n",
      "test_data MSELoss:(pred-real)/real= 0.0002377106895437464\n",
      "epoch= 74 iteration= 3553 loss= 0.002147178864106536\n",
      "epoch= 74 iteration= 3573 loss= 0.0007489269482903183\n",
      "epoch= 74 iteration= 3593 loss= 0.0011186932679265738\n",
      "test_data MSELoss:(pred-real)/real= 0.0002376877120696008\n",
      "epoch= 75 iteration= 3601 loss= 0.002146278042346239\n",
      "epoch= 75 iteration= 3621 loss= 0.0007486188551411033\n",
      "epoch= 75 iteration= 3641 loss= 0.0011181288864463568\n",
      "test_data MSELoss:(pred-real)/real= 0.00023765979858580977\n",
      "epoch= 76 iteration= 3649 loss= 0.0021454202942550182\n",
      "epoch= 76 iteration= 3669 loss= 0.0007483179215341806\n",
      "epoch= 76 iteration= 3689 loss= 0.0011175933759659529\n",
      "test_data MSELoss:(pred-real)/real= 0.00023763446952216328\n",
      "epoch= 77 iteration= 3697 loss= 0.0021444903686642647\n",
      "epoch= 77 iteration= 3717 loss= 0.0007480151834897697\n",
      "epoch= 77 iteration= 3737 loss= 0.0011170111829414964\n",
      "test_data MSELoss:(pred-real)/real= 0.00023760481708450242\n",
      "epoch= 78 iteration= 3745 loss= 0.0021435748785734177\n",
      "epoch= 78 iteration= 3765 loss= 0.0007477168110199273\n",
      "epoch= 78 iteration= 3785 loss= 0.0011164661264047027\n",
      "test_data MSELoss:(pred-real)/real= 0.00023757412272971124\n",
      "epoch= 79 iteration= 3793 loss= 0.002142610726878047\n",
      "epoch= 79 iteration= 3813 loss= 0.0007474366575479507\n",
      "epoch= 79 iteration= 3833 loss= 0.0011158807901665568\n",
      "test_data MSELoss:(pred-real)/real= 0.0002375362382736057\n",
      "epoch= 80 iteration= 3841 loss= 0.002141650067642331\n",
      "epoch= 80 iteration= 3861 loss= 0.0007471436401829123\n",
      "epoch= 80 iteration= 3881 loss= 0.0011153500527143478\n",
      "test_data MSELoss:(pred-real)/real= 0.00023751228291075678\n",
      "epoch= 81 iteration= 3889 loss= 0.002140599302947521\n",
      "epoch= 81 iteration= 3909 loss= 0.0007468425901606679\n",
      "epoch= 81 iteration= 3929 loss= 0.001114772167056799\n",
      "test_data MSELoss:(pred-real)/real= 0.0002374751027673483\n",
      "epoch= 82 iteration= 3937 loss= 0.0021395522635430098\n",
      "epoch= 82 iteration= 3957 loss= 0.0007465464295819402\n",
      "epoch= 82 iteration= 3977 loss= 0.0011142540024593472\n",
      "test_data MSELoss:(pred-real)/real= 0.00023743316414766015\n",
      "epoch= 83 iteration= 3985 loss= 0.0021386239677667618\n",
      "epoch= 83 iteration= 4005 loss= 0.0007462752982974052\n",
      "epoch= 83 iteration= 4025 loss= 0.0011137365363538265\n",
      "test_data MSELoss:(pred-real)/real= 0.00023738856543786824\n",
      "epoch= 84 iteration= 4033 loss= 0.00213752593845129\n",
      "epoch= 84 iteration= 4053 loss= 0.0007459937478415668\n",
      "epoch= 84 iteration= 4073 loss= 0.0011132130166515708\n",
      "test_data MSELoss:(pred-real)/real= 0.0002373467039433308\n",
      "epoch= 85 iteration= 4081 loss= 0.002136500319465995\n",
      "epoch= 85 iteration= 4101 loss= 0.0007456964813172817\n",
      "epoch= 85 iteration= 4121 loss= 0.0011126770405098796\n",
      "test_data MSELoss:(pred-real)/real= 0.0002372968345298432\n",
      "epoch= 86 iteration= 4129 loss= 0.0021353804040700197\n",
      "epoch= 86 iteration= 4149 loss= 0.0007454263977706432\n",
      "epoch= 86 iteration= 4169 loss= 0.0011121778516098857\n",
      "test_data MSELoss:(pred-real)/real= 0.00023724791826680304\n",
      "epoch= 87 iteration= 4177 loss= 0.0021343212574720383\n",
      "epoch= 87 iteration= 4197 loss= 0.0007451564306393266\n",
      "epoch= 87 iteration= 4217 loss= 0.0011116493260487914\n",
      "test_data MSELoss:(pred-real)/real= 0.0002372047398239374\n",
      "epoch= 88 iteration= 4225 loss= 0.0021331747993826866\n",
      "epoch= 88 iteration= 4245 loss= 0.000744867546018213\n",
      "epoch= 88 iteration= 4265 loss= 0.0011111280182376504\n",
      "test_data MSELoss:(pred-real)/real= 0.00023715681163594127\n",
      "epoch= 89 iteration= 4273 loss= 0.0021320227533578873\n",
      "epoch= 89 iteration= 4293 loss= 0.0007445995579473674\n",
      "epoch= 89 iteration= 4313 loss= 0.0011106020538136363\n",
      "test_data MSELoss:(pred-real)/real= 0.00023710698733339086\n",
      "epoch= 90 iteration= 4321 loss= 0.0021308348514139652\n",
      "epoch= 90 iteration= 4341 loss= 0.0007443348877131939\n",
      "epoch= 90 iteration= 4361 loss= 0.0011100886622443795\n",
      "test_data MSELoss:(pred-real)/real= 0.00023704839550191535\n",
      "epoch= 91 iteration= 4369 loss= 0.002129701431840658\n",
      "epoch= 91 iteration= 4389 loss= 0.0007440857007168233\n",
      "epoch= 91 iteration= 4409 loss= 0.0011095989029854536\n",
      "test_data MSELoss:(pred-real)/real= 0.0002369861103943549\n",
      "epoch= 92 iteration= 4417 loss= 0.0021284581162035465\n",
      "epoch= 92 iteration= 4437 loss= 0.0007437915774062276\n",
      "epoch= 92 iteration= 4457 loss= 0.0011090999469161034\n",
      "test_data MSELoss:(pred-real)/real= 0.0002369230249314569\n",
      "epoch= 93 iteration= 4465 loss= 0.0021272364538162947\n",
      "epoch= 93 iteration= 4485 loss= 0.0007435607258230448\n",
      "epoch= 93 iteration= 4505 loss= 0.0011086021549999714\n",
      "test_data MSELoss:(pred-real)/real= 0.00023687407228862868\n",
      "epoch= 94 iteration= 4513 loss= 0.0021259516943246126\n",
      "epoch= 94 iteration= 4533 loss= 0.0007432891288772225\n",
      "epoch= 94 iteration= 4553 loss= 0.0011080966796725988\n",
      "test_data MSELoss:(pred-real)/real= 0.00023680274316575378\n",
      "epoch= 95 iteration= 4561 loss= 0.0021246953401714563\n",
      "epoch= 95 iteration= 4581 loss= 0.0007430500700138509\n",
      "epoch= 95 iteration= 4601 loss= 0.0011076015653088689\n",
      "test_data MSELoss:(pred-real)/real= 0.00023671605304116384\n",
      "epoch= 96 iteration= 4609 loss= 0.0021234462037682533\n",
      "epoch= 96 iteration= 4629 loss= 0.0007427763775922358\n",
      "epoch= 96 iteration= 4649 loss= 0.0011070959735661745\n",
      "test_data MSELoss:(pred-real)/real= 0.0002366432119742967\n",
      "epoch= 97 iteration= 4657 loss= 0.002122154226526618\n",
      "epoch= 97 iteration= 4677 loss= 0.0007425319054163992\n",
      "epoch= 97 iteration= 4697 loss= 0.0011066156439483166\n",
      "test_data MSELoss:(pred-real)/real= 0.00023655749537283556\n",
      "epoch= 98 iteration= 4705 loss= 0.0021208617836236954\n",
      "epoch= 98 iteration= 4725 loss= 0.0007422593771480024\n",
      "epoch= 98 iteration= 4745 loss= 0.0011061447439715266\n",
      "test_data MSELoss:(pred-real)/real= 0.00023649269714951516\n",
      "epoch= 99 iteration= 4753 loss= 0.002119386103004217\n",
      "epoch= 99 iteration= 4773 loss= 0.0007420194451697171\n",
      "epoch= 99 iteration= 4793 loss= 0.001105673611164093\n",
      "test_data MSELoss:(pred-real)/real= 0.00023641228035558014\n",
      "epoch= 100 iteration= 4801 loss= 0.002118052216246724\n",
      "epoch= 100 iteration= 4821 loss= 0.0007417574524879456\n",
      "epoch= 100 iteration= 4841 loss= 0.0011051746550947428\n",
      "test_data MSELoss:(pred-real)/real= 0.00023632822703802958\n",
      "epoch= 101 iteration= 4849 loss= 0.002116604708135128\n",
      "epoch= 101 iteration= 4869 loss= 0.0007415037835016847\n",
      "epoch= 101 iteration= 4889 loss= 0.0011047275038436055\n",
      "test_data MSELoss:(pred-real)/real= 0.0002362397950491868\n",
      "epoch= 102 iteration= 4897 loss= 0.0021152328699827194\n",
      "epoch= 102 iteration= 4917 loss= 0.000741282943636179\n",
      "epoch= 102 iteration= 4937 loss= 0.001104254275560379\n",
      "test_data MSELoss:(pred-real)/real= 0.00023614765668753535\n",
      "epoch= 103 iteration= 4945 loss= 0.00211378769017756\n",
      "epoch= 103 iteration= 4965 loss= 0.0007410376565530896\n",
      "epoch= 103 iteration= 4985 loss= 0.0011037447256967425\n",
      "test_data MSELoss:(pred-real)/real= 0.00023605463502462953\n",
      "epoch= 104 iteration= 4993 loss= 0.0021122389007359743\n",
      "epoch= 104 iteration= 5013 loss= 0.0007408028468489647\n",
      "epoch= 104 iteration= 5033 loss= 0.0011033114278689027\n",
      "test_data MSELoss:(pred-real)/real= 0.00023596163664478808\n",
      "epoch= 105 iteration= 5041 loss= 0.002110898494720459\n",
      "epoch= 105 iteration= 5061 loss= 0.0007405285141430795\n",
      "epoch= 105 iteration= 5081 loss= 0.0011029026936739683\n",
      "test_data MSELoss:(pred-real)/real= 0.00023586799507029353\n",
      "epoch= 106 iteration= 5089 loss= 0.00210933736525476\n",
      "epoch= 106 iteration= 5109 loss= 0.0007402920164167881\n",
      "epoch= 106 iteration= 5129 loss= 0.0011024107225239277\n",
      "test_data MSELoss:(pred-real)/real= 0.0002357710516662337\n",
      "epoch= 107 iteration= 5137 loss= 0.0021077324636280537\n",
      "epoch= 107 iteration= 5157 loss= 0.00074005126953125\n",
      "epoch= 107 iteration= 5177 loss= 0.001101942965760827\n",
      "test_data MSELoss:(pred-real)/real= 0.00023566384770674632\n",
      "epoch= 108 iteration= 5185 loss= 0.0021062493324279785\n",
      "epoch= 108 iteration= 5205 loss= 0.0007398460293188691\n",
      "epoch= 108 iteration= 5225 loss= 0.0011014528572559357\n",
      "test_data MSELoss:(pred-real)/real= 0.0002355556469410658\n",
      "epoch= 109 iteration= 5233 loss= 0.002104605082422495\n",
      "epoch= 109 iteration= 5253 loss= 0.0007395819993689656\n",
      "epoch= 109 iteration= 5273 loss= 0.001101011410355568\n",
      "test_data MSELoss:(pred-real)/real= 0.0002354282943997532\n",
      "epoch= 110 iteration= 5281 loss= 0.002103043720126152\n",
      "epoch= 110 iteration= 5301 loss= 0.0007393613923341036\n",
      "epoch= 110 iteration= 5321 loss= 0.0011005494743585587\n",
      "test_data MSELoss:(pred-real)/real= 0.00023532713821623475\n",
      "epoch= 111 iteration= 5329 loss= 0.0021013475488871336\n",
      "epoch= 111 iteration= 5349 loss= 0.0007391280960291624\n",
      "epoch= 111 iteration= 5369 loss= 0.0011000751983374357\n",
      "test_data MSELoss:(pred-real)/real= 0.0002352244089706801\n",
      "epoch= 112 iteration= 5377 loss= 0.0020997237879782915\n",
      "epoch= 112 iteration= 5397 loss= 0.0007388821104541421\n",
      "epoch= 112 iteration= 5417 loss= 0.0010996598284691572\n",
      "test_data MSELoss:(pred-real)/real= 0.00023510266037192197\n",
      "epoch= 113 iteration= 5425 loss= 0.0020980534609407187\n",
      "epoch= 113 iteration= 5445 loss= 0.0007386645884253085\n",
      "epoch= 113 iteration= 5465 loss= 0.0010991969611495733\n",
      "test_data MSELoss:(pred-real)/real= 0.00023497609508922325\n",
      "epoch= 114 iteration= 5473 loss= 0.0020963135175406933\n",
      "epoch= 114 iteration= 5493 loss= 0.0007384287309832871\n",
      "epoch= 114 iteration= 5513 loss= 0.0010987137211486697\n",
      "test_data MSELoss:(pred-real)/real= 0.0002348476875340566\n",
      "epoch= 115 iteration= 5521 loss= 0.002094461116939783\n",
      "epoch= 115 iteration= 5541 loss= 0.0007381902541965246\n",
      "epoch= 115 iteration= 5561 loss= 0.0010982692474499345\n",
      "test_data MSELoss:(pred-real)/real= 0.0002347342626308091\n",
      "epoch= 116 iteration= 5569 loss= 0.002092845970764756\n",
      "epoch= 116 iteration= 5589 loss= 0.000737970054615289\n",
      "epoch= 116 iteration= 5609 loss= 0.0010977920610457659\n",
      "test_data MSELoss:(pred-real)/real= 0.00023459236253984273\n",
      "epoch= 117 iteration= 5617 loss= 0.0020911474712193012\n",
      "epoch= 117 iteration= 5637 loss= 0.0007377488072961569\n",
      "epoch= 117 iteration= 5657 loss= 0.0010973827447742224\n",
      "test_data MSELoss:(pred-real)/real= 0.00023446186241926625\n",
      "epoch= 118 iteration= 5665 loss= 0.0020892058964818716\n",
      "epoch= 118 iteration= 5685 loss= 0.0007375158602371812\n",
      "epoch= 118 iteration= 5705 loss= 0.0010969135910272598\n",
      "test_data MSELoss:(pred-real)/real= 0.00023431679146597163\n",
      "epoch= 119 iteration= 5713 loss= 0.002087388187646866\n",
      "epoch= 119 iteration= 5733 loss= 0.0007372986292466521\n",
      "epoch= 119 iteration= 5753 loss= 0.0010964939137920737\n",
      "test_data MSELoss:(pred-real)/real= 0.000234192525385879\n",
      "epoch= 120 iteration= 5761 loss= 0.0020855888724327087\n",
      "epoch= 120 iteration= 5781 loss= 0.0007370442617684603\n",
      "epoch= 120 iteration= 5801 loss= 0.0010959762148559093\n",
      "test_data MSELoss:(pred-real)/real= 0.00023404778185067698\n",
      "epoch= 121 iteration= 5809 loss= 0.0020836240146309137\n",
      "epoch= 121 iteration= 5829 loss= 0.0007368362275883555\n",
      "epoch= 121 iteration= 5849 loss= 0.0010955098550766706\n",
      "test_data MSELoss:(pred-real)/real= 0.0002338995356694795\n",
      "epoch= 122 iteration= 5857 loss= 0.002081727609038353\n",
      "epoch= 122 iteration= 5877 loss= 0.0007365907076746225\n",
      "epoch= 122 iteration= 5897 loss= 0.0010951297590509057\n",
      "test_data MSELoss:(pred-real)/real= 0.0002337624173378572\n",
      "epoch= 123 iteration= 5905 loss= 0.0020797578617930412\n",
      "epoch= 123 iteration= 5925 loss= 0.0007363737095147371\n",
      "epoch= 123 iteration= 5945 loss= 0.001094640465453267\n",
      "test_data MSELoss:(pred-real)/real= 0.0002336101621040143\n",
      "epoch= 124 iteration= 5953 loss= 0.002077728044241667\n",
      "epoch= 124 iteration= 5973 loss= 0.0007361238822340965\n",
      "epoch= 124 iteration= 5993 loss= 0.0010941277723759413\n",
      "test_data MSELoss:(pred-real)/real= 0.0002334503922611475\n",
      "epoch= 125 iteration= 6001 loss= 0.0020757922902703285\n",
      "epoch= 125 iteration= 6021 loss= 0.0007359182345680892\n",
      "epoch= 125 iteration= 6041 loss= 0.001093666534870863\n",
      "test_data MSELoss:(pred-real)/real= 0.0002332817151909694\n",
      "epoch= 126 iteration= 6049 loss= 0.002073784591630101\n",
      "epoch= 126 iteration= 6069 loss= 0.0007356774294748902\n",
      "epoch= 126 iteration= 6089 loss= 0.001093199709430337\n",
      "test_data MSELoss:(pred-real)/real= 0.00023312874109251424\n",
      "epoch= 127 iteration= 6097 loss= 0.0020716299768537283\n",
      "epoch= 127 iteration= 6117 loss= 0.0007354493136517704\n",
      "epoch= 127 iteration= 6137 loss= 0.0010927660623565316\n",
      "test_data MSELoss:(pred-real)/real= 0.00023297948500839994\n",
      "epoch= 128 iteration= 6145 loss= 0.0020695372950285673\n",
      "epoch= 128 iteration= 6165 loss= 0.0007352318498305976\n",
      "epoch= 128 iteration= 6185 loss= 0.001092239050194621\n",
      "test_data MSELoss:(pred-real)/real= 0.000232812283502426\n",
      "epoch= 129 iteration= 6193 loss= 0.002067358698695898\n",
      "epoch= 129 iteration= 6213 loss= 0.0007349917432293296\n",
      "epoch= 129 iteration= 6233 loss= 0.0010917950421571732\n",
      "test_data MSELoss:(pred-real)/real= 0.00023263290495378897\n",
      "epoch= 130 iteration= 6241 loss= 0.0020652408711612225\n",
      "epoch= 130 iteration= 6261 loss= 0.0007347479113377631\n",
      "epoch= 130 iteration= 6281 loss= 0.0010912339203059673\n",
      "test_data MSELoss:(pred-real)/real= 0.00023245739575941115\n",
      "epoch= 131 iteration= 6289 loss= 0.0020629826467484236\n",
      "epoch= 131 iteration= 6309 loss= 0.0007345379563048482\n",
      "epoch= 131 iteration= 6329 loss= 0.0010907419491559267\n",
      "test_data MSELoss:(pred-real)/real= 0.00023226895718835293\n",
      "epoch= 132 iteration= 6337 loss= 0.0020608026534318924\n",
      "epoch= 132 iteration= 6357 loss= 0.0007342923199757934\n",
      "epoch= 132 iteration= 6377 loss= 0.001090270816348493\n",
      "test_data MSELoss:(pred-real)/real= 0.0002320908461115323\n",
      "epoch= 133 iteration= 6385 loss= 0.0020586075261235237\n",
      "epoch= 133 iteration= 6405 loss= 0.0007340703159570694\n",
      "epoch= 133 iteration= 6425 loss= 0.0010897746542468667\n",
      "test_data MSELoss:(pred-real)/real= 0.00023190204083221034\n",
      "epoch= 134 iteration= 6433 loss= 0.002056205878034234\n",
      "epoch= 134 iteration= 6453 loss= 0.0007338017458096147\n",
      "epoch= 134 iteration= 6473 loss= 0.0010892774444073439\n",
      "test_data MSELoss:(pred-real)/real= 0.0002317040620255284\n",
      "epoch= 135 iteration= 6481 loss= 0.002053862204775214\n",
      "epoch= 135 iteration= 6501 loss= 0.0007335585542023182\n",
      "epoch= 135 iteration= 6521 loss= 0.0010886809322983027\n",
      "test_data MSELoss:(pred-real)/real= 0.00023150424822233618\n",
      "epoch= 136 iteration= 6529 loss= 0.0020514419302344322\n",
      "epoch= 136 iteration= 6549 loss= 0.0007333165849559009\n",
      "epoch= 136 iteration= 6569 loss= 0.0010882046772167087\n",
      "test_data MSELoss:(pred-real)/real= 0.00023130603804020212\n",
      "epoch= 137 iteration= 6577 loss= 0.002049077535048127\n",
      "epoch= 137 iteration= 6597 loss= 0.0007330786320380867\n",
      "epoch= 137 iteration= 6617 loss= 0.0010876250453293324\n",
      "test_data MSELoss:(pred-real)/real= 0.00023111793416319415\n",
      "epoch= 138 iteration= 6625 loss= 0.002046592766419053\n",
      "epoch= 138 iteration= 6645 loss= 0.0007328374776989222\n",
      "epoch= 138 iteration= 6665 loss= 0.001087083714082837\n",
      "test_data MSELoss:(pred-real)/real= 0.0002309043091372587\n",
      "epoch= 139 iteration= 6673 loss= 0.0020440202206373215\n",
      "epoch= 139 iteration= 6693 loss= 0.0007325791520997882\n",
      "epoch= 139 iteration= 6713 loss= 0.0010865272488445044\n",
      "test_data MSELoss:(pred-real)/real= 0.0002306955080712214\n",
      "epoch= 140 iteration= 6721 loss= 0.002041563158854842\n",
      "epoch= 140 iteration= 6741 loss= 0.0007323335157707334\n",
      "epoch= 140 iteration= 6761 loss= 0.0010859252652153373\n",
      "test_data MSELoss:(pred-real)/real= 0.00023047631402732803\n",
      "epoch= 141 iteration= 6769 loss= 0.0020388439297676086\n",
      "epoch= 141 iteration= 6789 loss= 0.000732084852643311\n",
      "epoch= 141 iteration= 6809 loss= 0.0010853679850697517\n",
      "test_data MSELoss:(pred-real)/real= 0.0002302610664628446\n",
      "epoch= 142 iteration= 6817 loss= 0.002036341466009617\n",
      "epoch= 142 iteration= 6837 loss= 0.0007318052230402827\n",
      "epoch= 142 iteration= 6857 loss= 0.0010848084930330515\n",
      "test_data MSELoss:(pred-real)/real= 0.0002300462088896893\n",
      "epoch= 143 iteration= 6865 loss= 0.002033600118011236\n",
      "epoch= 143 iteration= 6885 loss= 0.0007315564434975386\n",
      "epoch= 143 iteration= 6905 loss= 0.0010842136107385159\n",
      "test_data MSELoss:(pred-real)/real= 0.00022982108857831917\n",
      "epoch= 144 iteration= 6913 loss= 0.002030812669545412\n",
      "epoch= 144 iteration= 6933 loss= 0.0007312741363421082\n",
      "epoch= 144 iteration= 6953 loss= 0.001083610113710165\n",
      "test_data MSELoss:(pred-real)/real= 0.00022958608606131746\n",
      "epoch= 145 iteration= 6961 loss= 0.002028114628046751\n",
      "epoch= 145 iteration= 6981 loss= 0.0007310081855393946\n",
      "epoch= 145 iteration= 7001 loss= 0.0010829220991581678\n",
      "test_data MSELoss:(pred-real)/real= 0.00022938019246794284\n",
      "epoch= 146 iteration= 7009 loss= 0.002025241032242775\n",
      "epoch= 146 iteration= 7029 loss= 0.0007307151099666953\n",
      "epoch= 146 iteration= 7049 loss= 0.0010822685435414314\n",
      "test_data MSELoss:(pred-real)/real= 0.00022913050779607146\n",
      "epoch= 147 iteration= 7057 loss= 0.002022399101406336\n",
      "epoch= 147 iteration= 7077 loss= 0.000730451662093401\n",
      "epoch= 147 iteration= 7097 loss= 0.0010816085850819945\n",
      "test_data MSELoss:(pred-real)/real= 0.00022886471851961686\n",
      "epoch= 148 iteration= 7105 loss= 0.0020194468088448048\n",
      "epoch= 148 iteration= 7125 loss= 0.0007301594596356153\n",
      "epoch= 148 iteration= 7145 loss= 0.0010809885570779443\n",
      "test_data MSELoss:(pred-real)/real= 0.00022862007608637214\n",
      "epoch= 149 iteration= 7153 loss= 0.002016549464315176\n",
      "epoch= 149 iteration= 7173 loss= 0.0007298649288713932\n",
      "epoch= 149 iteration= 7193 loss= 0.0010802694596350193\n",
      "test_data MSELoss:(pred-real)/real= 0.0002283702662680298\n",
      "epoch= 150 iteration= 7201 loss= 0.00201353314332664\n",
      "epoch= 150 iteration= 7221 loss= 0.0007295615505427122\n",
      "epoch= 150 iteration= 7241 loss= 0.0010795950656756759\n",
      "test_data MSELoss:(pred-real)/real= 0.0002281068118463736\n",
      "epoch= 151 iteration= 7249 loss= 0.0020104709547013044\n",
      "epoch= 151 iteration= 7269 loss= 0.0007292510708793998\n",
      "epoch= 151 iteration= 7289 loss= 0.0010788437211886048\n",
      "test_data MSELoss:(pred-real)/real= 0.000227866478235228\n",
      "epoch= 152 iteration= 7297 loss= 0.0020071619655936956\n",
      "epoch= 152 iteration= 7317 loss= 0.0007289633504115045\n",
      "epoch= 152 iteration= 7337 loss= 0.0010781235760077834\n",
      "test_data MSELoss:(pred-real)/real= 0.00022758379345759748\n",
      "epoch= 153 iteration= 7345 loss= 0.002004028297960758\n",
      "epoch= 153 iteration= 7365 loss= 0.0007285999599844217\n",
      "epoch= 153 iteration= 7385 loss= 0.0010774150723591447\n",
      "test_data MSELoss:(pred-real)/real= 0.0002273093181429431\n",
      "epoch= 154 iteration= 7393 loss= 0.002000821754336357\n",
      "epoch= 154 iteration= 7413 loss= 0.0007282669539563358\n",
      "epoch= 154 iteration= 7433 loss= 0.0010765392798930407\n",
      "test_data MSELoss:(pred-real)/real= 0.00022703684808220715\n",
      "epoch= 155 iteration= 7441 loss= 0.001997415442019701\n",
      "epoch= 155 iteration= 7461 loss= 0.0007279403507709503\n",
      "epoch= 155 iteration= 7481 loss= 0.001075743930414319\n",
      "test_data MSELoss:(pred-real)/real= 0.0002267494986881502\n",
      "epoch= 156 iteration= 7489 loss= 0.0019940671045333147\n",
      "epoch= 156 iteration= 7509 loss= 0.0007275987882167101\n",
      "epoch= 156 iteration= 7529 loss= 0.0010749541688710451\n",
      "test_data MSELoss:(pred-real)/real= 0.00022646027646260335\n",
      "epoch= 157 iteration= 7537 loss= 0.0019905962981283665\n",
      "epoch= 157 iteration= 7557 loss= 0.0007272239308804274\n",
      "epoch= 157 iteration= 7577 loss= 0.0010741580044850707\n",
      "test_data MSELoss:(pred-real)/real= 0.000226167420623824\n",
      "epoch= 158 iteration= 7585 loss= 0.001987079158425331\n",
      "epoch= 158 iteration= 7605 loss= 0.0007268658373504877\n",
      "epoch= 158 iteration= 7625 loss= 0.0010732642840594053\n",
      "test_data MSELoss:(pred-real)/real= 0.0002258661697851494\n",
      "epoch= 159 iteration= 7633 loss= 0.0019834572449326515\n",
      "epoch= 159 iteration= 7653 loss= 0.0007264754385687411\n",
      "epoch= 159 iteration= 7673 loss= 0.0010722900042310357\n",
      "test_data MSELoss:(pred-real)/real= 0.00022556298063136637\n",
      "epoch= 160 iteration= 7681 loss= 0.001979909837245941\n",
      "epoch= 160 iteration= 7701 loss= 0.0007260737475007772\n",
      "epoch= 160 iteration= 7721 loss= 0.0010714535601437092\n",
      "test_data MSELoss:(pred-real)/real= 0.0002252529295219574\n",
      "epoch= 161 iteration= 7729 loss= 0.0019761144649237394\n",
      "epoch= 161 iteration= 7749 loss= 0.0007256995304487646\n",
      "epoch= 161 iteration= 7769 loss= 0.001070509315468371\n",
      "test_data MSELoss:(pred-real)/real= 0.00022494139047921636\n",
      "epoch= 162 iteration= 7777 loss= 0.001972211292013526\n",
      "epoch= 162 iteration= 7797 loss= 0.000725287536624819\n",
      "epoch= 162 iteration= 7817 loss= 0.0010695391101762652\n",
      "test_data MSELoss:(pred-real)/real= 0.00022464618959929794\n",
      "epoch= 163 iteration= 7825 loss= 0.0019683223217725754\n",
      "epoch= 163 iteration= 7845 loss= 0.0007248558104038239\n",
      "epoch= 163 iteration= 7865 loss= 0.0010685650631785393\n",
      "test_data MSELoss:(pred-real)/real= 0.00022431296965805814\n",
      "epoch= 164 iteration= 7873 loss= 0.0019642249681055546\n",
      "epoch= 164 iteration= 7893 loss= 0.0007243966101668775\n",
      "epoch= 164 iteration= 7913 loss= 0.0010675322264432907\n",
      "test_data MSELoss:(pred-real)/real= 0.0002239837500383146\n",
      "epoch= 165 iteration= 7921 loss= 0.001960308523848653\n",
      "epoch= 165 iteration= 7941 loss= 0.0007239584811031818\n",
      "epoch= 165 iteration= 7961 loss= 0.0010665284935384989\n",
      "test_data MSELoss:(pred-real)/real= 0.00022365349577739834\n",
      "epoch= 166 iteration= 7969 loss= 0.0019561403896659613\n",
      "epoch= 166 iteration= 7989 loss= 0.0007234399090521038\n",
      "epoch= 166 iteration= 8009 loss= 0.0010653450153768063\n",
      "test_data MSELoss:(pred-real)/real= 0.00022331429936457426\n",
      "epoch= 167 iteration= 8017 loss= 0.0019518540939316154\n",
      "epoch= 167 iteration= 8037 loss= 0.0007229687762446702\n",
      "epoch= 167 iteration= 8057 loss= 0.0010641819098964334\n",
      "test_data MSELoss:(pred-real)/real= 0.00022295910312095658\n",
      "epoch= 168 iteration= 8065 loss= 0.0019475107546895742\n",
      "epoch= 168 iteration= 8085 loss= 0.0007224525907076895\n",
      "epoch= 168 iteration= 8105 loss= 0.0010631144978106022\n",
      "test_data MSELoss:(pred-real)/real= 0.00022258257231442258\n",
      "epoch= 169 iteration= 8113 loss= 0.001943236798979342\n",
      "epoch= 169 iteration= 8133 loss= 0.000721917487680912\n",
      "epoch= 169 iteration= 8153 loss= 0.001061927992850542\n",
      "test_data MSELoss:(pred-real)/real= 0.00022223027190193534\n",
      "epoch= 170 iteration= 8161 loss= 0.0019386321073397994\n",
      "epoch= 170 iteration= 8181 loss= 0.0007213755743578076\n",
      "epoch= 170 iteration= 8201 loss= 0.0010606623254716396\n",
      "test_data MSELoss:(pred-real)/real= 0.00022187339345691726\n",
      "epoch= 171 iteration= 8209 loss= 0.0019339278806000948\n",
      "epoch= 171 iteration= 8229 loss= 0.0007208091556094587\n",
      "epoch= 171 iteration= 8249 loss= 0.0010593733750283718\n",
      "test_data MSELoss:(pred-real)/real= 0.00022149915021145715\n",
      "epoch= 172 iteration= 8257 loss= 0.0019292064243927598\n",
      "epoch= 172 iteration= 8277 loss= 0.0007202314445748925\n",
      "epoch= 172 iteration= 8297 loss= 0.00105809117667377\n",
      "test_data MSELoss:(pred-real)/real= 0.0002211210652603768\n",
      "epoch= 173 iteration= 8305 loss= 0.001924440497532487\n",
      "epoch= 173 iteration= 8325 loss= 0.0007196030928753316\n",
      "epoch= 173 iteration= 8345 loss= 0.001056744484230876\n",
      "test_data MSELoss:(pred-real)/real= 0.0002207168174209073\n",
      "epoch= 174 iteration= 8353 loss= 0.0019194494234398007\n",
      "epoch= 174 iteration= 8373 loss= 0.0007189704920165241\n",
      "epoch= 174 iteration= 8393 loss= 0.001055320492014289\n",
      "test_data MSELoss:(pred-real)/real= 0.0002203303898568265\n",
      "epoch= 175 iteration= 8401 loss= 0.0019144219113513827\n",
      "epoch= 175 iteration= 8421 loss= 0.0007183026755228639\n",
      "epoch= 175 iteration= 8441 loss= 0.001053895684890449\n",
      "test_data MSELoss:(pred-real)/real= 0.0002199223410570994\n",
      "epoch= 176 iteration= 8449 loss= 0.0019091463182121515\n",
      "epoch= 176 iteration= 8469 loss= 0.0007176524959504604\n",
      "epoch= 176 iteration= 8489 loss= 0.0010523980017751455\n",
      "test_data MSELoss:(pred-real)/real= 0.0002195142340497114\n",
      "epoch= 177 iteration= 8497 loss= 0.001903832540847361\n",
      "epoch= 177 iteration= 8517 loss= 0.0007169162854552269\n",
      "epoch= 177 iteration= 8537 loss= 0.0010509074199944735\n",
      "test_data MSELoss:(pred-real)/real= 0.00021911991207161917\n",
      "epoch= 178 iteration= 8545 loss= 0.001898379996418953\n",
      "epoch= 178 iteration= 8565 loss= 0.0007161912508308887\n",
      "epoch= 178 iteration= 8585 loss= 0.0010492042638361454\n",
      "test_data MSELoss:(pred-real)/real= 0.00021867829709663056\n",
      "epoch= 179 iteration= 8593 loss= 0.0018928205827251077\n",
      "epoch= 179 iteration= 8613 loss= 0.0007153968326747417\n",
      "epoch= 179 iteration= 8633 loss= 0.0010476111201569438\n",
      "test_data MSELoss:(pred-real)/real= 0.00021824496798217297\n",
      "epoch= 180 iteration= 8641 loss= 0.0018871994689106941\n",
      "epoch= 180 iteration= 8661 loss= 0.0007146275602281094\n",
      "epoch= 180 iteration= 8681 loss= 0.0010458806063979864\n",
      "test_data MSELoss:(pred-real)/real= 0.00021780788956675677\n",
      "epoch= 181 iteration= 8689 loss= 0.0018813151400536299\n",
      "epoch= 181 iteration= 8709 loss= 0.0007137717329896986\n",
      "epoch= 181 iteration= 8729 loss= 0.0010441961931064725\n",
      "test_data MSELoss:(pred-real)/real= 0.00021735917689511553\n",
      "epoch= 182 iteration= 8737 loss= 0.0018752970499917865\n",
      "epoch= 182 iteration= 8757 loss= 0.0007129189907573164\n",
      "epoch= 182 iteration= 8777 loss= 0.0010423106141388416\n",
      "test_data MSELoss:(pred-real)/real= 0.00021692396039725282\n",
      "epoch= 183 iteration= 8785 loss= 0.001868974301032722\n",
      "epoch= 183 iteration= 8805 loss= 0.0007120111840777099\n",
      "epoch= 183 iteration= 8825 loss= 0.0010405986104160547\n",
      "test_data MSELoss:(pred-real)/real= 0.00021643382860929704\n",
      "epoch= 184 iteration= 8833 loss= 0.001862795208580792\n",
      "epoch= 184 iteration= 8853 loss= 0.0007110577425919473\n",
      "epoch= 184 iteration= 8873 loss= 0.0010385209461674094\n",
      "test_data MSELoss:(pred-real)/real= 0.00021597412924165838\n",
      "epoch= 185 iteration= 8881 loss= 0.0018562806071713567\n",
      "epoch= 185 iteration= 8901 loss= 0.0007100735674612224\n",
      "epoch= 185 iteration= 8921 loss= 0.0010364919435232878\n",
      "test_data MSELoss:(pred-real)/real= 0.0002154870620870497\n",
      "epoch= 186 iteration= 8929 loss= 0.0018495731055736542\n",
      "epoch= 186 iteration= 8949 loss= 0.0007090662256814539\n",
      "epoch= 186 iteration= 8969 loss= 0.0010344444308429956\n",
      "test_data MSELoss:(pred-real)/real= 0.00021501196752069519\n",
      "epoch= 187 iteration= 8977 loss= 0.001842800062149763\n",
      "epoch= 187 iteration= 8997 loss= 0.0007079850183799863\n",
      "epoch= 187 iteration= 9017 loss= 0.0010323121678084135\n",
      "test_data MSELoss:(pred-real)/real= 0.00021451614738907666\n",
      "epoch= 188 iteration= 9025 loss= 0.0018356856890022755\n",
      "epoch= 188 iteration= 9045 loss= 0.0007068730192258954\n",
      "epoch= 188 iteration= 9065 loss= 0.001030133105814457\n",
      "test_data MSELoss:(pred-real)/real= 0.00021400422774604523\n",
      "epoch= 189 iteration= 9073 loss= 0.0018285755068063736\n",
      "epoch= 189 iteration= 9093 loss= 0.0007057063630782068\n",
      "epoch= 189 iteration= 9113 loss= 0.0010277708061039448\n",
      "test_data MSELoss:(pred-real)/real= 0.00021349432499846445\n",
      "epoch= 190 iteration= 9121 loss= 0.0018212414579465985\n",
      "epoch= 190 iteration= 9141 loss= 0.0007044714875519276\n",
      "epoch= 190 iteration= 9161 loss= 0.0010254338849335909\n",
      "test_data MSELoss:(pred-real)/real= 0.00021298136562108994\n",
      "epoch= 191 iteration= 9169 loss= 0.0018136156722903252\n",
      "epoch= 191 iteration= 9189 loss= 0.0007032299763523042\n",
      "epoch= 191 iteration= 9209 loss= 0.0010230427142232656\n",
      "test_data MSELoss:(pred-real)/real= 0.00021244556846795605\n",
      "epoch= 192 iteration= 9217 loss= 0.0018057908164337277\n",
      "epoch= 192 iteration= 9237 loss= 0.0007018664618954062\n",
      "epoch= 192 iteration= 9257 loss= 0.0010203772690147161\n",
      "test_data MSELoss:(pred-real)/real= 0.0002118900760251563\n",
      "epoch= 193 iteration= 9265 loss= 0.001797824981622398\n",
      "epoch= 193 iteration= 9285 loss= 0.0007004917715676129\n",
      "epoch= 193 iteration= 9305 loss= 0.0010177989024668932\n",
      "test_data MSELoss:(pred-real)/real= 0.00021133946866029872\n",
      "epoch= 194 iteration= 9313 loss= 0.001789609668776393\n",
      "epoch= 194 iteration= 9333 loss= 0.0006990209803916514\n",
      "epoch= 194 iteration= 9353 loss= 0.001015183748677373\n",
      "test_data MSELoss:(pred-real)/real= 0.00021078175632283092\n",
      "epoch= 195 iteration= 9361 loss= 0.0017811780562624335\n",
      "epoch= 195 iteration= 9381 loss= 0.0006974888383410871\n",
      "epoch= 195 iteration= 9401 loss= 0.0010123234242200851\n",
      "test_data MSELoss:(pred-real)/real= 0.00021020872081862764\n",
      "epoch= 196 iteration= 9409 loss= 0.0017724110512062907\n",
      "epoch= 196 iteration= 9429 loss= 0.0006959522143006325\n",
      "epoch= 196 iteration= 9449 loss= 0.001009397441521287\n",
      "test_data MSELoss:(pred-real)/real= 0.00020964057475794106\n",
      "epoch= 197 iteration= 9457 loss= 0.0017635183176025748\n",
      "epoch= 197 iteration= 9477 loss= 0.0006943143089301884\n",
      "epoch= 197 iteration= 9497 loss= 0.0010065492242574692\n",
      "test_data MSELoss:(pred-real)/real= 0.00020903114709653893\n",
      "epoch= 198 iteration= 9505 loss= 0.0017542835557833314\n",
      "epoch= 198 iteration= 9525 loss= 0.000692625530064106\n",
      "epoch= 198 iteration= 9545 loss= 0.0010034169536083937\n",
      "test_data MSELoss:(pred-real)/real= 0.0002084336469124537\n",
      "epoch= 199 iteration= 9553 loss= 0.0017447324935346842\n",
      "epoch= 199 iteration= 9573 loss= 0.0006907634669914842\n",
      "epoch= 199 iteration= 9593 loss= 0.0010001470800489187\n",
      "test_data MSELoss:(pred-real)/real= 0.00020783605505130253\n",
      "epoch= 200 iteration= 9601 loss= 0.001734929857775569\n",
      "epoch= 200 iteration= 9621 loss= 0.0006889547221362591\n",
      "epoch= 200 iteration= 9641 loss= 0.0009969056118279696\n",
      "test_data MSELoss:(pred-real)/real= 0.00020721719847642816\n",
      "epoch= 201 iteration= 9649 loss= 0.0017249409575015306\n",
      "epoch= 201 iteration= 9669 loss= 0.0006869642529636621\n",
      "epoch= 201 iteration= 9689 loss= 0.0009933250257745385\n",
      "test_data MSELoss:(pred-real)/real= 0.0002065879940346349\n",
      "epoch= 202 iteration= 9697 loss= 0.0017145753372460604\n",
      "epoch= 202 iteration= 9717 loss= 0.0006849385099485517\n",
      "epoch= 202 iteration= 9737 loss= 0.0009899757569655776\n",
      "test_data MSELoss:(pred-real)/real= 0.00020593242807080968\n",
      "epoch= 203 iteration= 9745 loss= 0.0017041063401848078\n",
      "epoch= 203 iteration= 9765 loss= 0.0006827565375715494\n",
      "epoch= 203 iteration= 9785 loss= 0.0009863052982836962\n",
      "test_data MSELoss:(pred-real)/real= 0.0002052835305221379\n",
      "epoch= 204 iteration= 9793 loss= 0.0016930196434259415\n",
      "epoch= 204 iteration= 9813 loss= 0.000680589466355741\n",
      "epoch= 204 iteration= 9833 loss= 0.0009824938606470823\n",
      "test_data MSELoss:(pred-real)/real= 0.0002046239205810707\n",
      "epoch= 205 iteration= 9841 loss= 0.0016817933646962047\n",
      "epoch= 205 iteration= 9861 loss= 0.0006782612763345242\n",
      "epoch= 205 iteration= 9881 loss= 0.0009785520378500223\n",
      "test_data MSELoss:(pred-real)/real= 0.00020395054016262293\n",
      "epoch= 206 iteration= 9889 loss= 0.0016703330911695957\n",
      "epoch= 206 iteration= 9909 loss= 0.0006758130621165037\n",
      "epoch= 206 iteration= 9929 loss= 0.0009744916460476816\n",
      "test_data MSELoss:(pred-real)/real= 0.00020327872189227492\n",
      "epoch= 207 iteration= 9937 loss= 0.0016583414981141686\n",
      "epoch= 207 iteration= 9957 loss= 0.0006732464535161853\n",
      "epoch= 207 iteration= 9977 loss= 0.0009702437091618776\n",
      "test_data MSELoss:(pred-real)/real= 0.00020256618445273488\n",
      "epoch= 208 iteration= 9985 loss= 0.0016461941413581371\n",
      "epoch= 208 iteration= 10005 loss= 0.0006705874111503363\n",
      "epoch= 208 iteration= 10025 loss= 0.0009659550269134343\n",
      "test_data MSELoss:(pred-real)/real= 0.00020185279136057942\n",
      "epoch= 209 iteration= 10033 loss= 0.0016336776316165924\n",
      "epoch= 209 iteration= 10053 loss= 0.0006678062491118908\n",
      "epoch= 209 iteration= 10073 loss= 0.0009614980663172901\n",
      "test_data MSELoss:(pred-real)/real= 0.00020114963699597866\n",
      "epoch= 210 iteration= 10081 loss= 0.001620725728571415\n",
      "epoch= 210 iteration= 10101 loss= 0.0006649436545558274\n",
      "epoch= 210 iteration= 10121 loss= 0.0009568475070409477\n",
      "test_data MSELoss:(pred-real)/real= 0.00020041804236825556\n",
      "epoch= 211 iteration= 10129 loss= 0.001607223297469318\n",
      "epoch= 211 iteration= 10149 loss= 0.0006618986371904612\n",
      "epoch= 211 iteration= 10169 loss= 0.0009520471794530749\n",
      "test_data MSELoss:(pred-real)/real= 0.000199688888824312\n",
      "epoch= 212 iteration= 10177 loss= 0.0015934205148369074\n",
      "epoch= 212 iteration= 10197 loss= 0.0006587417447008193\n",
      "epoch= 212 iteration= 10217 loss= 0.000947161577641964\n",
      "test_data MSELoss:(pred-real)/real= 0.00019894147917511872\n",
      "epoch= 213 iteration= 10225 loss= 0.0015794693026691675\n",
      "epoch= 213 iteration= 10245 loss= 0.0006554315332323313\n",
      "epoch= 213 iteration= 10265 loss= 0.0009420841815881431\n",
      "test_data MSELoss:(pred-real)/real= 0.00019817114298348315\n",
      "epoch= 214 iteration= 10273 loss= 0.0015648892149329185\n",
      "epoch= 214 iteration= 10293 loss= 0.0006520326714962721\n",
      "epoch= 214 iteration= 10313 loss= 0.0009369596955366433\n",
      "test_data MSELoss:(pred-real)/real= 0.00019741617070394567\n",
      "epoch= 215 iteration= 10321 loss= 0.001549926120787859\n",
      "epoch= 215 iteration= 10341 loss= 0.0006483502220362425\n",
      "epoch= 215 iteration= 10361 loss= 0.0009313372429460287\n",
      "test_data MSELoss:(pred-real)/real= 0.00019662606282508933\n",
      "epoch= 216 iteration= 10369 loss= 0.0015343957347795367\n",
      "epoch= 216 iteration= 10389 loss= 0.000644690589979291\n",
      "epoch= 216 iteration= 10409 loss= 0.0009257422643713653\n",
      "test_data MSELoss:(pred-real)/real= 0.0001958380475116428\n",
      "epoch= 217 iteration= 10417 loss= 0.0015187934041023254\n",
      "epoch= 217 iteration= 10437 loss= 0.0006407990586012602\n",
      "epoch= 217 iteration= 10457 loss= 0.0009201022912748158\n",
      "test_data MSELoss:(pred-real)/real= 0.00019504472802509554\n",
      "epoch= 218 iteration= 10465 loss= 0.0015025986358523369\n",
      "epoch= 218 iteration= 10485 loss= 0.0006366956513375044\n",
      "epoch= 218 iteration= 10505 loss= 0.0009140162728726864\n",
      "test_data MSELoss:(pred-real)/real= 0.00019425475256866774\n",
      "epoch= 219 iteration= 10513 loss= 0.0014859249349683523\n",
      "epoch= 219 iteration= 10533 loss= 0.0006325037684291601\n",
      "epoch= 219 iteration= 10553 loss= 0.0009079803130589426\n",
      "test_data MSELoss:(pred-real)/real= 0.00019343662352184766\n",
      "epoch= 220 iteration= 10561 loss= 0.0014689036179333925\n",
      "epoch= 220 iteration= 10581 loss= 0.0006280458765104413\n",
      "epoch= 220 iteration= 10601 loss= 0.0009016559342853725\n",
      "test_data MSELoss:(pred-real)/real= 0.00019261125271441415\n",
      "epoch= 221 iteration= 10609 loss= 0.0014515486545860767\n",
      "epoch= 221 iteration= 10629 loss= 0.0006234012544155121\n",
      "epoch= 221 iteration= 10649 loss= 0.0008949643815867603\n",
      "test_data MSELoss:(pred-real)/real= 0.00019178775255568326\n",
      "epoch= 222 iteration= 10657 loss= 0.0014336499152705073\n",
      "epoch= 222 iteration= 10677 loss= 0.0006186243845149875\n",
      "epoch= 222 iteration= 10697 loss= 0.0008884303970262408\n",
      "test_data MSELoss:(pred-real)/real= 0.00019092616785201244\n",
      "epoch= 223 iteration= 10705 loss= 0.0014154256787151098\n",
      "epoch= 223 iteration= 10725 loss= 0.0006136306910775602\n",
      "epoch= 223 iteration= 10745 loss= 0.000881468818988651\n",
      "test_data MSELoss:(pred-real)/real= 0.00019010918549611233\n",
      "epoch= 224 iteration= 10753 loss= 0.0013966921251267195\n",
      "epoch= 224 iteration= 10773 loss= 0.0006084334454499185\n",
      "epoch= 224 iteration= 10793 loss= 0.0008744177757762372\n",
      "test_data MSELoss:(pred-real)/real= 0.0001892635591502767\n",
      "epoch= 225 iteration= 10801 loss= 0.0013777052517980337\n",
      "epoch= 225 iteration= 10821 loss= 0.0006030296790413558\n",
      "epoch= 225 iteration= 10841 loss= 0.0008671326795592904\n",
      "test_data MSELoss:(pred-real)/real= 0.00018841274504666217\n",
      "epoch= 226 iteration= 10849 loss= 0.001358206383883953\n",
      "epoch= 226 iteration= 10869 loss= 0.0005974950036033988\n",
      "epoch= 226 iteration= 10889 loss= 0.0008595892577432096\n",
      "test_data MSELoss:(pred-real)/real= 0.00018757571087917312\n",
      "epoch= 227 iteration= 10897 loss= 0.0013385121710598469\n",
      "epoch= 227 iteration= 10917 loss= 0.0005916836089454591\n",
      "epoch= 227 iteration= 10937 loss= 0.0008518784306943417\n",
      "test_data MSELoss:(pred-real)/real= 0.0001867317856522277\n",
      "epoch= 228 iteration= 10945 loss= 0.0013186695287004113\n",
      "epoch= 228 iteration= 10965 loss= 0.0005856764037162066\n",
      "epoch= 228 iteration= 10985 loss= 0.0008441251702606678\n",
      "test_data MSELoss:(pred-real)/real= 0.00018587434897199273\n",
      "epoch= 229 iteration= 10993 loss= 0.0012985264183953404\n",
      "epoch= 229 iteration= 11013 loss= 0.0005794563330709934\n",
      "epoch= 229 iteration= 11033 loss= 0.0008359898929484189\n",
      "test_data MSELoss:(pred-real)/real= 0.00018503182072890923\n",
      "epoch= 230 iteration= 11041 loss= 0.0012780171819031239\n",
      "epoch= 230 iteration= 11061 loss= 0.0005730808479711413\n",
      "epoch= 230 iteration= 11081 loss= 0.0008277821470983326\n",
      "test_data MSELoss:(pred-real)/real= 0.00018419612024445087\n",
      "epoch= 231 iteration= 11089 loss= 0.0012575314613059163\n",
      "epoch= 231 iteration= 11109 loss= 0.0005663878400810063\n",
      "epoch= 231 iteration= 11129 loss= 0.0008191985543817282\n",
      "test_data MSELoss:(pred-real)/real= 0.00018336130888201295\n",
      "epoch= 232 iteration= 11137 loss= 0.0012369200121611357\n",
      "epoch= 232 iteration= 11157 loss= 0.0005596037954092026\n",
      "epoch= 232 iteration= 11177 loss= 0.0008107497706077993\n",
      "test_data MSELoss:(pred-real)/real= 0.0001825246639782563\n",
      "epoch= 233 iteration= 11185 loss= 0.0012165619991719723\n",
      "epoch= 233 iteration= 11205 loss= 0.0005525792366825044\n",
      "epoch= 233 iteration= 11225 loss= 0.000802008667960763\n",
      "test_data MSELoss:(pred-real)/real= 0.0001816993215470575\n",
      "epoch= 234 iteration= 11233 loss= 0.0011962327407673001\n",
      "epoch= 234 iteration= 11253 loss= 0.0005454144557006657\n",
      "epoch= 234 iteration= 11273 loss= 0.0007933056331239641\n",
      "test_data MSELoss:(pred-real)/real= 0.00018088673023157752\n",
      "epoch= 235 iteration= 11281 loss= 0.001176350750029087\n",
      "epoch= 235 iteration= 11301 loss= 0.0005381217342801392\n",
      "epoch= 235 iteration= 11321 loss= 0.0007844147039577365\n",
      "test_data MSELoss:(pred-real)/real= 0.00018010192070505582\n",
      "epoch= 236 iteration= 11329 loss= 0.0011565913446247578\n",
      "epoch= 236 iteration= 11349 loss= 0.0005304914084263146\n",
      "epoch= 236 iteration= 11369 loss= 0.0007753859390504658\n",
      "test_data MSELoss:(pred-real)/real= 0.00017933630515472033\n",
      "epoch= 237 iteration= 11377 loss= 0.0011375033063814044\n",
      "epoch= 237 iteration= 11397 loss= 0.0005230054375715554\n",
      "epoch= 237 iteration= 11417 loss= 0.0007662692805752158\n",
      "test_data MSELoss:(pred-real)/real= 0.00017858000865089707\n",
      "epoch= 238 iteration= 11425 loss= 0.0011191400699317455\n",
      "epoch= 238 iteration= 11445 loss= 0.0005153403035365045\n",
      "epoch= 238 iteration= 11465 loss= 0.0007571808528155088\n",
      "test_data MSELoss:(pred-real)/real= 0.00017784631345421075\n",
      "epoch= 239 iteration= 11473 loss= 0.0011014925548806787\n",
      "epoch= 239 iteration= 11493 loss= 0.0005075685912743211\n",
      "epoch= 239 iteration= 11513 loss= 0.0007481823558919132\n",
      "test_data MSELoss:(pred-real)/real= 0.0001771269802702591\n",
      "epoch= 240 iteration= 11521 loss= 0.0010849355021491647\n",
      "epoch= 240 iteration= 11541 loss= 0.0004997761570848525\n",
      "epoch= 240 iteration= 11561 loss= 0.0007391656981781125\n",
      "test_data MSELoss:(pred-real)/real= 0.00017643121536821128\n",
      "epoch= 241 iteration= 11569 loss= 0.0010694023221731186\n",
      "epoch= 241 iteration= 11589 loss= 0.0004921387881040573\n",
      "epoch= 241 iteration= 11609 loss= 0.0007301028817892075\n",
      "test_data MSELoss:(pred-real)/real= 0.0001757735401042737\n",
      "epoch= 242 iteration= 11617 loss= 0.001055074972100556\n",
      "epoch= 242 iteration= 11637 loss= 0.00048449233872815967\n",
      "epoch= 242 iteration= 11657 loss= 0.000721267715562135\n",
      "test_data MSELoss:(pred-real)/real= 0.0001751329247781541\n",
      "epoch= 243 iteration= 11665 loss= 0.0010423469357192516\n",
      "epoch= 243 iteration= 11685 loss= 0.0004769464721903205\n",
      "epoch= 243 iteration= 11705 loss= 0.0007125770207494497\n",
      "test_data MSELoss:(pred-real)/real= 0.00017451184830861167\n",
      "epoch= 244 iteration= 11713 loss= 0.0010308846831321716\n",
      "epoch= 244 iteration= 11733 loss= 0.0004695438838098198\n",
      "epoch= 244 iteration= 11753 loss= 0.0007039497140794992\n",
      "test_data MSELoss:(pred-real)/real= 0.0001739301333145704\n",
      "epoch= 245 iteration= 11761 loss= 0.0010208087041974068\n",
      "epoch= 245 iteration= 11781 loss= 0.0004623545682989061\n",
      "epoch= 245 iteration= 11801 loss= 0.0006956825964152813\n",
      "test_data MSELoss:(pred-real)/real= 0.00017337782701360994\n",
      "epoch= 246 iteration= 11809 loss= 0.0010123108513653278\n",
      "epoch= 246 iteration= 11829 loss= 0.0004551862657535821\n",
      "epoch= 246 iteration= 11849 loss= 0.0006876250263303518\n",
      "test_data MSELoss:(pred-real)/real= 0.0001728318144159857\n",
      "epoch= 247 iteration= 11857 loss= 0.0010052213910967112\n",
      "epoch= 247 iteration= 11877 loss= 0.00044851526035927236\n",
      "epoch= 247 iteration= 11897 loss= 0.000679818622302264\n",
      "test_data MSELoss:(pred-real)/real= 0.00017231832680408843\n",
      "epoch= 248 iteration= 11905 loss= 0.0009992726845666766\n",
      "epoch= 248 iteration= 11925 loss= 0.0004418840690050274\n",
      "epoch= 248 iteration= 11945 loss= 0.0006720550009049475\n",
      "test_data MSELoss:(pred-real)/real= 0.00017184163443744182\n",
      "epoch= 249 iteration= 11953 loss= 0.000995066948235035\n",
      "epoch= 249 iteration= 11973 loss= 0.000435703550465405\n",
      "epoch= 249 iteration= 11993 loss= 0.0006647859700024128\n",
      "test_data MSELoss:(pred-real)/real= 0.00017138082475867122\n",
      "epoch= 250 iteration= 12001 loss= 0.0009914975380524993\n",
      "epoch= 250 iteration= 12021 loss= 0.0004296732950024307\n",
      "epoch= 250 iteration= 12041 loss= 0.0006577182793989778\n",
      "test_data MSELoss:(pred-real)/real= 0.0001709405652945861\n",
      "epoch= 251 iteration= 12049 loss= 0.000989008927717805\n",
      "epoch= 251 iteration= 12069 loss= 0.0004238674300722778\n",
      "epoch= 251 iteration= 12089 loss= 0.000650932954158634\n",
      "test_data MSELoss:(pred-real)/real= 0.00017053112824214623\n",
      "epoch= 252 iteration= 12097 loss= 0.0009873404633253813\n",
      "epoch= 252 iteration= 12117 loss= 0.00041834081639535725\n",
      "epoch= 252 iteration= 12137 loss= 0.0006442638696171343\n",
      "test_data MSELoss:(pred-real)/real= 0.00017013091055559926\n",
      "epoch= 253 iteration= 12145 loss= 0.000986183644272387\n",
      "epoch= 253 iteration= 12165 loss= 0.0004130517481826246\n",
      "epoch= 253 iteration= 12185 loss= 0.0006379177793860435\n",
      "test_data MSELoss:(pred-real)/real= 0.00016976893894025125\n",
      "epoch= 254 iteration= 12193 loss= 0.0009860917925834656\n",
      "epoch= 254 iteration= 12213 loss= 0.0004082256637047976\n",
      "epoch= 254 iteration= 12233 loss= 0.000631820410490036\n",
      "test_data MSELoss:(pred-real)/real= 0.00016940045898081735\n",
      "epoch= 255 iteration= 12241 loss= 0.0009858408011496067\n",
      "epoch= 255 iteration= 12261 loss= 0.00040351145435124636\n",
      "epoch= 255 iteration= 12281 loss= 0.0006257810164242983\n",
      "test_data MSELoss:(pred-real)/real= 0.00016907868775888345\n",
      "epoch= 256 iteration= 12289 loss= 0.0009861413855105639\n",
      "epoch= 256 iteration= 12309 loss= 0.00039900021511130035\n",
      "epoch= 256 iteration= 12329 loss= 0.0006199993658810854\n",
      "test_data MSELoss:(pred-real)/real= 0.0001687730004050536\n",
      "epoch= 257 iteration= 12337 loss= 0.0009866941254585981\n",
      "epoch= 257 iteration= 12357 loss= 0.0003948038211092353\n",
      "epoch= 257 iteration= 12377 loss= 0.0006145150400698185\n",
      "test_data MSELoss:(pred-real)/real= 0.00016847662736836356\n",
      "epoch= 258 iteration= 12385 loss= 0.0009873423259705305\n",
      "epoch= 258 iteration= 12405 loss= 0.00039053260115906596\n",
      "epoch= 258 iteration= 12425 loss= 0.0006089211674407125\n",
      "test_data MSELoss:(pred-real)/real= 0.00016822018296807072\n",
      "epoch= 259 iteration= 12433 loss= 0.0009880629368126392\n",
      "epoch= 259 iteration= 12453 loss= 0.00038668184424750507\n",
      "epoch= 259 iteration= 12473 loss= 0.0006035339320078492\n",
      "test_data MSELoss:(pred-real)/real= 0.00016795570372778456\n",
      "epoch= 260 iteration= 12481 loss= 0.0009892751695588231\n",
      "epoch= 260 iteration= 12501 loss= 0.0003829433408100158\n",
      "epoch= 260 iteration= 12521 loss= 0.0005983313894830644\n",
      "test_data MSELoss:(pred-real)/real= 0.00016773810966697056\n",
      "epoch= 261 iteration= 12529 loss= 0.0009902159217745066\n",
      "epoch= 261 iteration= 12549 loss= 0.00037919197347946465\n",
      "epoch= 261 iteration= 12569 loss= 0.0005929835606366396\n",
      "test_data MSELoss:(pred-real)/real= 0.00016753784657339566\n",
      "epoch= 262 iteration= 12577 loss= 0.0009913608664646745\n",
      "epoch= 262 iteration= 12597 loss= 0.00037560908822342753\n",
      "epoch= 262 iteration= 12617 loss= 0.0005879095988348126\n",
      "test_data MSELoss:(pred-real)/real= 0.00016734439632273279\n",
      "epoch= 263 iteration= 12625 loss= 0.0009926719358190894\n",
      "epoch= 263 iteration= 12645 loss= 0.0003724285343196243\n",
      "epoch= 263 iteration= 12665 loss= 0.0005828754510730505\n",
      "test_data MSELoss:(pred-real)/real= 0.00016721028732717967\n",
      "epoch= 264 iteration= 12673 loss= 0.000994304777123034\n",
      "epoch= 264 iteration= 12693 loss= 0.00036931270733475685\n",
      "epoch= 264 iteration= 12713 loss= 0.0005778652848675847\n",
      "test_data MSELoss:(pred-real)/real= 0.00016706332316971385\n",
      "epoch= 265 iteration= 12721 loss= 0.0009955749846994877\n",
      "epoch= 265 iteration= 12741 loss= 0.00036621210165321827\n",
      "epoch= 265 iteration= 12761 loss= 0.0005730273551307619\n",
      "test_data MSELoss:(pred-real)/real= 0.00016695725789759309\n",
      "epoch= 266 iteration= 12769 loss= 0.0009969919919967651\n",
      "epoch= 266 iteration= 12789 loss= 0.0003630092251114547\n",
      "epoch= 266 iteration= 12809 loss= 0.0005681230686604977\n",
      "test_data MSELoss:(pred-real)/real= 0.00016687473907950334\n",
      "epoch= 267 iteration= 12817 loss= 0.0009983050404116511\n",
      "epoch= 267 iteration= 12837 loss= 0.0003601328353397548\n",
      "epoch= 267 iteration= 12857 loss= 0.0005634672706946731\n",
      "test_data MSELoss:(pred-real)/real= 0.00016681150773365517\n",
      "epoch= 268 iteration= 12865 loss= 0.0009995963191613555\n",
      "epoch= 268 iteration= 12885 loss= 0.0003572732675820589\n",
      "epoch= 268 iteration= 12905 loss= 0.0005587803898379207\n",
      "test_data MSELoss:(pred-real)/real= 0.00016675520419084933\n",
      "epoch= 269 iteration= 12913 loss= 0.0010009858524426818\n",
      "epoch= 269 iteration= 12933 loss= 0.0003544783394318074\n",
      "epoch= 269 iteration= 12953 loss= 0.0005541497957892716\n",
      "test_data MSELoss:(pred-real)/real= 0.00016675148326612544\n",
      "epoch= 270 iteration= 12961 loss= 0.00100203906185925\n",
      "epoch= 270 iteration= 12981 loss= 0.00035200698766857386\n",
      "epoch= 270 iteration= 13001 loss= 0.0005495311925187707\n",
      "test_data MSELoss:(pred-real)/real= 0.0001667543241637759\n",
      "epoch= 271 iteration= 13009 loss= 0.001003484008833766\n",
      "epoch= 271 iteration= 13029 loss= 0.0003494124975986779\n",
      "epoch= 271 iteration= 13049 loss= 0.0005448560114018619\n",
      "test_data MSELoss:(pred-real)/real= 0.0001667893444391666\n",
      "epoch= 272 iteration= 13057 loss= 0.0010044816881418228\n",
      "epoch= 272 iteration= 13077 loss= 0.0003470057563390583\n",
      "epoch= 272 iteration= 13097 loss= 0.0005403873510658741\n",
      "test_data MSELoss:(pred-real)/real= 0.00016683717112755402\n",
      "epoch= 273 iteration= 13105 loss= 0.0010056820465251803\n",
      "epoch= 273 iteration= 13125 loss= 0.0003444560570642352\n",
      "epoch= 273 iteration= 13145 loss= 0.0005359667120501399\n",
      "test_data MSELoss:(pred-real)/real= 0.00016688848627381957\n",
      "epoch= 274 iteration= 13153 loss= 0.0010069281561300159\n",
      "epoch= 274 iteration= 13173 loss= 0.00034227027208544314\n",
      "epoch= 274 iteration= 13193 loss= 0.0005316016031429172\n",
      "test_data MSELoss:(pred-real)/real= 0.00016700259875506162\n",
      "epoch= 275 iteration= 13201 loss= 0.0010083317756652832\n",
      "epoch= 275 iteration= 13221 loss= 0.0003399825654923916\n",
      "epoch= 275 iteration= 13241 loss= 0.0005272970884107053\n",
      "test_data MSELoss:(pred-real)/real= 0.00016709439041733275\n",
      "epoch= 276 iteration= 13249 loss= 0.00100926891900599\n",
      "epoch= 276 iteration= 13269 loss= 0.0003379961126483977\n",
      "epoch= 276 iteration= 13289 loss= 0.0005230771494098008\n",
      "test_data MSELoss:(pred-real)/real= 0.00016722636828490068\n",
      "epoch= 277 iteration= 13297 loss= 0.0010109316790476441\n",
      "epoch= 277 iteration= 13317 loss= 0.0003359002876095474\n",
      "epoch= 277 iteration= 13337 loss= 0.0005190626252442598\n",
      "test_data MSELoss:(pred-real)/real= 0.00016738349986553658\n",
      "epoch= 278 iteration= 13345 loss= 0.0010118195787072182\n",
      "epoch= 278 iteration= 13365 loss= 0.00033395300852134824\n",
      "epoch= 278 iteration= 13385 loss= 0.0005148666095919907\n",
      "test_data MSELoss:(pred-real)/real= 0.00016752747833379545\n",
      "epoch= 279 iteration= 13393 loss= 0.0010124030523002148\n",
      "epoch= 279 iteration= 13413 loss= 0.00033192543196491897\n",
      "epoch= 279 iteration= 13433 loss= 0.0005108019686304033\n",
      "test_data MSELoss:(pred-real)/real= 0.00016768906607467216\n",
      "epoch= 280 iteration= 13441 loss= 0.0010136808268725872\n",
      "epoch= 280 iteration= 13461 loss= 0.0003301535325590521\n",
      "epoch= 280 iteration= 13481 loss= 0.0005069252219982445\n",
      "test_data MSELoss:(pred-real)/real= 0.00016788540669949726\n",
      "epoch= 281 iteration= 13489 loss= 0.0010147800203412771\n",
      "epoch= 281 iteration= 13509 loss= 0.0003282377729192376\n",
      "epoch= 281 iteration= 13529 loss= 0.0005028873565606773\n",
      "test_data MSELoss:(pred-real)/real= 0.00016808790132927243\n",
      "epoch= 282 iteration= 13537 loss= 0.001015572575852275\n",
      "epoch= 282 iteration= 13557 loss= 0.00032666264451108873\n",
      "epoch= 282 iteration= 13577 loss= 0.0004992001922801137\n",
      "test_data MSELoss:(pred-real)/real= 0.00016831085231387987\n",
      "epoch= 283 iteration= 13585 loss= 0.0010164567502215505\n",
      "epoch= 283 iteration= 13605 loss= 0.0003250077133998275\n",
      "epoch= 283 iteration= 13625 loss= 0.0004955014446750283\n",
      "test_data MSELoss:(pred-real)/real= 0.0001685154693404911\n",
      "epoch= 284 iteration= 13633 loss= 0.0010175923816859722\n",
      "epoch= 284 iteration= 13653 loss= 0.000323388259857893\n",
      "epoch= 284 iteration= 13673 loss= 0.000491756887640804\n",
      "test_data MSELoss:(pred-real)/real= 0.00016875533110578546\n",
      "epoch= 285 iteration= 13681 loss= 0.0010180312674492598\n",
      "epoch= 285 iteration= 13701 loss= 0.00032186953467316926\n",
      "epoch= 285 iteration= 13721 loss= 0.0004881281638517976\n",
      "test_data MSELoss:(pred-real)/real= 0.00016899333786568604\n",
      "epoch= 286 iteration= 13729 loss= 0.0010191056644544005\n",
      "epoch= 286 iteration= 13749 loss= 0.00032054202165454626\n",
      "epoch= 286 iteration= 13769 loss= 0.0004846531664952636\n",
      "test_data MSELoss:(pred-real)/real= 0.00016922589566092938\n",
      "epoch= 287 iteration= 13777 loss= 0.0010196140501648188\n",
      "epoch= 287 iteration= 13797 loss= 0.0003190967836417258\n",
      "epoch= 287 iteration= 13817 loss= 0.00048114877426996827\n",
      "test_data MSELoss:(pred-real)/real= 0.00016949574637692422\n",
      "epoch= 288 iteration= 13825 loss= 0.0010207558516412973\n",
      "epoch= 288 iteration= 13845 loss= 0.00031787491752766073\n",
      "epoch= 288 iteration= 13865 loss= 0.0004777202266268432\n",
      "test_data MSELoss:(pred-real)/real= 0.00016972547600744293\n",
      "epoch= 289 iteration= 13873 loss= 0.001021487289108336\n",
      "epoch= 289 iteration= 13893 loss= 0.00031663497793488204\n",
      "epoch= 289 iteration= 13913 loss= 0.0004746446502394974\n",
      "test_data MSELoss:(pred-real)/real= 0.00016999511390167755\n",
      "epoch= 290 iteration= 13921 loss= 0.0010224347934126854\n",
      "epoch= 290 iteration= 13941 loss= 0.0003154322621412575\n",
      "epoch= 290 iteration= 13961 loss= 0.0004713570815511048\n",
      "test_data MSELoss:(pred-real)/real= 0.00017024601402226835\n",
      "epoch= 291 iteration= 13969 loss= 0.001023010816425085\n",
      "epoch= 291 iteration= 13989 loss= 0.00031433190451934934\n",
      "epoch= 291 iteration= 14009 loss= 0.00046822038711979985\n",
      "test_data MSELoss:(pred-real)/real= 0.00017047597175405825\n",
      "epoch= 292 iteration= 14017 loss= 0.0010236992966383696\n",
      "epoch= 292 iteration= 14037 loss= 0.00031327339820563793\n",
      "epoch= 292 iteration= 14057 loss= 0.00046515846042893827\n",
      "test_data MSELoss:(pred-real)/real= 0.00017071659640350846\n",
      "epoch= 293 iteration= 14065 loss= 0.0010244883596897125\n",
      "epoch= 293 iteration= 14085 loss= 0.0003122471971437335\n",
      "epoch= 293 iteration= 14105 loss= 0.0004625252331607044\n",
      "test_data MSELoss:(pred-real)/real= 0.00017097894415201153\n",
      "epoch= 294 iteration= 14113 loss= 0.0010249034967273474\n",
      "epoch= 294 iteration= 14133 loss= 0.0003112942795269191\n",
      "epoch= 294 iteration= 14153 loss= 0.00045955402310937643\n",
      "test_data MSELoss:(pred-real)/real= 0.00017121319724537897\n",
      "epoch= 295 iteration= 14161 loss= 0.0010252578649669886\n",
      "epoch= 295 iteration= 14181 loss= 0.00031037558801472187\n",
      "epoch= 295 iteration= 14201 loss= 0.00045662137563340366\n",
      "test_data MSELoss:(pred-real)/real= 0.00017143568584288005\n",
      "epoch= 296 iteration= 14209 loss= 0.0010261540301144123\n",
      "epoch= 296 iteration= 14229 loss= 0.0003097066073678434\n",
      "epoch= 296 iteration= 14249 loss= 0.00045399030204862356\n",
      "test_data MSELoss:(pred-real)/real= 0.00017168540252896492\n",
      "epoch= 297 iteration= 14257 loss= 0.0010265496093779802\n",
      "epoch= 297 iteration= 14277 loss= 0.0003087729273829609\n",
      "epoch= 297 iteration= 14297 loss= 0.0004514037282206118\n",
      "test_data MSELoss:(pred-real)/real= 0.00017190801663673482\n",
      "epoch= 298 iteration= 14305 loss= 0.0010274174856022\n",
      "epoch= 298 iteration= 14325 loss= 0.0003080923925153911\n",
      "epoch= 298 iteration= 14345 loss= 0.0004489014681894332\n",
      "test_data MSELoss:(pred-real)/real= 0.00017210992591571995\n",
      "epoch= 299 iteration= 14353 loss= 0.0010276900138705969\n",
      "epoch= 299 iteration= 14373 loss= 0.0003073389525525272\n",
      "epoch= 299 iteration= 14393 loss= 0.00044629344483837485\n",
      "test_data MSELoss:(pred-real)/real= 0.00017231519559572915\n",
      "epoch= 300 iteration= 14401 loss= 0.0010285680182278156\n",
      "epoch= 300 iteration= 14421 loss= 0.0003068512596655637\n",
      "epoch= 300 iteration= 14441 loss= 0.00044379528844729066\n",
      "test_data MSELoss:(pred-real)/real= 0.00017252712168556173\n",
      "epoch= 301 iteration= 14449 loss= 0.001028913538902998\n",
      "epoch= 301 iteration= 14469 loss= 0.0003060199087485671\n",
      "epoch= 301 iteration= 14489 loss= 0.0004414315626490861\n",
      "test_data MSELoss:(pred-real)/real= 0.00017271451106353196\n",
      "epoch= 302 iteration= 14497 loss= 0.0010293656960129738\n",
      "epoch= 302 iteration= 14517 loss= 0.00030551140662282705\n",
      "epoch= 302 iteration= 14537 loss= 0.00043923966586589813\n",
      "test_data MSELoss:(pred-real)/real= 0.00017289367206103635\n",
      "epoch= 303 iteration= 14545 loss= 0.0010298313573002815\n",
      "epoch= 303 iteration= 14565 loss= 0.0003049300576094538\n",
      "epoch= 303 iteration= 14585 loss= 0.0004368943627923727\n",
      "test_data MSELoss:(pred-real)/real= 0.00017307032867392992\n",
      "epoch= 304 iteration= 14593 loss= 0.0010304789757356048\n",
      "epoch= 304 iteration= 14613 loss= 0.00030440668342635036\n",
      "epoch= 304 iteration= 14633 loss= 0.0004348991787992418\n",
      "test_data MSELoss:(pred-real)/real= 0.00017322934982075822\n",
      "epoch= 305 iteration= 14641 loss= 0.0010314520914107561\n",
      "epoch= 305 iteration= 14661 loss= 0.00030387763399630785\n",
      "epoch= 305 iteration= 14681 loss= 0.0004328397335484624\n",
      "test_data MSELoss:(pred-real)/real= 0.00017338172438030597\n",
      "epoch= 306 iteration= 14689 loss= 0.0010313435923308134\n",
      "epoch= 306 iteration= 14709 loss= 0.00030335015617311\n",
      "epoch= 306 iteration= 14729 loss= 0.00043062801705673337\n",
      "test_data MSELoss:(pred-real)/real= 0.00017350246198475361\n",
      "epoch= 307 iteration= 14737 loss= 0.001031806692481041\n",
      "epoch= 307 iteration= 14757 loss= 0.00030295728356577456\n",
      "epoch= 307 iteration= 14777 loss= 0.0004287164774723351\n",
      "test_data MSELoss:(pred-real)/real= 0.00017360652309434955\n",
      "epoch= 308 iteration= 14785 loss= 0.0010320469737052917\n",
      "epoch= 308 iteration= 14805 loss= 0.00030231723212637007\n",
      "epoch= 308 iteration= 14825 loss= 0.00042678724275901914\n",
      "test_data MSELoss:(pred-real)/real= 0.00017370817477058154\n",
      "epoch= 309 iteration= 14833 loss= 0.001032083760946989\n",
      "epoch= 309 iteration= 14853 loss= 0.00030195488943718374\n",
      "epoch= 309 iteration= 14873 loss= 0.00042502692667767406\n",
      "test_data MSELoss:(pred-real)/real= 0.0001738320443109842\n",
      "epoch= 310 iteration= 14881 loss= 0.001032014493830502\n",
      "epoch= 310 iteration= 14901 loss= 0.00030156358843669295\n",
      "epoch= 310 iteration= 14921 loss= 0.00042325540562160313\n",
      "test_data MSELoss:(pred-real)/real= 0.00017393000744050368\n",
      "epoch= 311 iteration= 14929 loss= 0.0010316907428205013\n",
      "epoch= 311 iteration= 14949 loss= 0.0003011799999512732\n",
      "epoch= 311 iteration= 14969 loss= 0.0004214610089547932\n",
      "test_data MSELoss:(pred-real)/real= 0.0001739980547426967\n",
      "epoch= 312 iteration= 14977 loss= 0.0010316515108570457\n",
      "epoch= 312 iteration= 14997 loss= 0.00030073412926867604\n",
      "epoch= 312 iteration= 15017 loss= 0.00041975214844569564\n",
      "test_data MSELoss:(pred-real)/real= 0.000174103843892226\n",
      "epoch= 313 iteration= 15025 loss= 0.001031719846650958\n",
      "epoch= 313 iteration= 15045 loss= 0.0003003992314916104\n",
      "epoch= 313 iteration= 15065 loss= 0.00041812658309936523\n",
      "test_data MSELoss:(pred-real)/real= 0.0001741381511237705\n",
      "epoch= 314 iteration= 15073 loss= 0.0010313288075849414\n",
      "epoch= 314 iteration= 15093 loss= 0.0003000797296408564\n",
      "epoch= 314 iteration= 15113 loss= 0.0004164654528722167\n",
      "test_data MSELoss:(pred-real)/real= 0.00017423060708097183\n",
      "epoch= 315 iteration= 15121 loss= 0.0010312225203961134\n",
      "epoch= 315 iteration= 15141 loss= 0.0002999486750923097\n",
      "epoch= 315 iteration= 15161 loss= 0.0004149340093135834\n",
      "test_data MSELoss:(pred-real)/real= 0.00017423516837880015\n",
      "epoch= 316 iteration= 15169 loss= 0.0010312080848962069\n",
      "epoch= 316 iteration= 15189 loss= 0.00029969477327540517\n",
      "epoch= 316 iteration= 15209 loss= 0.00041337317088618875\n",
      "test_data MSELoss:(pred-real)/real= 0.00017428478458896278\n",
      "epoch= 317 iteration= 15217 loss= 0.001030732411891222\n",
      "epoch= 317 iteration= 15237 loss= 0.000299353851005435\n",
      "epoch= 317 iteration= 15257 loss= 0.0004120529047213495\n",
      "test_data MSELoss:(pred-real)/real= 0.00017429293402528855\n",
      "epoch= 318 iteration= 15265 loss= 0.001030498999170959\n",
      "epoch= 318 iteration= 15285 loss= 0.0002992195077240467\n",
      "epoch= 318 iteration= 15305 loss= 0.00041057835915125906\n",
      "test_data MSELoss:(pred-real)/real= 0.00017430940642952918\n",
      "epoch= 319 iteration= 15313 loss= 0.0010301679139956832\n",
      "epoch= 319 iteration= 15333 loss= 0.0002989764616359025\n",
      "epoch= 319 iteration= 15353 loss= 0.0004091619048267603\n",
      "test_data MSELoss:(pred-real)/real= 0.00017430489315302112\n",
      "epoch= 320 iteration= 15361 loss= 0.0010300286812707782\n",
      "epoch= 320 iteration= 15381 loss= 0.0002988889464177191\n",
      "epoch= 320 iteration= 15401 loss= 0.0004075984179507941\n",
      "test_data MSELoss:(pred-real)/real= 0.00017431429660064168\n",
      "epoch= 321 iteration= 15409 loss= 0.001029321807436645\n",
      "epoch= 321 iteration= 15429 loss= 0.00029877061024308205\n",
      "epoch= 321 iteration= 15449 loss= 0.00040629791328683496\n",
      "test_data MSELoss:(pred-real)/real= 0.00017428002174710855\n",
      "epoch= 322 iteration= 15457 loss= 0.0010292766382917762\n",
      "epoch= 322 iteration= 15477 loss= 0.0002986722975037992\n",
      "epoch= 322 iteration= 15497 loss= 0.0004049362032674253\n",
      "test_data MSELoss:(pred-real)/real= 0.00017425673249817918\n",
      "epoch= 323 iteration= 15505 loss= 0.001028696307912469\n",
      "epoch= 323 iteration= 15525 loss= 0.00029859249480068684\n",
      "epoch= 323 iteration= 15545 loss= 0.00040370807982981205\n",
      "test_data MSELoss:(pred-real)/real= 0.00017429863291908986\n",
      "epoch= 324 iteration= 15553 loss= 0.0010280914139002562\n",
      "epoch= 324 iteration= 15573 loss= 0.0002984405728057027\n",
      "epoch= 324 iteration= 15593 loss= 0.0004024595255032182\n",
      "test_data MSELoss:(pred-real)/real= 0.00017423014614905696\n",
      "epoch= 325 iteration= 15601 loss= 0.0010274022351950407\n",
      "epoch= 325 iteration= 15621 loss= 0.0002983713638968766\n",
      "epoch= 325 iteration= 15641 loss= 0.00040110404370352626\n",
      "test_data MSELoss:(pred-real)/real= 0.00017416449081792963\n",
      "epoch= 326 iteration= 15649 loss= 0.0010267321486026049\n",
      "epoch= 326 iteration= 15669 loss= 0.000298240571282804\n",
      "epoch= 326 iteration= 15689 loss= 0.00039988948265090585\n",
      "test_data MSELoss:(pred-real)/real= 0.000174116756170406\n",
      "epoch= 327 iteration= 15697 loss= 0.0010259703267365694\n",
      "epoch= 327 iteration= 15717 loss= 0.0002981576253660023\n",
      "epoch= 327 iteration= 15737 loss= 0.0003987866803072393\n",
      "test_data MSELoss:(pred-real)/real= 0.00017407217164873147\n",
      "epoch= 328 iteration= 15745 loss= 0.0010251300409436226\n",
      "epoch= 328 iteration= 15765 loss= 0.00029815989546477795\n",
      "epoch= 328 iteration= 15785 loss= 0.0003975211293436587\n",
      "test_data MSELoss:(pred-real)/real= 0.00017401304030499886\n",
      "epoch= 329 iteration= 15793 loss= 0.0010244410950690508\n",
      "epoch= 329 iteration= 15813 loss= 0.00029816548340022564\n",
      "epoch= 329 iteration= 15833 loss= 0.00039621646283194423\n",
      "test_data MSELoss:(pred-real)/real= 0.00017393558700860013\n",
      "epoch= 330 iteration= 15841 loss= 0.0010236033704131842\n",
      "epoch= 330 iteration= 15861 loss= 0.00029817302129231393\n",
      "epoch= 330 iteration= 15881 loss= 0.0003954162239097059\n",
      "test_data MSELoss:(pred-real)/real= 0.00017386767431162297\n",
      "epoch= 331 iteration= 15889 loss= 0.0010224598227068782\n",
      "epoch= 331 iteration= 15909 loss= 0.0002982787846121937\n",
      "epoch= 331 iteration= 15929 loss= 0.0003941530594602227\n",
      "test_data MSELoss:(pred-real)/real= 0.00017380969948135316\n",
      "epoch= 332 iteration= 15937 loss= 0.0010214158101007342\n",
      "epoch= 332 iteration= 15957 loss= 0.00029828707920387387\n",
      "epoch= 332 iteration= 15977 loss= 0.00039312103763222694\n",
      "test_data MSELoss:(pred-real)/real= 0.00017374173221469392\n",
      "epoch= 333 iteration= 15985 loss= 0.0010203116107732058\n",
      "epoch= 333 iteration= 16005 loss= 0.00029840279603376985\n",
      "epoch= 333 iteration= 16025 loss= 0.00039176474092528224\n",
      "test_data MSELoss:(pred-real)/real= 0.00017363444312650244\n",
      "epoch= 334 iteration= 16033 loss= 0.00101901451125741\n",
      "epoch= 334 iteration= 16053 loss= 0.00029851103317923844\n",
      "epoch= 334 iteration= 16073 loss= 0.00039088146877475083\n",
      "test_data MSELoss:(pred-real)/real= 0.0001735413923597662\n",
      "epoch= 335 iteration= 16081 loss= 0.0010174622293561697\n",
      "epoch= 335 iteration= 16101 loss= 0.0002985866740345955\n",
      "epoch= 335 iteration= 16121 loss= 0.0003896514535881579\n",
      "test_data MSELoss:(pred-real)/real= 0.0001734158424369525\n",
      "epoch= 336 iteration= 16129 loss= 0.0010167546570301056\n",
      "epoch= 336 iteration= 16149 loss= 0.0002988440392073244\n",
      "epoch= 336 iteration= 16169 loss= 0.00038863063673488796\n",
      "test_data MSELoss:(pred-real)/real= 0.00017334323420072905\n",
      "epoch= 337 iteration= 16177 loss= 0.0010155737400054932\n",
      "epoch= 337 iteration= 16197 loss= 0.00029911796445958316\n",
      "epoch= 337 iteration= 16217 loss= 0.0003873605455737561\n",
      "test_data MSELoss:(pred-real)/real= 0.00017321707236988003\n",
      "epoch= 338 iteration= 16225 loss= 0.0010144959669560194\n",
      "epoch= 338 iteration= 16245 loss= 0.00029935690690763295\n",
      "epoch= 338 iteration= 16265 loss= 0.0003863283200189471\n",
      "test_data MSELoss:(pred-real)/real= 0.0001731378044496523\n",
      "epoch= 339 iteration= 16273 loss= 0.0010138158686459064\n",
      "epoch= 339 iteration= 16293 loss= 0.000299543549772352\n",
      "epoch= 339 iteration= 16313 loss= 0.0003851793590001762\n",
      "test_data MSELoss:(pred-real)/real= 0.00017301325642620212\n",
      "epoch= 340 iteration= 16321 loss= 0.0010127112036570907\n",
      "epoch= 340 iteration= 16341 loss= 0.000299972016364336\n",
      "epoch= 340 iteration= 16361 loss= 0.0003841865109279752\n",
      "test_data MSELoss:(pred-real)/real= 0.0001729199037072249\n",
      "epoch= 341 iteration= 16369 loss= 0.0010119430953636765\n",
      "epoch= 341 iteration= 16389 loss= 0.0003002200974151492\n",
      "epoch= 341 iteration= 16409 loss= 0.0003831787616945803\n",
      "test_data MSELoss:(pred-real)/real= 0.00017280928950640372\n",
      "epoch= 342 iteration= 16417 loss= 0.0010103806853294373\n",
      "epoch= 342 iteration= 16437 loss= 0.0003004251921083778\n",
      "epoch= 342 iteration= 16457 loss= 0.0003819854464381933\n",
      "test_data MSELoss:(pred-real)/real= 0.0001726780268654693\n",
      "epoch= 343 iteration= 16465 loss= 0.0010094392346218228\n",
      "epoch= 343 iteration= 16485 loss= 0.00030066323233768344\n",
      "epoch= 343 iteration= 16505 loss= 0.00038102298276498914\n",
      "test_data MSELoss:(pred-real)/real= 0.0001725653164612595\n",
      "epoch= 344 iteration= 16513 loss= 0.0010080384090542793\n",
      "epoch= 344 iteration= 16533 loss= 0.0003010735963471234\n",
      "epoch= 344 iteration= 16553 loss= 0.00037981854984536767\n",
      "test_data MSELoss:(pred-real)/real= 0.00017246590614377054\n",
      "epoch= 345 iteration= 16561 loss= 0.001007001381367445\n",
      "epoch= 345 iteration= 16581 loss= 0.0003013468813151121\n",
      "epoch= 345 iteration= 16601 loss= 0.00037885812344029546\n",
      "test_data MSELoss:(pred-real)/real= 0.00017235217928828205\n",
      "epoch= 346 iteration= 16609 loss= 0.0010055992752313614\n",
      "epoch= 346 iteration= 16629 loss= 0.0003017937997356057\n",
      "epoch= 346 iteration= 16649 loss= 0.0003777267411351204\n",
      "test_data MSELoss:(pred-real)/real= 0.00017219156252394895\n",
      "epoch= 347 iteration= 16657 loss= 0.0010041147470474243\n",
      "epoch= 347 iteration= 16677 loss= 0.00030211146804504097\n",
      "epoch= 347 iteration= 16697 loss= 0.00037685700226575136\n",
      "test_data MSELoss:(pred-real)/real= 0.0001720465977996355\n",
      "epoch= 348 iteration= 16705 loss= 0.0010029395343735814\n",
      "epoch= 348 iteration= 16725 loss= 0.00030242381035350263\n",
      "epoch= 348 iteration= 16745 loss= 0.0003758265229407698\n",
      "test_data MSELoss:(pred-real)/real= 0.0001719462510664016\n",
      "epoch= 349 iteration= 16753 loss= 0.001001065829768777\n",
      "epoch= 349 iteration= 16773 loss= 0.00030276054167188704\n",
      "epoch= 349 iteration= 16793 loss= 0.0003747014852706343\n",
      "test_data MSELoss:(pred-real)/real= 0.00017180094437208027\n",
      "epoch= 350 iteration= 16801 loss= 0.0009994435822591186\n",
      "epoch= 350 iteration= 16821 loss= 0.0003031622327398509\n",
      "epoch= 350 iteration= 16841 loss= 0.00037377403350546956\n",
      "test_data MSELoss:(pred-real)/real= 0.00017165247809316497\n",
      "epoch= 351 iteration= 16849 loss= 0.0009979975875467062\n",
      "epoch= 351 iteration= 16869 loss= 0.000303664623061195\n",
      "epoch= 351 iteration= 16889 loss= 0.00037283351412042975\n",
      "test_data MSELoss:(pred-real)/real= 0.000171516959744622\n",
      "epoch= 352 iteration= 16897 loss= 0.0009964276105165482\n",
      "epoch= 352 iteration= 16917 loss= 0.0003041388699784875\n",
      "epoch= 352 iteration= 16937 loss= 0.00037159002386033535\n",
      "test_data MSELoss:(pred-real)/real= 0.00017135666603280698\n",
      "epoch= 353 iteration= 16945 loss= 0.0009948592633008957\n",
      "epoch= 353 iteration= 16965 loss= 0.0003046429774258286\n",
      "epoch= 353 iteration= 16985 loss= 0.00037040424649603665\n",
      "test_data MSELoss:(pred-real)/real= 0.0001712020835839212\n",
      "epoch= 354 iteration= 16993 loss= 0.0009934339905157685\n",
      "epoch= 354 iteration= 17013 loss= 0.0003052685933653265\n",
      "epoch= 354 iteration= 17033 loss= 0.0003695240884553641\n",
      "test_data MSELoss:(pred-real)/real= 0.00017108381289290264\n",
      "epoch= 355 iteration= 17041 loss= 0.0009917686693370342\n",
      "epoch= 355 iteration= 17061 loss= 0.00030590742244385183\n",
      "epoch= 355 iteration= 17081 loss= 0.0003684585099108517\n",
      "test_data MSELoss:(pred-real)/real= 0.0001709047210169956\n",
      "epoch= 356 iteration= 17089 loss= 0.0009899557335302234\n",
      "epoch= 356 iteration= 17109 loss= 0.0003066326607950032\n",
      "epoch= 356 iteration= 17129 loss= 0.00036756362533196807\n",
      "test_data MSELoss:(pred-real)/real= 0.00017074063616746572\n",
      "epoch= 357 iteration= 17137 loss= 0.0009883638704195619\n",
      "epoch= 357 iteration= 17157 loss= 0.0003072115359827876\n",
      "epoch= 357 iteration= 17177 loss= 0.00036640226608142257\n",
      "test_data MSELoss:(pred-real)/real= 0.00017063184714061208\n",
      "epoch= 358 iteration= 17185 loss= 0.0009868342895060778\n",
      "epoch= 358 iteration= 17205 loss= 0.00030805301503278315\n",
      "epoch= 358 iteration= 17225 loss= 0.0003652959130704403\n",
      "test_data MSELoss:(pred-real)/real= 0.00017049263879016509\n",
      "epoch= 359 iteration= 17233 loss= 0.0009847565088421106\n",
      "epoch= 359 iteration= 17253 loss= 0.00030884789885021746\n",
      "epoch= 359 iteration= 17273 loss= 0.00036426499718800187\n",
      "test_data MSELoss:(pred-real)/real= 0.00017032828982337377\n",
      "epoch= 360 iteration= 17281 loss= 0.0009835594100877643\n",
      "epoch= 360 iteration= 17301 loss= 0.0003097585286013782\n",
      "epoch= 360 iteration= 17321 loss= 0.0003631901345215738\n",
      "test_data MSELoss:(pred-real)/real= 0.00017015710654959547\n",
      "epoch= 361 iteration= 17329 loss= 0.0009821730200201273\n",
      "epoch= 361 iteration= 17349 loss= 0.0003107344382442534\n",
      "epoch= 361 iteration= 17369 loss= 0.00036214315332472324\n",
      "test_data MSELoss:(pred-real)/real= 0.0001700265671388479\n",
      "epoch= 362 iteration= 17377 loss= 0.0009804299334064126\n",
      "epoch= 362 iteration= 17397 loss= 0.0003117501619271934\n",
      "epoch= 362 iteration= 17417 loss= 0.00036113211535848677\n",
      "test_data MSELoss:(pred-real)/real= 0.00016986028786050155\n",
      "epoch= 363 iteration= 17425 loss= 0.000979075557552278\n",
      "epoch= 363 iteration= 17445 loss= 0.00031280587427318096\n",
      "epoch= 363 iteration= 17465 loss= 0.0003598867915570736\n",
      "test_data MSELoss:(pred-real)/real= 0.00016968479030765593\n",
      "epoch= 364 iteration= 17473 loss= 0.0009777970844879746\n",
      "epoch= 364 iteration= 17493 loss= 0.0003138689207844436\n",
      "epoch= 364 iteration= 17513 loss= 0.0003591628628782928\n",
      "test_data MSELoss:(pred-real)/real= 0.00016954577877186238\n",
      "epoch= 365 iteration= 17521 loss= 0.0009759693057276309\n",
      "epoch= 365 iteration= 17541 loss= 0.0003149357798974961\n",
      "epoch= 365 iteration= 17561 loss= 0.0003581423661671579\n",
      "test_data MSELoss:(pred-real)/real= 0.0001693968806648627\n",
      "epoch= 366 iteration= 17569 loss= 0.0009744857670739293\n",
      "epoch= 366 iteration= 17589 loss= 0.0003160337219014764\n",
      "epoch= 366 iteration= 17609 loss= 0.00035702131572179496\n",
      "test_data MSELoss:(pred-real)/real= 0.00016925567979342304\n",
      "epoch= 367 iteration= 17617 loss= 0.0009727369761094451\n",
      "epoch= 367 iteration= 17637 loss= 0.0003173062577843666\n",
      "epoch= 367 iteration= 17657 loss= 0.00035593946813605726\n",
      "test_data MSELoss:(pred-real)/real= 0.00016907734752749092\n",
      "epoch= 368 iteration= 17665 loss= 0.0009706897544674575\n",
      "epoch= 368 iteration= 17685 loss= 0.0003185013774782419\n",
      "epoch= 368 iteration= 17705 loss= 0.0003551289555616677\n",
      "test_data MSELoss:(pred-real)/real= 0.00016891556442715227\n",
      "epoch= 369 iteration= 17713 loss= 0.0009691673330962658\n",
      "epoch= 369 iteration= 17733 loss= 0.0003200364881195128\n",
      "epoch= 369 iteration= 17753 loss= 0.00035409387783147395\n",
      "test_data MSELoss:(pred-real)/real= 0.00016875737019290683\n",
      "epoch= 370 iteration= 17761 loss= 0.0009673732565715909\n",
      "epoch= 370 iteration= 17781 loss= 0.0003214312018826604\n",
      "epoch= 370 iteration= 17801 loss= 0.000353019597241655\n",
      "test_data MSELoss:(pred-real)/real= 0.00016861708863871172\n",
      "epoch= 371 iteration= 17809 loss= 0.0009656311012804508\n",
      "epoch= 371 iteration= 17829 loss= 0.0003229703288525343\n",
      "epoch= 371 iteration= 17849 loss= 0.00035201027640141547\n",
      "test_data MSELoss:(pred-real)/real= 0.00016844757410581224\n",
      "epoch= 372 iteration= 17857 loss= 0.0009643377270549536\n",
      "epoch= 372 iteration= 17877 loss= 0.0003248663851991296\n",
      "epoch= 372 iteration= 17897 loss= 0.0003512416733428836\n",
      "test_data MSELoss:(pred-real)/real= 0.000168257436962449\n",
      "epoch= 373 iteration= 17905 loss= 0.0009619268821552396\n",
      "epoch= 373 iteration= 17925 loss= 0.0003264301049057394\n",
      "epoch= 373 iteration= 17945 loss= 0.00035033770836889744\n",
      "test_data MSELoss:(pred-real)/real= 0.00016808470427349677\n",
      "epoch= 374 iteration= 17953 loss= 0.0009600783814676106\n",
      "epoch= 374 iteration= 17973 loss= 0.0003279389929957688\n",
      "epoch= 374 iteration= 17993 loss= 0.0003495182318147272\n",
      "test_data MSELoss:(pred-real)/real= 0.00016789692053862382\n",
      "epoch= 375 iteration= 18001 loss= 0.0009579129982739687\n",
      "epoch= 375 iteration= 18021 loss= 0.0003300101088825613\n",
      "epoch= 375 iteration= 18041 loss= 0.00034873801632784307\n",
      "test_data MSELoss:(pred-real)/real= 0.0001677030450082384\n",
      "epoch= 376 iteration= 18049 loss= 0.0009555690921843052\n",
      "epoch= 376 iteration= 18069 loss= 0.00033219472970813513\n",
      "epoch= 376 iteration= 18089 loss= 0.00034782668808475137\n",
      "test_data MSELoss:(pred-real)/real= 0.00016752367118897383\n",
      "epoch= 377 iteration= 18097 loss= 0.0009535387507639825\n",
      "epoch= 377 iteration= 18117 loss= 0.0003345021395944059\n",
      "epoch= 377 iteration= 18137 loss= 0.0003470108495093882\n",
      "test_data MSELoss:(pred-real)/real= 0.00016726392350392417\n",
      "epoch= 378 iteration= 18145 loss= 0.0009514426346868277\n",
      "epoch= 378 iteration= 18165 loss= 0.0003372406354174018\n",
      "epoch= 378 iteration= 18185 loss= 0.0003462342428974807\n",
      "test_data MSELoss:(pred-real)/real= 0.00016702809552953112\n",
      "epoch= 379 iteration= 18193 loss= 0.0009493043180555105\n",
      "epoch= 379 iteration= 18213 loss= 0.00034012109972536564\n",
      "epoch= 379 iteration= 18233 loss= 0.00034534448059275746\n",
      "test_data MSELoss:(pred-real)/real= 0.0001668128476012498\n",
      "epoch= 380 iteration= 18241 loss= 0.0009471728699281812\n",
      "epoch= 380 iteration= 18261 loss= 0.0003436898114159703\n",
      "epoch= 380 iteration= 18281 loss= 0.00034447063808329403\n",
      "test_data MSELoss:(pred-real)/real= 0.00016659699140291194\n",
      "epoch= 381 iteration= 18289 loss= 0.0009449682547710836\n",
      "epoch= 381 iteration= 18309 loss= 0.00034754900843836367\n",
      "epoch= 381 iteration= 18329 loss= 0.0003438648418523371\n",
      "test_data MSELoss:(pred-real)/real= 0.00016633609666314442\n",
      "epoch= 382 iteration= 18337 loss= 0.0009430792997591197\n",
      "epoch= 382 iteration= 18357 loss= 0.0003522902261465788\n",
      "epoch= 382 iteration= 18377 loss= 0.00034298410173505545\n",
      "test_data MSELoss:(pred-real)/real= 0.00016608576115686446\n",
      "epoch= 383 iteration= 18385 loss= 0.0009413845255039632\n",
      "epoch= 383 iteration= 18405 loss= 0.0003573622088879347\n",
      "epoch= 383 iteration= 18425 loss= 0.0003423729503992945\n",
      "test_data MSELoss:(pred-real)/real= 0.00016585387784289195\n",
      "epoch= 384 iteration= 18433 loss= 0.0009397614048793912\n",
      "epoch= 384 iteration= 18453 loss= 0.00036302339867688715\n",
      "epoch= 384 iteration= 18473 loss= 0.0003415844985283911\n",
      "test_data MSELoss:(pred-real)/real= 0.00016561869670113084\n",
      "epoch= 385 iteration= 18481 loss= 0.0009381911950185895\n",
      "epoch= 385 iteration= 18501 loss= 0.0003689416917040944\n",
      "epoch= 385 iteration= 18521 loss= 0.00034114846494048834\n",
      "test_data MSELoss:(pred-real)/real= 0.00016539878561161458\n",
      "epoch= 386 iteration= 18529 loss= 0.0009374173823744059\n",
      "epoch= 386 iteration= 18549 loss= 0.00037508030072785914\n",
      "epoch= 386 iteration= 18569 loss= 0.0003405244497116655\n",
      "test_data MSELoss:(pred-real)/real= 0.0001651688842684962\n",
      "epoch= 387 iteration= 18577 loss= 0.0009360846597701311\n",
      "epoch= 387 iteration= 18597 loss= 0.00038115098141133785\n",
      "epoch= 387 iteration= 18617 loss= 0.00033990858355537057\n",
      "test_data MSELoss:(pred-real)/real= 0.00016499314624525142\n",
      "epoch= 388 iteration= 18625 loss= 0.0009352655033580959\n",
      "epoch= 388 iteration= 18645 loss= 0.00038710623630322516\n",
      "epoch= 388 iteration= 18665 loss= 0.0003393004590179771\n",
      "test_data MSELoss:(pred-real)/real= 0.0001648393772484269\n",
      "epoch= 389 iteration= 18673 loss= 0.0009343582205474377\n",
      "epoch= 389 iteration= 18693 loss= 0.0003920860181096941\n",
      "epoch= 389 iteration= 18713 loss= 0.0003387451288290322\n",
      "test_data MSELoss:(pred-real)/real= 0.0001647767894610297\n",
      "epoch= 390 iteration= 18721 loss= 0.0009340624674223363\n",
      "epoch= 390 iteration= 18741 loss= 0.00039620278403162956\n",
      "epoch= 390 iteration= 18761 loss= 0.0003380041162017733\n",
      "test_data MSELoss:(pred-real)/real= 0.00016481756792927627\n",
      "epoch= 391 iteration= 18769 loss= 0.0009339082753285766\n",
      "epoch= 391 iteration= 18789 loss= 0.0003987374366261065\n",
      "epoch= 391 iteration= 18809 loss= 0.0003372896171640605\n",
      "test_data MSELoss:(pred-real)/real= 0.00016500185884069652\n",
      "epoch= 392 iteration= 18817 loss= 0.0009339090902358294\n",
      "epoch= 392 iteration= 18837 loss= 0.0004001686756964773\n",
      "epoch= 392 iteration= 18857 loss= 0.00033622252522036433\n",
      "test_data MSELoss:(pred-real)/real= 0.00016530590364709495\n",
      "epoch= 393 iteration= 18865 loss= 0.0009346056031063199\n",
      "epoch= 393 iteration= 18885 loss= 0.00039999480941332877\n",
      "epoch= 393 iteration= 18905 loss= 0.0003351359046064317\n",
      "test_data MSELoss:(pred-real)/real= 0.0001658686946029775\n",
      "epoch= 394 iteration= 18913 loss= 0.0009356167283840477\n",
      "epoch= 394 iteration= 18933 loss= 0.00039784208638593554\n",
      "epoch= 394 iteration= 18953 loss= 0.00033352908212691545\n",
      "test_data MSELoss:(pred-real)/real= 0.00016672429264872335\n",
      "epoch= 395 iteration= 18961 loss= 0.0009369236649945378\n",
      "epoch= 395 iteration= 18981 loss= 0.00039401830872520804\n",
      "epoch= 395 iteration= 19001 loss= 0.00033236679155379534\n",
      "test_data MSELoss:(pred-real)/real= 0.00016787663553259337\n",
      "epoch= 396 iteration= 19009 loss= 0.0009391845669597387\n",
      "epoch= 396 iteration= 19029 loss= 0.00038868680712766945\n",
      "epoch= 396 iteration= 19049 loss= 0.00033054762752726674\n",
      "test_data MSELoss:(pred-real)/real= 0.0001691858316917205\n",
      "epoch= 397 iteration= 19057 loss= 0.0009425205644220114\n",
      "epoch= 397 iteration= 19077 loss= 0.00038141635013744235\n",
      "epoch= 397 iteration= 19097 loss= 0.000328858382999897\n",
      "test_data MSELoss:(pred-real)/real= 0.00017078621676773763\n",
      "epoch= 398 iteration= 19105 loss= 0.0009467940544709563\n",
      "epoch= 398 iteration= 19125 loss= 0.00037267731386236846\n",
      "epoch= 398 iteration= 19145 loss= 0.00032692731474526227\n",
      "test_data MSELoss:(pred-real)/real= 0.00017240236084035133\n",
      "epoch= 399 iteration= 19153 loss= 0.0009524131892248988\n",
      "epoch= 399 iteration= 19173 loss= 0.0003626659163273871\n",
      "epoch= 399 iteration= 19193 loss= 0.0003251951711717993\n",
      "test_data MSELoss:(pred-real)/real= 0.00017412437009625136\n",
      "epoch= 400 iteration= 19201 loss= 0.000958171091042459\n",
      "epoch= 400 iteration= 19221 loss= 0.00035197538090869784\n",
      "epoch= 400 iteration= 19241 loss= 0.000323416490573436\n",
      "test_data MSELoss:(pred-real)/real= 0.00017577236940269358\n",
      "epoch= 401 iteration= 19249 loss= 0.0009648676495999098\n",
      "epoch= 401 iteration= 19269 loss= 0.0003414544917177409\n",
      "epoch= 401 iteration= 19289 loss= 0.000321876083035022\n",
      "test_data MSELoss:(pred-real)/real= 0.00017744291071721818\n",
      "epoch= 402 iteration= 19297 loss= 0.0009712375467643142\n",
      "epoch= 402 iteration= 19317 loss= 0.0003313876804895699\n",
      "epoch= 402 iteration= 19337 loss= 0.00032036390621215105\n",
      "test_data MSELoss:(pred-real)/real= 0.00017878504950203934\n",
      "epoch= 403 iteration= 19345 loss= 0.0009775739163160324\n",
      "epoch= 403 iteration= 19365 loss= 0.00032337731681764126\n",
      "epoch= 403 iteration= 19385 loss= 0.0003189260605722666\n",
      "test_data MSELoss:(pred-real)/real= 0.0001799228812160436\n",
      "epoch= 404 iteration= 19393 loss= 0.0009833674412220716\n",
      "epoch= 404 iteration= 19413 loss= 0.00031704269349575043\n",
      "epoch= 404 iteration= 19433 loss= 0.0003177770704496652\n",
      "test_data MSELoss:(pred-real)/real= 0.00018084349067066797\n",
      "epoch= 405 iteration= 19441 loss= 0.000987687730230391\n",
      "epoch= 405 iteration= 19461 loss= 0.0003132274141535163\n",
      "epoch= 405 iteration= 19481 loss= 0.0003166705137118697\n",
      "test_data MSELoss:(pred-real)/real= 0.00018142637563869357\n",
      "epoch= 406 iteration= 19489 loss= 0.0009911361848935485\n",
      "epoch= 406 iteration= 19509 loss= 0.0003119864850305021\n",
      "epoch= 406 iteration= 19529 loss= 0.0003156953607685864\n",
      "test_data MSELoss:(pred-real)/real= 0.00018168904607591686\n",
      "epoch= 407 iteration= 19537 loss= 0.0009937294526025653\n",
      "epoch= 407 iteration= 19557 loss= 0.0003132927813567221\n",
      "epoch= 407 iteration= 19577 loss= 0.00031491066329181194\n",
      "test_data MSELoss:(pred-real)/real= 0.00018167737944168038\n",
      "epoch= 408 iteration= 19585 loss= 0.0009939074516296387\n",
      "epoch= 408 iteration= 19605 loss= 0.0003171648131683469\n",
      "epoch= 408 iteration= 19625 loss= 0.0003142798668704927\n",
      "test_data MSELoss:(pred-real)/real= 0.0001811784317396814\n",
      "epoch= 409 iteration= 19633 loss= 0.000993464607745409\n",
      "epoch= 409 iteration= 19653 loss= 0.0003230708825867623\n",
      "epoch= 409 iteration= 19673 loss= 0.00031359295826405287\n",
      "test_data MSELoss:(pred-real)/real= 0.00018050604521704371\n",
      "epoch= 410 iteration= 19681 loss= 0.0009911952074617147\n",
      "epoch= 410 iteration= 19701 loss= 0.0003304333076812327\n",
      "epoch= 410 iteration= 19721 loss= 0.0003130667028017342\n",
      "test_data MSELoss:(pred-real)/real= 0.00017948757340491284\n",
      "epoch= 411 iteration= 19729 loss= 0.0009880393045023084\n",
      "epoch= 411 iteration= 19749 loss= 0.00033879344118759036\n",
      "epoch= 411 iteration= 19769 loss= 0.00031258893432095647\n",
      "test_data MSELoss:(pred-real)/real= 0.0001780797556421021\n",
      "epoch= 412 iteration= 19777 loss= 0.0009840771090239286\n",
      "epoch= 412 iteration= 19797 loss= 0.0003476004349067807\n",
      "epoch= 412 iteration= 19817 loss= 0.0003120461478829384\n",
      "test_data MSELoss:(pred-real)/real= 0.0001765578770573484\n",
      "epoch= 413 iteration= 19825 loss= 0.0009788400493562222\n",
      "epoch= 413 iteration= 19845 loss= 0.0003560454642865807\n",
      "epoch= 413 iteration= 19865 loss= 0.0003115306026302278\n",
      "test_data MSELoss:(pred-real)/real= 0.0001749146405927604\n",
      "epoch= 414 iteration= 19873 loss= 0.0009724716073833406\n",
      "epoch= 414 iteration= 19893 loss= 0.00036317118792794645\n",
      "epoch= 414 iteration= 19913 loss= 0.00031097469036467373\n",
      "test_data MSELoss:(pred-real)/real= 0.00017319729522569105\n",
      "epoch= 415 iteration= 19921 loss= 0.0009646597900427878\n",
      "epoch= 415 iteration= 19941 loss= 0.00036851890035904944\n",
      "epoch= 415 iteration= 19961 loss= 0.00031036327709443867\n",
      "test_data MSELoss:(pred-real)/real= 0.00017151679494418204\n",
      "epoch= 416 iteration= 19969 loss= 0.0009565256768837571\n",
      "epoch= 416 iteration= 19989 loss= 0.00037149639683775604\n",
      "epoch= 416 iteration= 20009 loss= 0.00030988489743322134\n",
      "test_data MSELoss:(pred-real)/real= 0.00016998114842863287\n",
      "epoch= 417 iteration= 20017 loss= 0.000948355533182621\n",
      "epoch= 417 iteration= 20037 loss= 0.0003720186650753021\n",
      "epoch= 417 iteration= 20057 loss= 0.0003094513958785683\n",
      "test_data MSELoss:(pred-real)/real= 0.00016858138260431588\n",
      "epoch= 418 iteration= 20065 loss= 0.0009402640862390399\n",
      "epoch= 418 iteration= 20085 loss= 0.00037001771852374077\n",
      "epoch= 418 iteration= 20105 loss= 0.0003090193495154381\n",
      "test_data MSELoss:(pred-real)/real= 0.00016750103095546364\n",
      "epoch= 419 iteration= 20113 loss= 0.0009322901605628431\n",
      "epoch= 419 iteration= 20133 loss= 0.00036552833626046777\n",
      "epoch= 419 iteration= 20153 loss= 0.00030850674374960363\n",
      "test_data MSELoss:(pred-real)/real= 0.00016668404678057413\n",
      "epoch= 420 iteration= 20161 loss= 0.0009253821335732937\n",
      "epoch= 420 iteration= 20181 loss= 0.0003596360038500279\n",
      "epoch= 420 iteration= 20201 loss= 0.00030817833612672985\n",
      "test_data MSELoss:(pred-real)/real= 0.00016609778358542827\n",
      "epoch= 421 iteration= 20209 loss= 0.0009195450111292303\n",
      "epoch= 421 iteration= 20229 loss= 0.0003521775361150503\n",
      "epoch= 421 iteration= 20249 loss= 0.00030793348560109735\n",
      "test_data MSELoss:(pred-real)/real= 0.00016570643601880873\n",
      "epoch= 422 iteration= 20257 loss= 0.0009148957906290889\n",
      "epoch= 422 iteration= 20277 loss= 0.00034455745480954647\n",
      "epoch= 422 iteration= 20297 loss= 0.00030777184292674065\n",
      "test_data MSELoss:(pred-real)/real= 0.00016548784842598251\n",
      "epoch= 423 iteration= 20305 loss= 0.0009109774837270379\n",
      "epoch= 423 iteration= 20325 loss= 0.00033689604606479406\n",
      "epoch= 423 iteration= 20345 loss= 0.0003075239947065711\n",
      "test_data MSELoss:(pred-real)/real= 0.0001653917526709847\n",
      "epoch= 424 iteration= 20353 loss= 0.0009078782168217003\n",
      "epoch= 424 iteration= 20373 loss= 0.00033038895344361663\n",
      "epoch= 424 iteration= 20393 loss= 0.00030716959736309946\n",
      "test_data MSELoss:(pred-real)/real= 0.0001653068211453501\n",
      "epoch= 425 iteration= 20401 loss= 0.0009053676621988416\n",
      "epoch= 425 iteration= 20421 loss= 0.00032513492624275386\n",
      "epoch= 425 iteration= 20441 loss= 0.00030676546157337725\n",
      "test_data MSELoss:(pred-real)/real= 0.00016525199353054632\n",
      "epoch= 426 iteration= 20449 loss= 0.0009029090288095176\n",
      "epoch= 426 iteration= 20469 loss= 0.0003213974414393306\n",
      "epoch= 426 iteration= 20489 loss= 0.00030633865389972925\n",
      "test_data MSELoss:(pred-real)/real= 0.0001651950198720442\n",
      "epoch= 427 iteration= 20497 loss= 0.0009006917243823409\n",
      "epoch= 427 iteration= 20517 loss= 0.00031925778603181243\n",
      "epoch= 427 iteration= 20537 loss= 0.0003059792798012495\n",
      "test_data MSELoss:(pred-real)/real= 0.00016510999703314155\n",
      "epoch= 428 iteration= 20545 loss= 0.0008987585315480828\n",
      "epoch= 428 iteration= 20565 loss= 0.0003185587120242417\n",
      "epoch= 428 iteration= 20585 loss= 0.0003054691478610039\n",
      "test_data MSELoss:(pred-real)/real= 0.00016495069612574298\n",
      "epoch= 429 iteration= 20593 loss= 0.0008967002504505217\n",
      "epoch= 429 iteration= 20613 loss= 0.0003194051096215844\n",
      "epoch= 429 iteration= 20633 loss= 0.0003048782527912408\n",
      "test_data MSELoss:(pred-real)/real= 0.00016474061558255926\n",
      "epoch= 430 iteration= 20641 loss= 0.0008947276510298252\n",
      "epoch= 430 iteration= 20661 loss= 0.00032128323800861835\n",
      "epoch= 430 iteration= 20681 loss= 0.00030410877661779523\n",
      "test_data MSELoss:(pred-real)/real= 0.00016453292482765391\n",
      "epoch= 431 iteration= 20689 loss= 0.0008928974275477231\n",
      "epoch= 431 iteration= 20709 loss= 0.0003242575912736356\n",
      "epoch= 431 iteration= 20729 loss= 0.0003035328700207174\n",
      "test_data MSELoss:(pred-real)/real= 0.00016429045099357608\n",
      "epoch= 432 iteration= 20737 loss= 0.0008914183126762509\n",
      "epoch= 432 iteration= 20757 loss= 0.0003278736840002239\n",
      "epoch= 432 iteration= 20777 loss= 0.00030286857509054244\n",
      "test_data MSELoss:(pred-real)/real= 0.0001639848753256956\n",
      "epoch= 433 iteration= 20785 loss= 0.0008900664979591966\n",
      "epoch= 433 iteration= 20805 loss= 0.0003320476971566677\n",
      "epoch= 433 iteration= 20825 loss= 0.0003019264549948275\n",
      "test_data MSELoss:(pred-real)/real= 0.00016371313358831685\n",
      "epoch= 434 iteration= 20833 loss= 0.0008890638127923012\n",
      "epoch= 434 iteration= 20853 loss= 0.000336346187395975\n",
      "epoch= 434 iteration= 20873 loss= 0.0003010731306858361\n",
      "test_data MSELoss:(pred-real)/real= 0.00016341099035344087\n",
      "epoch= 435 iteration= 20881 loss= 0.000887774454895407\n",
      "epoch= 435 iteration= 20901 loss= 0.00034090178087353706\n",
      "epoch= 435 iteration= 20921 loss= 0.0003003755409736186\n",
      "test_data MSELoss:(pred-real)/real= 0.00016313657724822405\n",
      "epoch= 436 iteration= 20929 loss= 0.0008869247976690531\n",
      "epoch= 436 iteration= 20949 loss= 0.0003453278332017362\n",
      "epoch= 436 iteration= 20969 loss= 0.00029964331770315766\n",
      "test_data MSELoss:(pred-real)/real= 0.00016285036399494858\n",
      "epoch= 437 iteration= 20977 loss= 0.000886554887983948\n",
      "epoch= 437 iteration= 20997 loss= 0.00034921750193461776\n",
      "epoch= 437 iteration= 21017 loss= 0.0002989722997881472\n",
      "test_data MSELoss:(pred-real)/real= 0.0001625756460271077\n",
      "epoch= 438 iteration= 21025 loss= 0.000886180845554918\n",
      "epoch= 438 iteration= 21045 loss= 0.0003528245724737644\n",
      "epoch= 438 iteration= 21065 loss= 0.00029796245507895947\n",
      "test_data MSELoss:(pred-real)/real= 0.00016234606300713494\n",
      "epoch= 439 iteration= 21073 loss= 0.0008858684450387955\n",
      "epoch= 439 iteration= 21093 loss= 0.00035600591218099\n",
      "epoch= 439 iteration= 21113 loss= 0.00029733055271208286\n",
      "test_data MSELoss:(pred-real)/real= 0.0001621723309654044\n",
      "epoch= 440 iteration= 21121 loss= 0.0008853481849655509\n",
      "epoch= 440 iteration= 21141 loss= 0.0003585914964787662\n",
      "epoch= 440 iteration= 21161 loss= 0.00029639597050845623\n",
      "test_data MSELoss:(pred-real)/real= 0.00016199103592953178\n",
      "epoch= 441 iteration= 21169 loss= 0.0008856073254719377\n",
      "epoch= 441 iteration= 21189 loss= 0.0003605519304983318\n",
      "epoch= 441 iteration= 21209 loss= 0.00029561627889052033\n",
      "test_data MSELoss:(pred-real)/real= 0.0001619097285583848\n",
      "epoch= 442 iteration= 21217 loss= 0.0008853899780660868\n",
      "epoch= 442 iteration= 21237 loss= 0.00036208046367391944\n",
      "epoch= 442 iteration= 21257 loss= 0.00029476144118234515\n",
      "test_data MSELoss:(pred-real)/real= 0.00016187666115001774\n",
      "epoch= 443 iteration= 21265 loss= 0.0008851888705976307\n",
      "epoch= 443 iteration= 21285 loss= 0.00036280060885474086\n",
      "epoch= 443 iteration= 21305 loss= 0.0002936928940471262\n",
      "test_data MSELoss:(pred-real)/real= 0.00016187823021027726\n",
      "epoch= 444 iteration= 21313 loss= 0.000885161105543375\n",
      "epoch= 444 iteration= 21333 loss= 0.00036298861959949136\n",
      "epoch= 444 iteration= 21353 loss= 0.0002928245230577886\n",
      "test_data MSELoss:(pred-real)/real= 0.00016197454642679076\n",
      "epoch= 445 iteration= 21361 loss= 0.0008850438171066344\n",
      "epoch= 445 iteration= 21381 loss= 0.0003627578844316304\n",
      "epoch= 445 iteration= 21401 loss= 0.0002919080143328756\n",
      "test_data MSELoss:(pred-real)/real= 0.0001621317507670028\n",
      "epoch= 446 iteration= 21409 loss= 0.0008854616899043322\n",
      "epoch= 446 iteration= 21429 loss= 0.00036207021912559867\n",
      "epoch= 446 iteration= 21449 loss= 0.0002908988099079579\n",
      "test_data MSELoss:(pred-real)/real= 0.00016233761198236607\n",
      "epoch= 447 iteration= 21457 loss= 0.0008859193185344338\n",
      "epoch= 447 iteration= 21477 loss= 0.0003605771344155073\n",
      "epoch= 447 iteration= 21497 loss= 0.00028997656772844493\n",
      "test_data MSELoss:(pred-real)/real= 0.00016264419609797188\n",
      "epoch= 448 iteration= 21505 loss= 0.0008861664682626724\n",
      "epoch= 448 iteration= 21525 loss= 0.0003585336671676487\n",
      "epoch= 448 iteration= 21545 loss= 0.00028884634957648814\n",
      "test_data MSELoss:(pred-real)/real= 0.00016297803922498132\n",
      "epoch= 449 iteration= 21553 loss= 0.0008864243282005191\n",
      "epoch= 449 iteration= 21573 loss= 0.00035654898965731263\n",
      "epoch= 449 iteration= 21593 loss= 0.00028768411721102893\n",
      "test_data MSELoss:(pred-real)/real= 0.00016334264764736873\n",
      "epoch= 450 iteration= 21601 loss= 0.0008865087293088436\n",
      "epoch= 450 iteration= 21621 loss= 0.0003539953613653779\n",
      "epoch= 450 iteration= 21641 loss= 0.0002867481089197099\n",
      "test_data MSELoss:(pred-real)/real= 0.00016379838198190554\n",
      "epoch= 451 iteration= 21649 loss= 0.0008868550066836178\n",
      "epoch= 451 iteration= 21669 loss= 0.00035122031113132834\n",
      "epoch= 451 iteration= 21689 loss= 0.00028562970692291856\n",
      "test_data MSELoss:(pred-real)/real= 0.00016422852386313024\n",
      "epoch= 452 iteration= 21697 loss= 0.0008874943014234304\n",
      "epoch= 452 iteration= 21717 loss= 0.0003484319895505905\n",
      "epoch= 452 iteration= 21737 loss= 0.0002845700946636498\n",
      "test_data MSELoss:(pred-real)/real= 0.0001646849272219697\n",
      "epoch= 453 iteration= 21745 loss= 0.0008879908127710223\n",
      "epoch= 453 iteration= 21765 loss= 0.00034542122739367187\n",
      "epoch= 453 iteration= 21785 loss= 0.0002836627827491611\n",
      "test_data MSELoss:(pred-real)/real= 0.00016519012715434655\n",
      "epoch= 454 iteration= 21793 loss= 0.0008881801040843129\n",
      "epoch= 454 iteration= 21813 loss= 0.00034251323086209595\n",
      "epoch= 454 iteration= 21833 loss= 0.0002826761920005083\n",
      "test_data MSELoss:(pred-real)/real= 0.000165618165556225\n",
      "epoch= 455 iteration= 21841 loss= 0.0008884333074092865\n",
      "epoch= 455 iteration= 21861 loss= 0.0003397184773348272\n",
      "epoch= 455 iteration= 21881 loss= 0.0002816671330947429\n",
      "test_data MSELoss:(pred-real)/real= 0.00016606366807536688\n",
      "epoch= 456 iteration= 21889 loss= 0.0008882799884304404\n",
      "epoch= 456 iteration= 21909 loss= 0.00033714575693011284\n",
      "epoch= 456 iteration= 21929 loss= 0.0002805149124469608\n",
      "test_data MSELoss:(pred-real)/real= 0.00016645378564135173\n",
      "epoch= 457 iteration= 21937 loss= 0.0008886076393537223\n",
      "epoch= 457 iteration= 21957 loss= 0.00033466488821431994\n",
      "epoch= 457 iteration= 21977 loss= 0.00027949028299190104\n",
      "test_data MSELoss:(pred-real)/real= 0.0001668013574089855\n",
      "epoch= 458 iteration= 21985 loss= 0.0008881761459633708\n",
      "epoch= 458 iteration= 22005 loss= 0.00033262005308642983\n",
      "epoch= 458 iteration= 22025 loss= 0.00027879432309418917\n",
      "test_data MSELoss:(pred-real)/real= 0.0001670683683187235\n",
      "epoch= 459 iteration= 22033 loss= 0.0008885475108399987\n",
      "epoch= 459 iteration= 22053 loss= 0.0003307938459329307\n",
      "epoch= 459 iteration= 22073 loss= 0.0002776745241135359\n",
      "test_data MSELoss:(pred-real)/real= 0.00016733715165173635\n",
      "epoch= 460 iteration= 22081 loss= 0.0008879613596946001\n",
      "epoch= 460 iteration= 22101 loss= 0.00032932779868133366\n",
      "epoch= 460 iteration= 22121 loss= 0.00027687958208844066\n",
      "test_data MSELoss:(pred-real)/real= 0.00016757097655499819\n",
      "epoch= 461 iteration= 22129 loss= 0.0008880009409040213\n",
      "epoch= 461 iteration= 22149 loss= 0.00032816632301546633\n",
      "epoch= 461 iteration= 22169 loss= 0.00027606479125097394\n",
      "test_data MSELoss:(pred-real)/real= 0.00016773411152826156\n",
      "epoch= 462 iteration= 22177 loss= 0.0008870599558576941\n",
      "epoch= 462 iteration= 22197 loss= 0.0003273154143244028\n",
      "epoch= 462 iteration= 22217 loss= 0.00027525657787919044\n",
      "test_data MSELoss:(pred-real)/real= 0.00016780822406872175\n",
      "epoch= 463 iteration= 22225 loss= 0.0008862417889758945\n",
      "epoch= 463 iteration= 22245 loss= 0.0003267578431405127\n",
      "epoch= 463 iteration= 22265 loss= 0.0002743531367741525\n",
      "test_data MSELoss:(pred-real)/real= 0.00016785285188234412\n",
      "epoch= 464 iteration= 22273 loss= 0.0008854692569002509\n",
      "epoch= 464 iteration= 22293 loss= 0.0003265569102950394\n",
      "epoch= 464 iteration= 22313 loss= 0.000273781712166965\n",
      "test_data MSELoss:(pred-real)/real= 0.00016789519468147774\n",
      "epoch= 465 iteration= 22321 loss= 0.000884341774508357\n",
      "epoch= 465 iteration= 22341 loss= 0.0003266138955950737\n",
      "epoch= 465 iteration= 22361 loss= 0.0002728643885347992\n",
      "test_data MSELoss:(pred-real)/real= 0.00016783172832219863\n",
      "epoch= 466 iteration= 22369 loss= 0.000883300497662276\n",
      "epoch= 466 iteration= 22389 loss= 0.00032681613811291754\n",
      "epoch= 466 iteration= 22409 loss= 0.00027219977346248925\n",
      "test_data MSELoss:(pred-real)/real= 0.00016769551002653315\n",
      "epoch= 467 iteration= 22417 loss= 0.0008816967019811273\n",
      "epoch= 467 iteration= 22437 loss= 0.00032730610109865665\n",
      "epoch= 467 iteration= 22457 loss= 0.0002715673472266644\n",
      "test_data MSELoss:(pred-real)/real= 0.00016755898541305215\n",
      "epoch= 468 iteration= 22465 loss= 0.0008799870847724378\n",
      "epoch= 468 iteration= 22485 loss= 0.00032767083030194044\n",
      "epoch= 468 iteration= 22505 loss= 0.00027084400062449276\n",
      "test_data MSELoss:(pred-real)/real= 0.0001674295861448627\n",
      "epoch= 469 iteration= 22513 loss= 0.0008787120459601283\n",
      "epoch= 469 iteration= 22533 loss= 0.0003283604746684432\n",
      "epoch= 469 iteration= 22553 loss= 0.00027022947324439883\n",
      "test_data MSELoss:(pred-real)/real= 0.00016719474842830095\n",
      "epoch= 470 iteration= 22561 loss= 0.0008769590058363974\n",
      "epoch= 470 iteration= 22581 loss= 0.0003290486056357622\n",
      "epoch= 470 iteration= 22601 loss= 0.000269415439106524\n",
      "test_data MSELoss:(pred-real)/real= 0.00016686883282091003\n",
      "epoch= 471 iteration= 22609 loss= 0.0008753983420319855\n",
      "epoch= 471 iteration= 22629 loss= 0.00032963522244244814\n",
      "epoch= 471 iteration= 22649 loss= 0.0002689158427529037\n",
      "test_data MSELoss:(pred-real)/real= 0.00016659409593557938\n",
      "epoch= 472 iteration= 22657 loss= 0.0008737632888369262\n",
      "epoch= 472 iteration= 22677 loss= 0.00033013554639182985\n",
      "epoch= 472 iteration= 22697 loss= 0.0002682401391211897\n",
      "test_data MSELoss:(pred-real)/real= 0.00016630316094961016\n",
      "epoch= 473 iteration= 22705 loss= 0.0008718966273590922\n",
      "epoch= 473 iteration= 22725 loss= 0.00033086707117035985\n",
      "epoch= 473 iteration= 22745 loss= 0.00026759167667478323\n",
      "test_data MSELoss:(pred-real)/real= 0.00016595793858869\n",
      "epoch= 474 iteration= 22753 loss= 0.0008703921921551228\n",
      "epoch= 474 iteration= 22773 loss= 0.0003312855842523277\n",
      "epoch= 474 iteration= 22793 loss= 0.00026704263291321695\n",
      "test_data MSELoss:(pred-real)/real= 0.0001656138731050305\n",
      "epoch= 475 iteration= 22801 loss= 0.000868635717779398\n",
      "epoch= 475 iteration= 22821 loss= 0.0003316399233881384\n",
      "epoch= 475 iteration= 22841 loss= 0.0002663113409653306\n",
      "test_data MSELoss:(pred-real)/real= 0.00016522385521966498\n",
      "epoch= 476 iteration= 22849 loss= 0.000866974878590554\n",
      "epoch= 476 iteration= 22869 loss= 0.0003320752293802798\n",
      "epoch= 476 iteration= 22889 loss= 0.00026565050939098\n",
      "test_data MSELoss:(pred-real)/real= 0.00016491363567183726\n",
      "epoch= 477 iteration= 22897 loss= 0.0008656653808429837\n",
      "epoch= 477 iteration= 22917 loss= 0.0003322897828184068\n",
      "epoch= 477 iteration= 22937 loss= 0.00026512908516451716\n",
      "test_data MSELoss:(pred-real)/real= 0.00016454465730930679\n",
      "epoch= 478 iteration= 22945 loss= 0.0008639102452434599\n",
      "epoch= 478 iteration= 22965 loss= 0.0003325451980344951\n",
      "epoch= 478 iteration= 22985 loss= 0.0002644364139996469\n",
      "test_data MSELoss:(pred-real)/real= 0.00016416902326454874\n",
      "epoch= 479 iteration= 22993 loss= 0.0008626306662335992\n",
      "epoch= 479 iteration= 23013 loss= 0.00033272767905145884\n",
      "epoch= 479 iteration= 23033 loss= 0.0002639239246491343\n",
      "test_data MSELoss:(pred-real)/real= 0.00016384197588195092\n",
      "epoch= 480 iteration= 23041 loss= 0.0008608601638115942\n",
      "epoch= 480 iteration= 23061 loss= 0.00033277447801083326\n",
      "epoch= 480 iteration= 23081 loss= 0.0002633567783050239\n",
      "test_data MSELoss:(pred-real)/real= 0.0001634908483538311\n",
      "epoch= 481 iteration= 23089 loss= 0.0008596157422289252\n",
      "epoch= 481 iteration= 23109 loss= 0.0003328684833832085\n",
      "epoch= 481 iteration= 23129 loss= 0.000262721732724458\n",
      "test_data MSELoss:(pred-real)/real= 0.00016321030343533494\n",
      "epoch= 482 iteration= 23137 loss= 0.0008580940775573254\n",
      "epoch= 482 iteration= 23157 loss= 0.00033300218638032675\n",
      "epoch= 482 iteration= 23177 loss= 0.0002621790627017617\n",
      "test_data MSELoss:(pred-real)/real= 0.00016289998930005823\n",
      "epoch= 483 iteration= 23185 loss= 0.0008568954654037952\n",
      "epoch= 483 iteration= 23205 loss= 0.00033304758835583925\n",
      "epoch= 483 iteration= 23225 loss= 0.00026141287526115775\n",
      "test_data MSELoss:(pred-real)/real= 0.00016264591031358577\n",
      "epoch= 484 iteration= 23233 loss= 0.0008553549414500594\n",
      "epoch= 484 iteration= 23253 loss= 0.00033327104756608605\n",
      "epoch= 484 iteration= 23273 loss= 0.0002609507937449962\n",
      "test_data MSELoss:(pred-real)/real= 0.0001623701897187857\n",
      "epoch= 485 iteration= 23281 loss= 0.0008542290888726711\n",
      "epoch= 485 iteration= 23301 loss= 0.0003332963678985834\n",
      "epoch= 485 iteration= 23321 loss= 0.00026033882750198245\n",
      "test_data MSELoss:(pred-real)/real= 0.00016213967501244042\n",
      "epoch= 486 iteration= 23329 loss= 0.0008527875179424882\n",
      "epoch= 486 iteration= 23349 loss= 0.00033339421497657895\n",
      "epoch= 486 iteration= 23369 loss= 0.0002598116116132587\n",
      "test_data MSELoss:(pred-real)/real= 0.0001619092687178636\n",
      "epoch= 487 iteration= 23377 loss= 0.0008517464157193899\n",
      "epoch= 487 iteration= 23397 loss= 0.00033362500835210085\n",
      "epoch= 487 iteration= 23417 loss= 0.0002592072996776551\n",
      "test_data MSELoss:(pred-real)/real= 0.00016168004513019695\n",
      "epoch= 488 iteration= 23425 loss= 0.0008505384903401136\n",
      "epoch= 488 iteration= 23445 loss= 0.0003338097594678402\n",
      "epoch= 488 iteration= 23465 loss= 0.0002586154732853174\n",
      "test_data MSELoss:(pred-real)/real= 0.00016151518721017056\n",
      "epoch= 489 iteration= 23473 loss= 0.0008499325485900044\n",
      "epoch= 489 iteration= 23493 loss= 0.000334134791046381\n",
      "epoch= 489 iteration= 23513 loss= 0.0002580563013907522\n",
      "test_data MSELoss:(pred-real)/real= 0.00016134110410348512\n",
      "epoch= 490 iteration= 23521 loss= 0.0008484885911457241\n",
      "epoch= 490 iteration= 23541 loss= 0.0003344278084114194\n",
      "epoch= 490 iteration= 23561 loss= 0.00025736697716638446\n",
      "test_data MSELoss:(pred-real)/real= 0.00016117003578983713\n",
      "epoch= 491 iteration= 23569 loss= 0.0008477187948301435\n",
      "epoch= 491 iteration= 23589 loss= 0.00033475260715931654\n",
      "epoch= 491 iteration= 23609 loss= 0.00025693897623568773\n",
      "test_data MSELoss:(pred-real)/real= 0.00016100412758532912\n",
      "epoch= 492 iteration= 23617 loss= 0.0008468662854284048\n",
      "epoch= 492 iteration= 23637 loss= 0.00033527781488373876\n",
      "epoch= 492 iteration= 23657 loss= 0.0002562694135122001\n",
      "test_data MSELoss:(pred-real)/real= 0.00016086916220956483\n",
      "epoch= 493 iteration= 23665 loss= 0.0008458895026706159\n",
      "epoch= 493 iteration= 23685 loss= 0.00033580430317670107\n",
      "epoch= 493 iteration= 23705 loss= 0.0002558162668719888\n",
      "test_data MSELoss:(pred-real)/real= 0.0001607408354175277\n",
      "epoch= 494 iteration= 23713 loss= 0.0008452655747532845\n",
      "epoch= 494 iteration= 23733 loss= 0.00033629563404247165\n",
      "epoch= 494 iteration= 23753 loss= 0.0002551431825850159\n",
      "test_data MSELoss:(pred-real)/real= 0.00016061170972534456\n",
      "epoch= 495 iteration= 23761 loss= 0.0008447746513411403\n",
      "epoch= 495 iteration= 23781 loss= 0.0003369156620465219\n",
      "epoch= 495 iteration= 23801 loss= 0.0002547505428083241\n",
      "test_data MSELoss:(pred-real)/real= 0.00016052729079092388\n",
      "epoch= 496 iteration= 23809 loss= 0.0008441138779744506\n",
      "epoch= 496 iteration= 23829 loss= 0.00033744238317012787\n",
      "epoch= 496 iteration= 23849 loss= 0.00025409850059077144\n",
      "test_data MSELoss:(pred-real)/real= 0.00016041921444411855\n",
      "epoch= 497 iteration= 23857 loss= 0.0008438090444542468\n",
      "epoch= 497 iteration= 23877 loss= 0.00033792361500672996\n",
      "epoch= 497 iteration= 23897 loss= 0.00025354180252179503\n",
      "test_data MSELoss:(pred-real)/real= 0.00016033643041737377\n",
      "epoch= 498 iteration= 23905 loss= 0.0008434845367446542\n",
      "epoch= 498 iteration= 23925 loss= 0.0003385281888768077\n",
      "epoch= 498 iteration= 23945 loss= 0.0002532100770622492\n",
      "test_data MSELoss:(pred-real)/real= 0.0001602450167411007\n",
      "epoch= 499 iteration= 23953 loss= 0.0008434054907411337\n",
      "epoch= 499 iteration= 23973 loss= 0.0003391115751583129\n",
      "epoch= 499 iteration= 23993 loss= 0.00025257308152504265\n",
      "test_data MSELoss:(pred-real)/real= 0.00016014728316804394\n",
      "epoch= 500 iteration= 24001 loss= 0.0008431805181317031\n",
      "epoch= 500 iteration= 24021 loss= 0.00033951911609619856\n",
      "epoch= 500 iteration= 24041 loss= 0.00025200529489666224\n",
      "test_data MSELoss:(pred-real)/real= 0.0001600597632204881\n",
      "epoch= 501 iteration= 24049 loss= 0.000842689536511898\n",
      "epoch= 501 iteration= 24069 loss= 0.0003401181020308286\n",
      "epoch= 501 iteration= 24089 loss= 0.00025142604135908186\n",
      "test_data MSELoss:(pred-real)/real= 0.0001599678387719905\n",
      "epoch= 502 iteration= 24097 loss= 0.0008421894162893295\n",
      "epoch= 502 iteration= 24117 loss= 0.000340591708663851\n",
      "epoch= 502 iteration= 24137 loss= 0.00025089600239880383\n",
      "test_data MSELoss:(pred-real)/real= 0.00015991409782145638\n",
      "epoch= 503 iteration= 24145 loss= 0.0008419680525548756\n",
      "epoch= 503 iteration= 24165 loss= 0.0003410190111026168\n",
      "epoch= 503 iteration= 24185 loss= 0.0002503990544937551\n",
      "test_data MSELoss:(pred-real)/real= 0.0001598560924321646\n",
      "epoch= 504 iteration= 24193 loss= 0.0008419522782787681\n",
      "epoch= 504 iteration= 24213 loss= 0.0003412284713704139\n",
      "epoch= 504 iteration= 24233 loss= 0.0002498653484508395\n",
      "test_data MSELoss:(pred-real)/real= 0.00015978799347067253\n",
      "epoch= 505 iteration= 24241 loss= 0.0008417492499575019\n",
      "epoch= 505 iteration= 24261 loss= 0.0003415716637391597\n",
      "epoch= 505 iteration= 24281 loss= 0.00024956479319371283\n",
      "test_data MSELoss:(pred-real)/real= 0.00015971330831234808\n",
      "epoch= 506 iteration= 24289 loss= 0.0008411041926592588\n",
      "epoch= 506 iteration= 24309 loss= 0.00034164736280217767\n",
      "epoch= 506 iteration= 24329 loss= 0.0002489112666808069\n",
      "test_data MSELoss:(pred-real)/real= 0.00015964177073328755\n",
      "epoch= 507 iteration= 24337 loss= 0.0008405478438362479\n",
      "epoch= 507 iteration= 24357 loss= 0.0003418498090468347\n",
      "epoch= 507 iteration= 24377 loss= 0.0002484688302502036\n",
      "test_data MSELoss:(pred-real)/real= 0.00015957856994646135\n",
      "epoch= 508 iteration= 24385 loss= 0.0008399272919632494\n",
      "epoch= 508 iteration= 24405 loss= 0.0003419948334340006\n",
      "epoch= 508 iteration= 24425 loss= 0.000248103984631598\n",
      "test_data MSELoss:(pred-real)/real= 0.0001595344852830749\n",
      "epoch= 509 iteration= 24433 loss= 0.0008391482988372445\n",
      "epoch= 509 iteration= 24453 loss= 0.00034205990959890187\n",
      "epoch= 509 iteration= 24473 loss= 0.0002475600631441921\n",
      "test_data MSELoss:(pred-real)/real= 0.00015944487531669438\n",
      "epoch= 510 iteration= 24481 loss= 0.0008381342049688101\n",
      "epoch= 510 iteration= 24501 loss= 0.0003421458532102406\n",
      "epoch= 510 iteration= 24521 loss= 0.0002472543274052441\n",
      "test_data MSELoss:(pred-real)/real= 0.00015937094867695122\n",
      "epoch= 511 iteration= 24529 loss= 0.0008370811119675636\n",
      "epoch= 511 iteration= 24549 loss= 0.0003421814471948892\n",
      "epoch= 511 iteration= 24569 loss= 0.0002465472789481282\n",
      "test_data MSELoss:(pred-real)/real= 0.00015928353095659987\n",
      "epoch= 512 iteration= 24577 loss= 0.0008357723709195852\n",
      "epoch= 512 iteration= 24597 loss= 0.00034216040512546897\n",
      "epoch= 512 iteration= 24617 loss= 0.00024642955395393074\n",
      "test_data MSELoss:(pred-real)/real= 0.00015921712038107215\n",
      "epoch= 513 iteration= 24625 loss= 0.0008341961074620485\n",
      "epoch= 513 iteration= 24645 loss= 0.00034234742633998394\n",
      "epoch= 513 iteration= 24665 loss= 0.0002459644456394017\n",
      "test_data MSELoss:(pred-real)/real= 0.00015914012983557767\n",
      "epoch= 514 iteration= 24673 loss= 0.0008324608206748962\n",
      "epoch= 514 iteration= 24693 loss= 0.00034238718217238784\n",
      "epoch= 514 iteration= 24713 loss= 0.00024552957620471716\n",
      "test_data MSELoss:(pred-real)/real= 0.00015903288185654675\n",
      "epoch= 515 iteration= 24721 loss= 0.0008305888622999191\n",
      "epoch= 515 iteration= 24741 loss= 0.00034247266012243927\n",
      "epoch= 515 iteration= 24761 loss= 0.0002450653992127627\n",
      "test_data MSELoss:(pred-real)/real= 0.00015897418743406888\n",
      "epoch= 516 iteration= 24769 loss= 0.000828874355647713\n",
      "epoch= 516 iteration= 24789 loss= 0.00034265409340150654\n",
      "epoch= 516 iteration= 24809 loss= 0.000244585913605988\n",
      "test_data MSELoss:(pred-real)/real= 0.0001588706738402834\n",
      "epoch= 517 iteration= 24817 loss= 0.0008269797544926405\n",
      "epoch= 517 iteration= 24837 loss= 0.00034292045165784657\n",
      "epoch= 517 iteration= 24857 loss= 0.00024418620159849524\n",
      "test_data MSELoss:(pred-real)/real= 0.0001588088591233827\n",
      "epoch= 518 iteration= 24865 loss= 0.0008252992993220687\n",
      "epoch= 518 iteration= 24885 loss= 0.00034325034357607365\n",
      "epoch= 518 iteration= 24905 loss= 0.00024371292965952307\n",
      "test_data MSELoss:(pred-real)/real= 0.0001587063765327912\n",
      "epoch= 519 iteration= 24913 loss= 0.0008233656990341842\n",
      "epoch= 519 iteration= 24933 loss= 0.0003435771504882723\n",
      "epoch= 519 iteration= 24953 loss= 0.0002432152978144586\n",
      "test_data MSELoss:(pred-real)/real= 0.00015861762512940912\n",
      "epoch= 520 iteration= 24961 loss= 0.0008217340800911188\n",
      "epoch= 520 iteration= 24981 loss= 0.0003439762513153255\n",
      "epoch= 520 iteration= 25001 loss= 0.0002429777814541012\n",
      "test_data MSELoss:(pred-real)/real= 0.0001585483754752204\n",
      "epoch= 521 iteration= 25009 loss= 0.0008200065931305289\n",
      "epoch= 521 iteration= 25029 loss= 0.0003444961621426046\n",
      "epoch= 521 iteration= 25049 loss= 0.00024240493075922132\n",
      "test_data MSELoss:(pred-real)/real= 0.00015848457878746557\n",
      "epoch= 522 iteration= 25057 loss= 0.0008182111196219921\n",
      "epoch= 522 iteration= 25077 loss= 0.00034509680699557066\n",
      "epoch= 522 iteration= 25097 loss= 0.00024201112682931125\n",
      "test_data MSELoss:(pred-real)/real= 0.0001583770859724609\n",
      "epoch= 523 iteration= 25105 loss= 0.0008165508043020964\n",
      "epoch= 523 iteration= 25125 loss= 0.00034565292298793793\n",
      "epoch= 523 iteration= 25145 loss= 0.00024140501045621932\n",
      "test_data MSELoss:(pred-real)/real= 0.00015831235650694\n",
      "epoch= 524 iteration= 25153 loss= 0.0008148517808876932\n",
      "epoch= 524 iteration= 25173 loss= 0.0003465002228040248\n",
      "epoch= 524 iteration= 25193 loss= 0.00024112220853567123\n",
      "test_data MSELoss:(pred-real)/real= 0.0001582100576342782\n",
      "epoch= 525 iteration= 25201 loss= 0.0008132733637467027\n",
      "epoch= 525 iteration= 25221 loss= 0.00034735992085188627\n",
      "epoch= 525 iteration= 25241 loss= 0.00024058969574980438\n",
      "test_data MSELoss:(pred-real)/real= 0.0001581424268806586\n",
      "epoch= 526 iteration= 25249 loss= 0.0008115089731290936\n",
      "epoch= 526 iteration= 25269 loss= 0.0003485815250314772\n",
      "epoch= 526 iteration= 25289 loss= 0.00024018328986130655\n",
      "test_data MSELoss:(pred-real)/real= 0.0001580258638568921\n",
      "epoch= 527 iteration= 25297 loss= 0.0008102271240204573\n",
      "epoch= 527 iteration= 25317 loss= 0.00034980117925442755\n",
      "epoch= 527 iteration= 25337 loss= 0.00023986668384168297\n",
      "test_data MSELoss:(pred-real)/real= 0.00015797532250871882\n",
      "epoch= 528 iteration= 25345 loss= 0.0008086186135187745\n",
      "epoch= 528 iteration= 25365 loss= 0.00035109638702124357\n",
      "epoch= 528 iteration= 25385 loss= 0.0002395775227341801\n",
      "test_data MSELoss:(pred-real)/real= 0.00015786838448548224\n",
      "epoch= 529 iteration= 25393 loss= 0.0008072670898400247\n",
      "epoch= 529 iteration= 25413 loss= 0.00035280745942145586\n",
      "epoch= 529 iteration= 25433 loss= 0.00023911282187327743\n",
      "test_data MSELoss:(pred-real)/real= 0.00015777464213897474\n",
      "epoch= 530 iteration= 25441 loss= 0.0008059318643063307\n",
      "epoch= 530 iteration= 25461 loss= 0.0003547279629856348\n",
      "epoch= 530 iteration= 25481 loss= 0.0002388510329183191\n",
      "test_data MSELoss:(pred-real)/real= 0.00015769543169881218\n",
      "epoch= 531 iteration= 25489 loss= 0.0008043217821978033\n",
      "epoch= 531 iteration= 25509 loss= 0.0003568755055312067\n",
      "epoch= 531 iteration= 25529 loss= 0.00023845300893299282\n",
      "test_data MSELoss:(pred-real)/real= 0.00015760923488414847\n",
      "epoch= 532 iteration= 25537 loss= 0.0008028426673263311\n",
      "epoch= 532 iteration= 25557 loss= 0.0003594247973524034\n",
      "epoch= 532 iteration= 25577 loss= 0.00023813662119209766\n",
      "test_data MSELoss:(pred-real)/real= 0.00015746891367598436\n",
      "epoch= 533 iteration= 25585 loss= 0.0008015116909518838\n",
      "epoch= 533 iteration= 25605 loss= 0.000362397258868441\n",
      "epoch= 533 iteration= 25625 loss= 0.00023794983280822635\n",
      "test_data MSELoss:(pred-real)/real= 0.00015736108143755702\n",
      "epoch= 534 iteration= 25633 loss= 0.0008003420080058277\n",
      "epoch= 534 iteration= 25653 loss= 0.00036617234582081437\n",
      "epoch= 534 iteration= 25673 loss= 0.00023757247254252434\n",
      "test_data MSELoss:(pred-real)/real= 0.00015718351569375953\n",
      "epoch= 535 iteration= 25681 loss= 0.000798530294559896\n",
      "epoch= 535 iteration= 25701 loss= 0.0003702659741975367\n",
      "epoch= 535 iteration= 25721 loss= 0.00023732619592919946\n",
      "test_data MSELoss:(pred-real)/real= 0.00015704948345955926\n",
      "epoch= 536 iteration= 25729 loss= 0.0007976379711180925\n",
      "epoch= 536 iteration= 25749 loss= 0.00037517771124839783\n",
      "epoch= 536 iteration= 25769 loss= 0.000237119835219346\n",
      "test_data MSELoss:(pred-real)/real= 0.00015689027604821605\n",
      "epoch= 537 iteration= 25777 loss= 0.000796769221778959\n",
      "epoch= 537 iteration= 25797 loss= 0.00038083732943050563\n",
      "epoch= 537 iteration= 25817 loss= 0.00023687593056820333\n",
      "test_data MSELoss:(pred-real)/real= 0.00015672960071242415\n",
      "epoch= 538 iteration= 25825 loss= 0.0007958553032949567\n",
      "epoch= 538 iteration= 25845 loss= 0.0003872106899507344\n",
      "epoch= 538 iteration= 25865 loss= 0.0002365258987993002\n",
      "test_data MSELoss:(pred-real)/real= 0.0001565625163493678\n",
      "epoch= 539 iteration= 25873 loss= 0.0007952988380566239\n",
      "epoch= 539 iteration= 25893 loss= 0.0003939199377782643\n",
      "epoch= 539 iteration= 25913 loss= 0.0002363894018344581\n",
      "test_data MSELoss:(pred-real)/real= 0.00015639962475688662\n",
      "epoch= 540 iteration= 25921 loss= 0.0007947859703563154\n",
      "epoch= 540 iteration= 25941 loss= 0.00040026335045695305\n",
      "epoch= 540 iteration= 25961 loss= 0.00023633745149709284\n",
      "test_data MSELoss:(pred-real)/real= 0.0001563063880894333\n",
      "epoch= 541 iteration= 25969 loss= 0.0007946969708427787\n",
      "epoch= 541 iteration= 25989 loss= 0.0004059950588271022\n",
      "epoch= 541 iteration= 26009 loss= 0.00023619606508873403\n",
      "test_data MSELoss:(pred-real)/real= 0.00015616272066836244\n",
      "epoch= 542 iteration= 26017 loss= 0.0007948281127028167\n",
      "epoch= 542 iteration= 26037 loss= 0.0004101452068425715\n",
      "epoch= 542 iteration= 26057 loss= 0.00023619878629688174\n",
      "test_data MSELoss:(pred-real)/real= 0.0001560306154715363\n",
      "epoch= 543 iteration= 26065 loss= 0.0007947779959067702\n",
      "epoch= 543 iteration= 26085 loss= 0.00041240459540858865\n",
      "epoch= 543 iteration= 26105 loss= 0.00023595860693603754\n",
      "test_data MSELoss:(pred-real)/real= 0.0001559274591272697\n",
      "epoch= 544 iteration= 26113 loss= 0.0007948693819344044\n",
      "epoch= 544 iteration= 26133 loss= 0.0004128905711695552\n",
      "epoch= 544 iteration= 26153 loss= 0.0002357928897254169\n",
      "test_data MSELoss:(pred-real)/real= 0.00015590778675687034\n",
      "epoch= 545 iteration= 26161 loss= 0.0007944939425215125\n",
      "epoch= 545 iteration= 26181 loss= 0.00041163465357385576\n",
      "epoch= 545 iteration= 26201 loss= 0.00023516846704296768\n",
      "test_data MSELoss:(pred-real)/real= 0.00015601037412125152\n",
      "epoch= 546 iteration= 26209 loss= 0.0007934650639072061\n",
      "epoch= 546 iteration= 26229 loss= 0.00040983912185765803\n",
      "epoch= 546 iteration= 26249 loss= 0.00023445789702236652\n",
      "test_data MSELoss:(pred-real)/real= 0.00015633338553016073\n",
      "epoch= 547 iteration= 26257 loss= 0.0007919279159978032\n",
      "epoch= 547 iteration= 26277 loss= 0.00040766026359051466\n",
      "epoch= 547 iteration= 26297 loss= 0.00023364662774838507\n",
      "test_data MSELoss:(pred-real)/real= 0.00015693404711782932\n",
      "epoch= 548 iteration= 26305 loss= 0.0007909114938229322\n",
      "epoch= 548 iteration= 26325 loss= 0.0004057587357237935\n",
      "epoch= 548 iteration= 26345 loss= 0.00023255322594195604\n",
      "test_data MSELoss:(pred-real)/real= 0.0001578303548740223\n",
      "epoch= 549 iteration= 26353 loss= 0.0007904256344772875\n",
      "epoch= 549 iteration= 26373 loss= 0.00040356680983677506\n",
      "epoch= 549 iteration= 26393 loss= 0.00023159261036198586\n",
      "test_data MSELoss:(pred-real)/real= 0.00015902393133728764\n",
      "epoch= 550 iteration= 26401 loss= 0.0007907111430540681\n",
      "epoch= 550 iteration= 26421 loss= 0.0004005646624136716\n",
      "epoch= 550 iteration= 26441 loss= 0.00023056358622852713\n",
      "test_data MSELoss:(pred-real)/real= 0.00016034685759223067\n",
      "epoch= 551 iteration= 26449 loss= 0.0007923082448542118\n",
      "epoch= 551 iteration= 26469 loss= 0.0003958845045417547\n",
      "epoch= 551 iteration= 26489 loss= 0.00022950580751057714\n",
      "test_data MSELoss:(pred-real)/real= 0.0001618776299437741\n",
      "epoch= 552 iteration= 26497 loss= 0.0007945094257593155\n",
      "epoch= 552 iteration= 26517 loss= 0.0003898036666214466\n",
      "epoch= 552 iteration= 26537 loss= 0.00022856181021779776\n",
      "test_data MSELoss:(pred-real)/real= 0.00016360100635210985\n",
      "epoch= 553 iteration= 26545 loss= 0.0007981765083968639\n",
      "epoch= 553 iteration= 26565 loss= 0.0003820545389316976\n",
      "epoch= 553 iteration= 26585 loss= 0.00022759998682886362\n",
      "test_data MSELoss:(pred-real)/real= 0.00016540781216463075\n",
      "epoch= 554 iteration= 26593 loss= 0.0008020452223718166\n",
      "epoch= 554 iteration= 26613 loss= 0.0003729737363755703\n",
      "epoch= 554 iteration= 26633 loss= 0.00022672806517221034\n",
      "test_data MSELoss:(pred-real)/real= 0.00016724154047551565\n",
      "epoch= 555 iteration= 26641 loss= 0.0008065155707299709\n",
      "epoch= 555 iteration= 26661 loss= 0.00036453758366405964\n",
      "epoch= 555 iteration= 26681 loss= 0.00022592220921069384\n",
      "test_data MSELoss:(pred-real)/real= 0.0001690910979959881\n",
      "epoch= 556 iteration= 26689 loss= 0.0008111351635307074\n",
      "epoch= 556 iteration= 26709 loss= 0.00035707466304302216\n",
      "epoch= 556 iteration= 26729 loss= 0.00022545206593349576\n",
      "test_data MSELoss:(pred-real)/real= 0.00017061161015590186\n",
      "epoch= 557 iteration= 26737 loss= 0.0008147397311404347\n",
      "epoch= 557 iteration= 26757 loss= 0.00035162142012268305\n",
      "epoch= 557 iteration= 26777 loss= 0.00022497247846331447\n",
      "test_data MSELoss:(pred-real)/real= 0.00017199779649672563\n",
      "epoch= 558 iteration= 26785 loss= 0.0008182571036741138\n",
      "epoch= 558 iteration= 26805 loss= 0.0003489519003778696\n",
      "epoch= 558 iteration= 26825 loss= 0.00022480054758489132\n",
      "test_data MSELoss:(pred-real)/real= 0.00017308198293903844\n",
      "epoch= 559 iteration= 26833 loss= 0.0008201737655326724\n",
      "epoch= 559 iteration= 26853 loss= 0.00034935231087729335\n",
      "epoch= 559 iteration= 26873 loss= 0.0002248897944809869\n",
      "test_data MSELoss:(pred-real)/real= 0.00017370014793414157\n",
      "epoch= 560 iteration= 26881 loss= 0.0008210157975554466\n",
      "epoch= 560 iteration= 26901 loss= 0.0003529592650011182\n",
      "epoch= 560 iteration= 26921 loss= 0.00022495142184197903\n",
      "test_data MSELoss:(pred-real)/real= 0.00017376530049659778\n",
      "epoch= 561 iteration= 26929 loss= 0.0008216520654968917\n",
      "epoch= 561 iteration= 26949 loss= 0.00035910896258428693\n",
      "epoch= 561 iteration= 26969 loss= 0.00022527352848555893\n",
      "test_data MSELoss:(pred-real)/real= 0.00017333975411020218\n",
      "epoch= 562 iteration= 26977 loss= 0.0008213295368477702\n",
      "epoch= 562 iteration= 26997 loss= 0.0003677045460790396\n",
      "epoch= 562 iteration= 27017 loss= 0.00022536740289069712\n",
      "test_data MSELoss:(pred-real)/real= 0.00017242146423086525\n",
      "epoch= 563 iteration= 27025 loss= 0.0008197070565074682\n",
      "epoch= 563 iteration= 27045 loss= 0.0003775111399590969\n",
      "epoch= 563 iteration= 27065 loss= 0.00022541856742464006\n",
      "test_data MSELoss:(pred-real)/real= 0.00017100759869208558\n",
      "epoch= 564 iteration= 27073 loss= 0.000817437656223774\n",
      "epoch= 564 iteration= 27093 loss= 0.0003876282135024667\n",
      "epoch= 564 iteration= 27113 loss= 0.00022539327619597316\n",
      "test_data MSELoss:(pred-real)/real= 0.00016924169394769706\n",
      "epoch= 565 iteration= 27121 loss= 0.000813882565125823\n",
      "epoch= 565 iteration= 27141 loss= 0.00039730354910716414\n",
      "epoch= 565 iteration= 27161 loss= 0.00022517812612932175\n",
      "test_data MSELoss:(pred-real)/real= 0.00016718571132514625\n",
      "epoch= 566 iteration= 27169 loss= 0.0008096745004877448\n",
      "epoch= 566 iteration= 27189 loss= 0.00040521216578781605\n",
      "epoch= 566 iteration= 27209 loss= 0.000224741903366521\n",
      "test_data MSELoss:(pred-real)/real= 0.0001650506630539894\n",
      "epoch= 567 iteration= 27217 loss= 0.0008051726035773754\n",
      "epoch= 567 iteration= 27237 loss= 0.0004102576058357954\n",
      "epoch= 567 iteration= 27257 loss= 0.0002241722831968218\n",
      "test_data MSELoss:(pred-real)/real= 0.000163044154032832\n",
      "epoch= 568 iteration= 27265 loss= 0.0008004081319086254\n",
      "epoch= 568 iteration= 27285 loss= 0.0004116108175367117\n",
      "epoch= 568 iteration= 27305 loss= 0.0002235476131318137\n",
      "test_data MSELoss:(pred-real)/real= 0.00016120646032504737\n",
      "epoch= 569 iteration= 27313 loss= 0.0007961713708937168\n",
      "epoch= 569 iteration= 27333 loss= 0.0004095534677617252\n",
      "epoch= 569 iteration= 27353 loss= 0.00022289814660325646\n",
      "test_data MSELoss:(pred-real)/real= 0.00015974411144270562\n",
      "epoch= 570 iteration= 27361 loss= 0.000792270409874618\n",
      "epoch= 570 iteration= 27381 loss= 0.0004043043591082096\n",
      "epoch= 570 iteration= 27401 loss= 0.00022241119586396962\n",
      "test_data MSELoss:(pred-real)/real= 0.00015874516175244934\n",
      "epoch= 571 iteration= 27409 loss= 0.00078843894880265\n",
      "epoch= 571 iteration= 27429 loss= 0.0003965283976867795\n",
      "epoch= 571 iteration= 27449 loss= 0.000221922920900397\n",
      "test_data MSELoss:(pred-real)/real= 0.00015808081479917746\n",
      "epoch= 572 iteration= 27457 loss= 0.0007859226316213608\n",
      "epoch= 572 iteration= 27477 loss= 0.00038700440200045705\n",
      "epoch= 572 iteration= 27497 loss= 0.00022167846327647567\n",
      "test_data MSELoss:(pred-real)/real= 0.00015777701701154002\n",
      "epoch= 573 iteration= 27505 loss= 0.000783648865763098\n",
      "epoch= 573 iteration= 27525 loss= 0.0003774898359552026\n",
      "epoch= 573 iteration= 27545 loss= 0.00022156606428325176\n",
      "test_data MSELoss:(pred-real)/real= 0.00015763327864988242\n",
      "epoch= 574 iteration= 27553 loss= 0.0007816007127985358\n",
      "epoch= 574 iteration= 27573 loss= 0.0003688660799525678\n",
      "epoch= 574 iteration= 27593 loss= 0.00022145788534544408\n",
      "test_data MSELoss:(pred-real)/real= 0.00015763518422318157\n",
      "epoch= 575 iteration= 27601 loss= 0.0007798665901646018\n",
      "epoch= 575 iteration= 27621 loss= 0.00036144204204902053\n",
      "epoch= 575 iteration= 27641 loss= 0.00022165870177559555\n",
      "test_data MSELoss:(pred-real)/real= 0.00015769954588904512\n",
      "epoch= 576 iteration= 27649 loss= 0.0007774992845952511\n",
      "epoch= 576 iteration= 27669 loss= 0.00035622314317151904\n",
      "epoch= 576 iteration= 27689 loss= 0.0002219229645561427\n",
      "test_data MSELoss:(pred-real)/real= 0.00015769322199048473\n",
      "epoch= 577 iteration= 27697 loss= 0.0007752339006401598\n",
      "epoch= 577 iteration= 27717 loss= 0.00035328837111592293\n",
      "epoch= 577 iteration= 27737 loss= 0.0002217915462097153\n",
      "test_data MSELoss:(pred-real)/real= 0.00015766442993481178\n",
      "epoch= 578 iteration= 27745 loss= 0.0007729789358563721\n",
      "epoch= 578 iteration= 27765 loss= 0.000352186500094831\n",
      "epoch= 578 iteration= 27785 loss= 0.000221780821448192\n",
      "test_data MSELoss:(pred-real)/real= 0.0001576006387040252\n",
      "epoch= 579 iteration= 27793 loss= 0.0007704146555624902\n",
      "epoch= 579 iteration= 27813 loss= 0.0003528317320160568\n",
      "epoch= 579 iteration= 27833 loss= 0.00022181135136634111\n",
      "test_data MSELoss:(pred-real)/real= 0.00015741099014121573\n",
      "epoch= 580 iteration= 27841 loss= 0.0007684066658839583\n",
      "epoch= 580 iteration= 27861 loss= 0.00035512910108081996\n",
      "epoch= 580 iteration= 27881 loss= 0.00022176868515089154\n",
      "test_data MSELoss:(pred-real)/real= 0.00015720380542916246\n",
      "epoch= 581 iteration= 27889 loss= 0.0007665763841941953\n",
      "epoch= 581 iteration= 27909 loss= 0.00035827665124088526\n",
      "epoch= 581 iteration= 27929 loss= 0.0002216851426055655\n",
      "test_data MSELoss:(pred-real)/real= 0.00015700291151006241\n",
      "epoch= 582 iteration= 27937 loss= 0.0007651996565982699\n",
      "epoch= 582 iteration= 27957 loss= 0.0003620149800553918\n",
      "epoch= 582 iteration= 27977 loss= 0.00022145485854707658\n",
      "test_data MSELoss:(pred-real)/real= 0.0001566869283124106\n",
      "epoch= 583 iteration= 27985 loss= 0.0007638089591637254\n",
      "epoch= 583 iteration= 28005 loss= 0.00036590074887499213\n",
      "epoch= 583 iteration= 28025 loss= 0.00022141821682453156\n",
      "test_data MSELoss:(pred-real)/real= 0.0001564273017720552\n",
      "epoch= 584 iteration= 28033 loss= 0.0007631115149706602\n",
      "epoch= 584 iteration= 28053 loss= 0.00036965246545150876\n",
      "epoch= 584 iteration= 28073 loss= 0.00022108246048446745\n",
      "test_data MSELoss:(pred-real)/real= 0.00015616304299328476\n",
      "epoch= 585 iteration= 28081 loss= 0.0007623019046150148\n",
      "epoch= 585 iteration= 28101 loss= 0.00037299777613952756\n",
      "epoch= 585 iteration= 28121 loss= 0.00022083253134042025\n",
      "test_data MSELoss:(pred-real)/real= 0.0001558544929139316\n",
      "epoch= 586 iteration= 28129 loss= 0.0007620723336003721\n",
      "epoch= 586 iteration= 28149 loss= 0.0003756608348339796\n",
      "epoch= 586 iteration= 28169 loss= 0.00022033178538549691\n",
      "test_data MSELoss:(pred-real)/real= 0.00015561475047434214\n",
      "epoch= 587 iteration= 28177 loss= 0.0007615854265168309\n",
      "epoch= 587 iteration= 28197 loss= 0.0003777971724048257\n",
      "epoch= 587 iteration= 28217 loss= 0.00021999210002832115\n",
      "test_data MSELoss:(pred-real)/real= 0.0001553962069010595\n",
      "epoch= 588 iteration= 28225 loss= 0.0007617064984515309\n",
      "epoch= 588 iteration= 28245 loss= 0.000379306438844651\n",
      "epoch= 588 iteration= 28265 loss= 0.00021960650337859988\n",
      "test_data MSELoss:(pred-real)/real= 0.0001552582954900572\n",
      "epoch= 589 iteration= 28273 loss= 0.0007616969523951411\n",
      "epoch= 589 iteration= 28293 loss= 0.00038036127807572484\n",
      "epoch= 589 iteration= 28313 loss= 0.00021895943791605532\n",
      "test_data MSELoss:(pred-real)/real= 0.0001551688961626496\n",
      "epoch= 590 iteration= 28321 loss= 0.0007617422961629927\n",
      "epoch= 590 iteration= 28341 loss= 0.00038046843837946653\n",
      "epoch= 590 iteration= 28361 loss= 0.00021848961478099227\n",
      "test_data MSELoss:(pred-real)/real= 0.00015518012914981228\n",
      "epoch= 591 iteration= 28369 loss= 0.0007618075469508767\n",
      "epoch= 591 iteration= 28389 loss= 0.00037988804979249835\n",
      "epoch= 591 iteration= 28409 loss= 0.00021783194097224623\n",
      "test_data MSELoss:(pred-real)/real= 0.00015522087524004745\n",
      "epoch= 592 iteration= 28417 loss= 0.0007617776282131672\n",
      "epoch= 592 iteration= 28437 loss= 0.00037892922409810126\n",
      "epoch= 592 iteration= 28457 loss= 0.00021720757649745792\n",
      "test_data MSELoss:(pred-real)/real= 0.00015539693777100183\n",
      "epoch= 593 iteration= 28465 loss= 0.0007618931122124195\n",
      "epoch= 593 iteration= 28485 loss= 0.000377252756152302\n",
      "epoch= 593 iteration= 28505 loss= 0.00021662478684447706\n",
      "test_data MSELoss:(pred-real)/real= 0.0001555665188789135\n",
      "epoch= 594 iteration= 28513 loss= 0.0007616763468831778\n",
      "epoch= 594 iteration= 28533 loss= 0.00037576130125671625\n",
      "epoch= 594 iteration= 28553 loss= 0.00021597296290565282\n",
      "test_data MSELoss:(pred-real)/real= 0.00015588921087328345\n",
      "epoch= 595 iteration= 28561 loss= 0.0007616572547703981\n",
      "epoch= 595 iteration= 28581 loss= 0.0003738457162398845\n",
      "epoch= 595 iteration= 28601 loss= 0.00021534613915719092\n",
      "test_data MSELoss:(pred-real)/real= 0.00015623558610968757\n",
      "epoch= 596 iteration= 28609 loss= 0.0007615291397087276\n",
      "epoch= 596 iteration= 28629 loss= 0.0003717954969033599\n",
      "epoch= 596 iteration= 28649 loss= 0.0002147789637092501\n",
      "test_data MSELoss:(pred-real)/real= 0.0001566012571856845\n",
      "epoch= 597 iteration= 28657 loss= 0.0007613240741193295\n",
      "epoch= 597 iteration= 28677 loss= 0.00036942100268788636\n",
      "epoch= 597 iteration= 28697 loss= 0.0002139998832717538\n",
      "test_data MSELoss:(pred-real)/real= 0.00015703982207924128\n",
      "epoch= 598 iteration= 28705 loss= 0.0007608477026224136\n",
      "epoch= 598 iteration= 28725 loss= 0.0003673373139463365\n",
      "epoch= 598 iteration= 28745 loss= 0.00021350292081478983\n",
      "test_data MSELoss:(pred-real)/real= 0.00015747838879178743\n",
      "epoch= 599 iteration= 28753 loss= 0.0007608841406181455\n",
      "epoch= 599 iteration= 28773 loss= 0.00036513531813398004\n",
      "epoch= 599 iteration= 28793 loss= 0.00021308072609826922\n",
      "test_data MSELoss:(pred-real)/real= 0.00015793835482327267\n",
      "epoch= 600 iteration= 28801 loss= 0.000760710216127336\n",
      "epoch= 600 iteration= 28821 loss= 0.0003629346610978246\n",
      "epoch= 600 iteration= 28841 loss= 0.00021243360242806375\n",
      "test_data MSELoss:(pred-real)/real= 0.0001583840698003769\n",
      "epoch= 601 iteration= 28849 loss= 0.0007603199919685721\n",
      "epoch= 601 iteration= 28869 loss= 0.00036098918644711375\n",
      "epoch= 601 iteration= 28889 loss= 0.00021184771321713924\n",
      "test_data MSELoss:(pred-real)/real= 0.00015884857675700913\n",
      "epoch= 602 iteration= 28897 loss= 0.0007596184150315821\n",
      "epoch= 602 iteration= 28917 loss= 0.00035946062416769564\n",
      "epoch= 602 iteration= 28937 loss= 0.0002112413931172341\n",
      "test_data MSELoss:(pred-real)/real= 0.00015924086692393758\n",
      "epoch= 603 iteration= 28945 loss= 0.000759389135055244\n",
      "epoch= 603 iteration= 28965 loss= 0.0003578516189008951\n",
      "epoch= 603 iteration= 28985 loss= 0.00021085422486066818\n",
      "test_data MSELoss:(pred-real)/real= 0.00015959673073666635\n",
      "epoch= 604 iteration= 28993 loss= 0.0007591017056256533\n",
      "epoch= 604 iteration= 29013 loss= 0.0003564917133189738\n",
      "epoch= 604 iteration= 29033 loss= 0.00021033214579802006\n",
      "test_data MSELoss:(pred-real)/real= 0.00015997026057448238\n",
      "epoch= 605 iteration= 29041 loss= 0.000758758804295212\n",
      "epoch= 605 iteration= 29061 loss= 0.00035519019002094865\n",
      "epoch= 605 iteration= 29081 loss= 0.00020985640003345907\n",
      "test_data MSELoss:(pred-real)/real= 0.00016026697267079726\n",
      "epoch= 606 iteration= 29089 loss= 0.0007579942466691136\n",
      "epoch= 606 iteration= 29109 loss= 0.00035427589318715036\n",
      "epoch= 606 iteration= 29129 loss= 0.00020952925842721015\n",
      "test_data MSELoss:(pred-real)/real= 0.00016052854116423986\n",
      "epoch= 607 iteration= 29137 loss= 0.0007576866773888469\n",
      "epoch= 607 iteration= 29157 loss= 0.0003534562711138278\n",
      "epoch= 607 iteration= 29177 loss= 0.00020900256640743464\n",
      "test_data MSELoss:(pred-real)/real= 0.00016072076323325746\n",
      "epoch= 608 iteration= 29185 loss= 0.0007571656024083495\n",
      "epoch= 608 iteration= 29205 loss= 0.00035284983459860086\n",
      "epoch= 608 iteration= 29225 loss= 0.00020868523279204965\n",
      "test_data MSELoss:(pred-real)/real= 0.00016089412820292638\n",
      "epoch= 609 iteration= 29233 loss= 0.0007567410357296467\n",
      "epoch= 609 iteration= 29253 loss= 0.00035259014111943543\n",
      "epoch= 609 iteration= 29273 loss= 0.00020829064305871725\n",
      "test_data MSELoss:(pred-real)/real= 0.0001609701597772073\n",
      "epoch= 610 iteration= 29281 loss= 0.0007556377677246928\n",
      "epoch= 610 iteration= 29301 loss= 0.00035235192626714706\n",
      "epoch= 610 iteration= 29321 loss= 0.0002080031408695504\n",
      "test_data MSELoss:(pred-real)/real= 0.00016105823087855242\n",
      "epoch= 611 iteration= 29329 loss= 0.000755321467295289\n",
      "epoch= 611 iteration= 29349 loss= 0.0003523692721500993\n",
      "epoch= 611 iteration= 29369 loss= 0.00020762349595315754\n",
      "test_data MSELoss:(pred-real)/real= 0.00016105678951134906\n",
      "epoch= 612 iteration= 29377 loss= 0.0007546214619651437\n",
      "epoch= 612 iteration= 29397 loss= 0.000352380215190351\n",
      "epoch= 612 iteration= 29417 loss= 0.0002071884082397446\n",
      "test_data MSELoss:(pred-real)/real= 0.00016104183050629216\n",
      "epoch= 613 iteration= 29425 loss= 0.0007539363577961922\n",
      "epoch= 613 iteration= 29445 loss= 0.0003527105145622045\n",
      "epoch= 613 iteration= 29465 loss= 0.00020695821149274707\n",
      "test_data MSELoss:(pred-real)/real= 0.00016094604870886542\n",
      "epoch= 614 iteration= 29473 loss= 0.0007533278549090028\n",
      "epoch= 614 iteration= 29493 loss= 0.0003528387751430273\n",
      "epoch= 614 iteration= 29513 loss= 0.00020652801322285086\n",
      "test_data MSELoss:(pred-real)/real= 0.00016082224756246432\n",
      "epoch= 615 iteration= 29521 loss= 0.0007525206310674548\n",
      "epoch= 615 iteration= 29541 loss= 0.0003531439579091966\n",
      "epoch= 615 iteration= 29561 loss= 0.00020633393432945013\n",
      "test_data MSELoss:(pred-real)/real= 0.000160638301531435\n",
      "epoch= 616 iteration= 29569 loss= 0.0007518247002735734\n",
      "epoch= 616 iteration= 29589 loss= 0.00035349029349163175\n",
      "epoch= 616 iteration= 29609 loss= 0.00020598356786649674\n",
      "test_data MSELoss:(pred-real)/real= 0.00016045396478148177\n",
      "epoch= 617 iteration= 29617 loss= 0.00075104262214154\n",
      "epoch= 617 iteration= 29637 loss= 0.0003537451266311109\n",
      "epoch= 617 iteration= 29657 loss= 0.00020568663603626192\n",
      "test_data MSELoss:(pred-real)/real= 0.00016025498189264908\n",
      "epoch= 618 iteration= 29665 loss= 0.0007502228254452348\n",
      "epoch= 618 iteration= 29685 loss= 0.00035401934292167425\n",
      "epoch= 618 iteration= 29705 loss= 0.0002052638155873865\n",
      "test_data MSELoss:(pred-real)/real= 0.00016003007149265614\n",
      "epoch= 619 iteration= 29713 loss= 0.0007493104785680771\n",
      "epoch= 619 iteration= 29733 loss= 0.00035428974661044776\n",
      "epoch= 619 iteration= 29753 loss= 0.00020504859276115894\n",
      "test_data MSELoss:(pred-real)/real= 0.00015978339179127942\n",
      "epoch= 620 iteration= 29761 loss= 0.0007485951646231115\n",
      "epoch= 620 iteration= 29781 loss= 0.00035445328103378415\n",
      "epoch= 620 iteration= 29801 loss= 0.00020466790010686964\n",
      "test_data MSELoss:(pred-real)/real= 0.000159528254516772\n",
      "epoch= 621 iteration= 29809 loss= 0.0007478366605937481\n",
      "epoch= 621 iteration= 29829 loss= 0.00035463989479467273\n",
      "epoch= 621 iteration= 29849 loss= 0.0002044178545475006\n",
      "test_data MSELoss:(pred-real)/real= 0.00015923902938084212\n",
      "epoch= 622 iteration= 29857 loss= 0.0007471618009731174\n",
      "epoch= 622 iteration= 29877 loss= 0.0003545400104485452\n",
      "epoch= 622 iteration= 29897 loss= 0.00020418045460246503\n",
      "test_data MSELoss:(pred-real)/real= 0.0001590010338986758\n",
      "epoch= 623 iteration= 29905 loss= 0.0007463493384420872\n",
      "epoch= 623 iteration= 29925 loss= 0.0003547011874616146\n",
      "epoch= 623 iteration= 29945 loss= 0.00020375238091219217\n",
      "test_data MSELoss:(pred-real)/real= 0.00015872333606239408\n",
      "epoch= 624 iteration= 29953 loss= 0.0007454961305484176\n",
      "epoch= 624 iteration= 29973 loss= 0.0003547595115378499\n",
      "epoch= 624 iteration= 29993 loss= 0.0002034487115452066\n",
      "test_data MSELoss:(pred-real)/real= 0.00015844826557440684\n",
      "epoch= 625 iteration= 30001 loss= 0.0007448443211615086\n",
      "epoch= 625 iteration= 30021 loss= 0.0003546702500898391\n",
      "epoch= 625 iteration= 30041 loss= 0.00020318420138210058\n",
      "test_data MSELoss:(pred-real)/real= 0.00015816982595424635\n",
      "epoch= 626 iteration= 30049 loss= 0.0007441596244461834\n",
      "epoch= 626 iteration= 30069 loss= 0.0003545368672348559\n",
      "epoch= 626 iteration= 30089 loss= 0.00020291843975428492\n",
      "test_data MSELoss:(pred-real)/real= 0.00015800166947883555\n",
      "epoch= 627 iteration= 30097 loss= 0.0007430592668242753\n",
      "epoch= 627 iteration= 30117 loss= 0.00035455659963190556\n",
      "epoch= 627 iteration= 30137 loss= 0.00020255110575817525\n",
      "test_data MSELoss:(pred-real)/real= 0.00015776704240124672\n",
      "epoch= 628 iteration= 30145 loss= 0.0007420902256853878\n",
      "epoch= 628 iteration= 30165 loss= 0.000354352465365082\n",
      "epoch= 628 iteration= 30185 loss= 0.00020231370581313968\n",
      "test_data MSELoss:(pred-real)/real= 0.00015754970736452377\n",
      "epoch= 629 iteration= 30193 loss= 0.0007414651336148381\n",
      "epoch= 629 iteration= 30213 loss= 0.00035416195169091225\n",
      "epoch= 629 iteration= 30233 loss= 0.00020196926197968423\n",
      "test_data MSELoss:(pred-real)/real= 0.00015736349705548492\n",
      "epoch= 630 iteration= 30241 loss= 0.0007410697289742529\n",
      "epoch= 630 iteration= 30261 loss= 0.00035415266756899655\n",
      "epoch= 630 iteration= 30281 loss= 0.00020175959798507392\n",
      "test_data MSELoss:(pred-real)/real= 0.00015717751703050453\n",
      "epoch= 631 iteration= 30289 loss= 0.000740325078368187\n",
      "epoch= 631 iteration= 30309 loss= 0.0003538929158821702\n",
      "epoch= 631 iteration= 30329 loss= 0.00020142371067777276\n",
      "test_data MSELoss:(pred-real)/real= 0.00015703138487879186\n",
      "epoch= 632 iteration= 30337 loss= 0.000739015347789973\n",
      "epoch= 632 iteration= 30357 loss= 0.00035418098559603095\n",
      "epoch= 632 iteration= 30377 loss= 0.00020109754404984415\n",
      "test_data MSELoss:(pred-real)/real= 0.0001568609401147114\n",
      "epoch= 633 iteration= 30385 loss= 0.0007381097530014813\n",
      "epoch= 633 iteration= 30405 loss= 0.00035398188629187644\n",
      "epoch= 633 iteration= 30425 loss= 0.00020066821889486164\n",
      "test_data MSELoss:(pred-real)/real= 0.0001567441868246533\n",
      "epoch= 634 iteration= 30433 loss= 0.0007375907152891159\n",
      "epoch= 634 iteration= 30453 loss= 0.000353990588337183\n",
      "epoch= 634 iteration= 30473 loss= 0.00020059029338881373\n",
      "test_data MSELoss:(pred-real)/real= 0.00015664174970879684\n",
      "epoch= 635 iteration= 30481 loss= 0.0007369670202024281\n",
      "epoch= 635 iteration= 30501 loss= 0.0003541499318089336\n",
      "epoch= 635 iteration= 30521 loss= 0.0002003574336413294\n",
      "test_data MSELoss:(pred-real)/real= 0.00015654291491955518\n",
      "epoch= 636 iteration= 30529 loss= 0.0007366133504547179\n",
      "epoch= 636 iteration= 30549 loss= 0.0003542079939506948\n",
      "epoch= 636 iteration= 30569 loss= 0.00019989846623502672\n",
      "test_data MSELoss:(pred-real)/real= 0.00015642068537999876\n",
      "epoch= 637 iteration= 30577 loss= 0.000735849782358855\n",
      "epoch= 637 iteration= 30597 loss= 0.000354281859472394\n",
      "epoch= 637 iteration= 30617 loss= 0.00019977628835476935\n",
      "test_data MSELoss:(pred-real)/real= 0.00015631013957317919\n",
      "epoch= 638 iteration= 30625 loss= 0.0007349624065682292\n",
      "epoch= 638 iteration= 30645 loss= 0.00035457900958135724\n",
      "epoch= 638 iteration= 30665 loss= 0.00019929457630496472\n",
      "test_data MSELoss:(pred-real)/real= 0.00015625424166501034\n",
      "epoch= 639 iteration= 30673 loss= 0.0007345968042500317\n",
      "epoch= 639 iteration= 30693 loss= 0.00035482164821587503\n",
      "epoch= 639 iteration= 30713 loss= 0.00019905918452423066\n",
      "test_data MSELoss:(pred-real)/real= 0.0001561878587381216\n",
      "epoch= 640 iteration= 30721 loss= 0.0007341732271015644\n",
      "epoch= 640 iteration= 30741 loss= 0.0003549594839569181\n",
      "epoch= 640 iteration= 30761 loss= 0.00019871070981025696\n",
      "test_data MSELoss:(pred-real)/real= 0.00015613629620929713\n",
      "epoch= 641 iteration= 30769 loss= 0.0007337448769249022\n",
      "epoch= 641 iteration= 30789 loss= 0.00035511539317667484\n",
      "epoch= 641 iteration= 30809 loss= 0.00019850872922688723\n",
      "test_data MSELoss:(pred-real)/real= 0.00015607040113536642\n",
      "epoch= 642 iteration= 30817 loss= 0.0007333082612603903\n",
      "epoch= 642 iteration= 30837 loss= 0.0003554163558874279\n",
      "epoch= 642 iteration= 30857 loss= 0.00019842557958327234\n",
      "test_data MSELoss:(pred-real)/real= 0.00015600804072164466\n",
      "epoch= 643 iteration= 30865 loss= 0.0007324795587919652\n",
      "epoch= 643 iteration= 30885 loss= 0.00035558920353651047\n",
      "epoch= 643 iteration= 30905 loss= 0.0001978894288185984\n",
      "test_data MSELoss:(pred-real)/real= 0.00015595021504850594\n",
      "epoch= 644 iteration= 30913 loss= 0.0007319975411519408\n",
      "epoch= 644 iteration= 30933 loss= 0.00035573699278756976\n",
      "epoch= 644 iteration= 30953 loss= 0.00019767429330386221\n",
      "test_data MSELoss:(pred-real)/real= 0.00015591107221553103\n",
      "epoch= 645 iteration= 30961 loss= 0.0007314032409340143\n",
      "epoch= 645 iteration= 30981 loss= 0.00035607744939625263\n",
      "epoch= 645 iteration= 31001 loss= 0.00019742533913813531\n",
      "test_data MSELoss:(pred-real)/real= 0.0001558941468829289\n",
      "epoch= 646 iteration= 31009 loss= 0.0007312685484066606\n",
      "epoch= 646 iteration= 31029 loss= 0.0003562641213648021\n",
      "epoch= 646 iteration= 31049 loss= 0.00019706955936271697\n",
      "test_data MSELoss:(pred-real)/real= 0.00015581758088956121\n",
      "epoch= 647 iteration= 31057 loss= 0.0007304198225028813\n",
      "epoch= 647 iteration= 31077 loss= 0.00035635672975331545\n",
      "epoch= 647 iteration= 31097 loss= 0.00019681859703268856\n",
      "test_data MSELoss:(pred-real)/real= 0.00015578909224132076\n",
      "epoch= 648 iteration= 31105 loss= 0.0007296882104128599\n",
      "epoch= 648 iteration= 31125 loss= 0.0003565027145668864\n",
      "epoch= 648 iteration= 31145 loss= 0.0001964281836990267\n",
      "test_data MSELoss:(pred-real)/real= 0.00015574287172057666\n",
      "epoch= 649 iteration= 31153 loss= 0.0007293774397112429\n",
      "epoch= 649 iteration= 31173 loss= 0.00035651586949825287\n",
      "epoch= 649 iteration= 31193 loss= 0.00019617988436948508\n",
      "test_data MSELoss:(pred-real)/real= 0.00015568863273074385\n",
      "epoch= 650 iteration= 31201 loss= 0.0007286487962119281\n",
      "epoch= 650 iteration= 31221 loss= 0.0003566900850273669\n",
      "epoch= 650 iteration= 31241 loss= 0.00019576579506974667\n",
      "test_data MSELoss:(pred-real)/real= 0.000155674152483698\n",
      "epoch= 651 iteration= 31249 loss= 0.0007279939018189907\n",
      "epoch= 651 iteration= 31269 loss= 0.0003567368257790804\n",
      "epoch= 651 iteration= 31289 loss= 0.00019558830535970628\n",
      "test_data MSELoss:(pred-real)/real= 0.00015559619860141538\n",
      "epoch= 652 iteration= 31297 loss= 0.0007272879593074322\n",
      "epoch= 652 iteration= 31317 loss= 0.00035685300827026367\n",
      "epoch= 652 iteration= 31337 loss= 0.0001953770115505904\n",
      "test_data MSELoss:(pred-real)/real= 0.00015558484701614362\n",
      "epoch= 653 iteration= 31345 loss= 0.0007262651342898607\n",
      "epoch= 653 iteration= 31365 loss= 0.0003568833344615996\n",
      "epoch= 653 iteration= 31385 loss= 0.00019507278921082616\n",
      "test_data MSELoss:(pred-real)/real= 0.00015553135963273235\n",
      "epoch= 654 iteration= 31393 loss= 0.0007252914365381002\n",
      "epoch= 654 iteration= 31413 loss= 0.0003567381063476205\n",
      "epoch= 654 iteration= 31433 loss= 0.00019474313012324274\n",
      "test_data MSELoss:(pred-real)/real= 0.00015545364512945526\n",
      "epoch= 655 iteration= 31441 loss= 0.0007242618594318628\n",
      "epoch= 655 iteration= 31461 loss= 0.0003569194523151964\n",
      "epoch= 655 iteration= 31481 loss= 0.00019436998991295695\n",
      "test_data MSELoss:(pred-real)/real= 0.0001554425820359029\n",
      "epoch= 656 iteration= 31489 loss= 0.0007232215721160173\n",
      "epoch= 656 iteration= 31509 loss= 0.0003570013213902712\n",
      "epoch= 656 iteration= 31529 loss= 0.00019434656132943928\n",
      "test_data MSELoss:(pred-real)/real= 0.00015537070648861118\n",
      "epoch= 657 iteration= 31537 loss= 0.000722153577953577\n",
      "epoch= 657 iteration= 31557 loss= 0.0003570077533368021\n",
      "epoch= 657 iteration= 31577 loss= 0.00019390507077332586\n",
      "test_data MSELoss:(pred-real)/real= 0.00015527905561611987\n",
      "epoch= 658 iteration= 31585 loss= 0.0007208865135908127\n",
      "epoch= 658 iteration= 31605 loss= 0.00035748022492043674\n",
      "epoch= 658 iteration= 31625 loss= 0.00019367282220628113\n",
      "test_data MSELoss:(pred-real)/real= 0.00015525950875598936\n",
      "epoch= 659 iteration= 31633 loss= 0.0007199818501248956\n",
      "epoch= 659 iteration= 31653 loss= 0.00035761011531576514\n",
      "epoch= 659 iteration= 31673 loss= 0.00019346547196619213\n",
      "test_data MSELoss:(pred-real)/real= 0.0001551836779981386\n",
      "epoch= 660 iteration= 31681 loss= 0.0007185232825577259\n",
      "epoch= 660 iteration= 31701 loss= 0.00035799306351691484\n",
      "epoch= 660 iteration= 31721 loss= 0.00019327644258737564\n",
      "test_data MSELoss:(pred-real)/real= 0.00015508126343775075\n",
      "epoch= 661 iteration= 31729 loss= 0.0007173285121098161\n",
      "epoch= 661 iteration= 31749 loss= 0.0003582639910746366\n",
      "epoch= 661 iteration= 31769 loss= 0.00019302070722915232\n",
      "test_data MSELoss:(pred-real)/real= 0.00015505648152611685\n",
      "epoch= 662 iteration= 31777 loss= 0.0007160881068557501\n",
      "epoch= 662 iteration= 31797 loss= 0.00035907438723370433\n",
      "epoch= 662 iteration= 31817 loss= 0.0001927429693751037\n",
      "test_data MSELoss:(pred-real)/real= 0.00015496116575377527\n",
      "epoch= 663 iteration= 31825 loss= 0.0007149671437218785\n",
      "epoch= 663 iteration= 31845 loss= 0.00035976810613647103\n",
      "epoch= 663 iteration= 31865 loss= 0.00019263639114797115\n",
      "test_data MSELoss:(pred-real)/real= 0.00015488643839489669\n",
      "epoch= 664 iteration= 31873 loss= 0.0007137240027077496\n",
      "epoch= 664 iteration= 31893 loss= 0.00036078866105526686\n",
      "epoch= 664 iteration= 31913 loss= 0.0001925801916513592\n",
      "test_data MSELoss:(pred-real)/real= 0.00015479152716579847\n",
      "epoch= 665 iteration= 31921 loss= 0.0007126720156520605\n",
      "epoch= 665 iteration= 31941 loss= 0.0003621403011493385\n",
      "epoch= 665 iteration= 31961 loss= 0.00019229500321671367\n",
      "test_data MSELoss:(pred-real)/real= 0.00015472059894818812\n",
      "epoch= 666 iteration= 31969 loss= 0.0007112759631127119\n",
      "epoch= 666 iteration= 31989 loss= 0.00036374141927808523\n",
      "epoch= 666 iteration= 32009 loss= 0.00019215926295146346\n",
      "test_data MSELoss:(pred-real)/real= 0.0001545446411910234\n",
      "epoch= 667 iteration= 32017 loss= 0.0007103037787601352\n",
      "epoch= 667 iteration= 32037 loss= 0.0003657782799564302\n",
      "epoch= 667 iteration= 32057 loss= 0.000191995786735788\n",
      "test_data MSELoss:(pred-real)/real= 0.00015444959353771992\n",
      "epoch= 668 iteration= 32065 loss= 0.0007093630847521126\n",
      "epoch= 668 iteration= 32085 loss= 0.0003685305709950626\n",
      "epoch= 668 iteration= 32105 loss= 0.00019190338207408786\n",
      "test_data MSELoss:(pred-real)/real= 0.00015429713894263842\n",
      "epoch= 669 iteration= 32113 loss= 0.0007081340299919248\n",
      "epoch= 669 iteration= 32133 loss= 0.00037226825952529907\n",
      "epoch= 669 iteration= 32153 loss= 0.0001918286143336445\n",
      "test_data MSELoss:(pred-real)/real= 0.00015412385400850325\n",
      "epoch= 670 iteration= 32161 loss= 0.0007073106244206429\n",
      "epoch= 670 iteration= 32181 loss= 0.00037723270361311734\n",
      "epoch= 670 iteration= 32201 loss= 0.0001915152242872864\n",
      "test_data MSELoss:(pred-real)/real= 0.00015391834458569064\n",
      "epoch= 671 iteration= 32209 loss= 0.0007065244135446846\n",
      "epoch= 671 iteration= 32229 loss= 0.00038343138294294477\n",
      "epoch= 671 iteration= 32249 loss= 0.00019112462177872658\n",
      "test_data MSELoss:(pred-real)/real= 0.00015373107089544646\n",
      "epoch= 672 iteration= 32257 loss= 0.0007056068861857057\n",
      "epoch= 672 iteration= 32277 loss= 0.0003909424995072186\n",
      "epoch= 672 iteration= 32297 loss= 0.00019101888756267726\n",
      "test_data MSELoss:(pred-real)/real= 0.00015354717870650348\n",
      "epoch= 673 iteration= 32305 loss= 0.0007046652608551085\n",
      "epoch= 673 iteration= 32325 loss= 0.0004000525805167854\n",
      "epoch= 673 iteration= 32345 loss= 0.00019067220273427665\n",
      "test_data MSELoss:(pred-real)/real= 0.00015340355457738042\n",
      "epoch= 674 iteration= 32353 loss= 0.0007045080419629812\n",
      "epoch= 674 iteration= 32373 loss= 0.00040867715142667294\n",
      "epoch= 674 iteration= 32393 loss= 0.00019035706645809114\n",
      "test_data MSELoss:(pred-real)/real= 0.00015330815258494113\n",
      "epoch= 675 iteration= 32401 loss= 0.0007058166083879769\n",
      "epoch= 675 iteration= 32421 loss= 0.00041542158578522503\n",
      "epoch= 675 iteration= 32441 loss= 0.00019029100076295435\n",
      "test_data MSELoss:(pred-real)/real= 0.0001532365055027185\n",
      "epoch= 676 iteration= 32449 loss= 0.000708154053427279\n",
      "epoch= 676 iteration= 32469 loss= 0.0004173445049673319\n",
      "epoch= 676 iteration= 32489 loss= 0.0001901774958241731\n",
      "test_data MSELoss:(pred-real)/real= 0.00015325766398746054\n",
      "epoch= 677 iteration= 32497 loss= 0.0007109848666004837\n",
      "epoch= 677 iteration= 32517 loss= 0.00041400277405045927\n",
      "epoch= 677 iteration= 32537 loss= 0.00019005461945198476\n",
      "test_data MSELoss:(pred-real)/real= 0.00015330747519328724\n",
      "epoch= 678 iteration= 32545 loss= 0.000713014742359519\n",
      "epoch= 678 iteration= 32565 loss= 0.0004064490494783968\n",
      "epoch= 678 iteration= 32585 loss= 0.0001894645392894745\n",
      "test_data MSELoss:(pred-real)/real= 0.0001534460054244846\n",
      "epoch= 679 iteration= 32593 loss= 0.0007127947174012661\n",
      "epoch= 679 iteration= 32613 loss= 0.0003968548262491822\n",
      "epoch= 679 iteration= 32633 loss= 0.00018882521544583142\n",
      "test_data MSELoss:(pred-real)/real= 0.00015380410877696704\n",
      "epoch= 680 iteration= 32641 loss= 0.0007104369578883052\n",
      "epoch= 680 iteration= 32661 loss= 0.00038733435212634504\n",
      "epoch= 680 iteration= 32681 loss= 0.00018795483629219234\n",
      "test_data MSELoss:(pred-real)/real= 0.00015448895101144444\n",
      "epoch= 681 iteration= 32689 loss= 0.0007069676648825407\n",
      "epoch= 681 iteration= 32709 loss= 0.00038007384864613414\n",
      "epoch= 681 iteration= 32729 loss= 0.00018750397430267185\n",
      "test_data MSELoss:(pred-real)/real= 0.00015550867865385954\n",
      "epoch= 682 iteration= 32737 loss= 0.0007031309651210904\n",
      "epoch= 682 iteration= 32757 loss= 0.00037507250090129673\n",
      "epoch= 682 iteration= 32777 loss= 0.00018657042528502643\n",
      "test_data MSELoss:(pred-real)/real= 0.0001567845742101781\n",
      "epoch= 683 iteration= 32785 loss= 0.0007002898491919041\n",
      "epoch= 683 iteration= 32805 loss= 0.0003722515539266169\n",
      "epoch= 683 iteration= 32825 loss= 0.00018590915715321898\n",
      "test_data MSELoss:(pred-real)/real= 0.00015809806136530825\n",
      "epoch= 684 iteration= 32833 loss= 0.0006982630002312362\n",
      "epoch= 684 iteration= 32853 loss= 0.0003702814574353397\n",
      "epoch= 684 iteration= 32873 loss= 0.00018516991985961795\n",
      "test_data MSELoss:(pred-real)/real= 0.00015943286271067337\n",
      "epoch= 685 iteration= 32881 loss= 0.0006975231226533651\n",
      "epoch= 685 iteration= 32901 loss= 0.00036900542909279466\n",
      "epoch= 685 iteration= 32921 loss= 0.00018480358994565904\n",
      "test_data MSELoss:(pred-real)/real= 0.0001606048292160267\n",
      "epoch= 686 iteration= 32929 loss= 0.0006981083424761891\n",
      "epoch= 686 iteration= 32949 loss= 0.00036740273935720325\n",
      "epoch= 686 iteration= 32969 loss= 0.0001842149067670107\n",
      "test_data MSELoss:(pred-real)/real= 0.00016165427878149784\n",
      "epoch= 687 iteration= 32977 loss= 0.0006989679532125592\n",
      "epoch= 687 iteration= 32997 loss= 0.0003647737321443856\n",
      "epoch= 687 iteration= 33017 loss= 0.00018374442879576236\n",
      "test_data MSELoss:(pred-real)/real= 0.00016249492873612325\n",
      "epoch= 688 iteration= 33025 loss= 0.000701237702742219\n",
      "epoch= 688 iteration= 33045 loss= 0.00036121823359280825\n",
      "epoch= 688 iteration= 33065 loss= 0.00018330448074266315\n",
      "test_data MSELoss:(pred-real)/real= 0.00016337168344762176\n",
      "epoch= 689 iteration= 33073 loss= 0.0007029719999991357\n",
      "epoch= 689 iteration= 33093 loss= 0.0003576297021936625\n",
      "epoch= 689 iteration= 33113 loss= 0.00018296140478923917\n",
      "test_data MSELoss:(pred-real)/real= 0.0001644229021621868\n",
      "epoch= 690 iteration= 33121 loss= 0.0007044344674795866\n",
      "epoch= 690 iteration= 33141 loss= 0.0003545209183357656\n",
      "epoch= 690 iteration= 33161 loss= 0.00018287025159224868\n",
      "test_data MSELoss:(pred-real)/real= 0.00016547000377613584\n",
      "epoch= 691 iteration= 33169 loss= 0.0007057621842250228\n",
      "epoch= 691 iteration= 33189 loss= 0.0003529535315465182\n",
      "epoch= 691 iteration= 33209 loss= 0.0001826998923206702\n",
      "test_data MSELoss:(pred-real)/real= 0.00016654124738124665\n",
      "epoch= 692 iteration= 33217 loss= 0.0007066485704854131\n",
      "epoch= 692 iteration= 33237 loss= 0.00035321718314662576\n",
      "epoch= 692 iteration= 33257 loss= 0.00018285316764377058\n",
      "test_data MSELoss:(pred-real)/real= 0.00016745788307162\n",
      "epoch= 693 iteration= 33265 loss= 0.0007067060214467347\n",
      "epoch= 693 iteration= 33285 loss= 0.00035573774948716164\n",
      "epoch= 693 iteration= 33305 loss= 0.00018284967518411577\n",
      "test_data MSELoss:(pred-real)/real= 0.0001681906040175818\n",
      "epoch= 694 iteration= 33313 loss= 0.0007069658022373915\n",
      "epoch= 694 iteration= 33333 loss= 0.00035963807022199035\n",
      "epoch= 694 iteration= 33353 loss= 0.00018301268573850393\n",
      "test_data MSELoss:(pred-real)/real= 0.00016858147173479666\n",
      "epoch= 695 iteration= 33361 loss= 0.0007071366999298334\n",
      "epoch= 695 iteration= 33381 loss= 0.00036555383121594787\n",
      "epoch= 695 iteration= 33401 loss= 0.00018322016694583\n",
      "test_data MSELoss:(pred-real)/real= 0.0001684737089817645\n",
      "epoch= 696 iteration= 33409 loss= 0.0007076674373820424\n",
      "epoch= 696 iteration= 33429 loss= 0.0003725725691765547\n",
      "epoch= 696 iteration= 33449 loss= 0.00018353195628151298\n",
      "test_data MSELoss:(pred-real)/real= 0.00016796294912637677\n",
      "epoch= 697 iteration= 33457 loss= 0.0007077764021232724\n",
      "epoch= 697 iteration= 33477 loss= 0.0003810271737165749\n",
      "epoch= 697 iteration= 33497 loss= 0.0001837356248870492\n",
      "test_data MSELoss:(pred-real)/real= 0.00016705421585356818\n",
      "epoch= 698 iteration= 33505 loss= 0.0007076060865074396\n",
      "epoch= 698 iteration= 33525 loss= 0.0003896835260093212\n",
      "epoch= 698 iteration= 33545 loss= 0.00018367913435213268\n",
      "test_data MSELoss:(pred-real)/real= 0.00016572918138990644\n",
      "epoch= 699 iteration= 33553 loss= 0.0007076175534166396\n",
      "epoch= 699 iteration= 33573 loss= 0.000398255477193743\n",
      "epoch= 699 iteration= 33593 loss= 0.0001835791626945138\n",
      "test_data MSELoss:(pred-real)/real= 0.00016407046641688793\n",
      "epoch= 700 iteration= 33601 loss= 0.0007072371081449091\n",
      "epoch= 700 iteration= 33621 loss= 0.0004056172911077738\n",
      "epoch= 700 iteration= 33641 loss= 0.00018320434901397675\n",
      "test_data MSELoss:(pred-real)/real= 0.0001622141648113029\n",
      "epoch= 701 iteration= 33649 loss= 0.0007065397221595049\n",
      "epoch= 701 iteration= 33669 loss= 0.00041093170875683427\n",
      "epoch= 701 iteration= 33689 loss= 0.00018281067605130374\n",
      "test_data MSELoss:(pred-real)/real= 0.0001603297278052196\n",
      "epoch= 702 iteration= 33697 loss= 0.0007060025818645954\n",
      "epoch= 702 iteration= 33717 loss= 0.0004137195646762848\n",
      "epoch= 702 iteration= 33737 loss= 0.00018227603868581355\n",
      "test_data MSELoss:(pred-real)/real= 0.0001586842096003238\n",
      "epoch= 703 iteration= 33745 loss= 0.000704933307133615\n",
      "epoch= 703 iteration= 33765 loss= 0.0004124870174564421\n",
      "epoch= 703 iteration= 33785 loss= 0.00018140174506697804\n",
      "test_data MSELoss:(pred-real)/real= 0.00015731260209577157\n",
      "epoch= 704 iteration= 33793 loss= 0.0007043217774480581\n",
      "epoch= 704 iteration= 33813 loss= 0.00040796585381031036\n",
      "epoch= 704 iteration= 33833 loss= 0.00018083318718709052\n",
      "test_data MSELoss:(pred-real)/real= 0.0001564889713336015\n",
      "epoch= 705 iteration= 33841 loss= 0.0007034380687400699\n",
      "epoch= 705 iteration= 33861 loss= 0.00040033782715909183\n",
      "epoch= 705 iteration= 33881 loss= 0.00018032928346656263\n",
      "test_data MSELoss:(pred-real)/real= 0.00015618813558830879\n",
      "epoch= 706 iteration= 33889 loss= 0.0007028896361589432\n",
      "epoch= 706 iteration= 33909 loss= 0.0003904302720911801\n",
      "epoch= 706 iteration= 33929 loss= 0.0001799821329768747\n",
      "test_data MSELoss:(pred-real)/real= 0.00015641724494344089\n",
      "epoch= 707 iteration= 33937 loss= 0.000702223158441484\n",
      "epoch= 707 iteration= 33957 loss= 0.00037969296681694686\n",
      "epoch= 707 iteration= 33977 loss= 0.0001801266917027533\n",
      "test_data MSELoss:(pred-real)/real= 0.00015695077090640552\n",
      "epoch= 708 iteration= 33985 loss= 0.0007014849106781185\n",
      "epoch= 708 iteration= 34005 loss= 0.00036923924926668406\n",
      "epoch= 708 iteration= 34025 loss= 0.00018018305127043277\n",
      "test_data MSELoss:(pred-real)/real= 0.00015767670520290268\n",
      "epoch= 709 iteration= 34033 loss= 0.0007002257625572383\n",
      "epoch= 709 iteration= 34053 loss= 0.0003607633989304304\n",
      "epoch= 709 iteration= 34073 loss= 0.00018091427045874298\n",
      "test_data MSELoss:(pred-real)/real= 0.00015839577099541202\n",
      "epoch= 710 iteration= 34081 loss= 0.0006979912286624312\n",
      "epoch= 710 iteration= 34101 loss= 0.000354805844835937\n",
      "epoch= 710 iteration= 34121 loss= 0.00018159934552386403\n",
      "test_data MSELoss:(pred-real)/real= 0.00015887681365711614\n",
      "epoch= 711 iteration= 34129 loss= 0.0006951597752049565\n",
      "epoch= 711 iteration= 34149 loss= 0.0003522450278978795\n",
      "epoch= 711 iteration= 34169 loss= 0.00018201980856247246\n",
      "test_data MSELoss:(pred-real)/real= 0.00015914601099211722\n",
      "epoch= 712 iteration= 34177 loss= 0.0006923407781869173\n",
      "epoch= 712 iteration= 34197 loss= 0.00035260990262031555\n",
      "epoch= 712 iteration= 34217 loss= 0.00018286099657416344\n",
      "test_data MSELoss:(pred-real)/real= 0.000159121169053833\n",
      "epoch= 713 iteration= 34225 loss= 0.0006889732321724296\n",
      "epoch= 713 iteration= 34245 loss= 0.00035581173142418265\n",
      "epoch= 713 iteration= 34265 loss= 0.00018328221631236374\n",
      "test_data MSELoss:(pred-real)/real= 0.00015891256043687463\n",
      "epoch= 714 iteration= 34273 loss= 0.0006863378221169114\n",
      "epoch= 714 iteration= 34293 loss= 0.0003609363338910043\n",
      "epoch= 714 iteration= 34313 loss= 0.00018362932314630598\n",
      "test_data MSELoss:(pred-real)/real= 0.00015838339131732937\n",
      "epoch= 715 iteration= 34321 loss= 0.0006834695814177394\n",
      "epoch= 715 iteration= 34341 loss= 0.00036766985431313515\n",
      "epoch= 715 iteration= 34361 loss= 0.0001840072509367019\n",
      "test_data MSELoss:(pred-real)/real= 0.00015781512192916125\n",
      "epoch= 716 iteration= 34369 loss= 0.0006811015191487968\n",
      "epoch= 716 iteration= 34389 loss= 0.0003747817245312035\n",
      "epoch= 716 iteration= 34409 loss= 0.00018407564493827522\n",
      "test_data MSELoss:(pred-real)/real= 0.0001570677224663086\n",
      "epoch= 717 iteration= 34417 loss= 0.0006793091306462884\n",
      "epoch= 717 iteration= 34437 loss= 0.00038144062273204327\n",
      "epoch= 717 iteration= 34457 loss= 0.00018383044516667724\n",
      "test_data MSELoss:(pred-real)/real= 0.0001561753779242281\n",
      "epoch= 718 iteration= 34465 loss= 0.0006784569704905152\n",
      "epoch= 718 iteration= 34485 loss= 0.00038699584547430277\n",
      "epoch= 718 iteration= 34505 loss= 0.0001837840536609292\n",
      "test_data MSELoss:(pred-real)/real= 0.00015528291078226175\n",
      "epoch= 719 iteration= 34513 loss= 0.000677487114444375\n",
      "epoch= 719 iteration= 34533 loss= 0.00039107943302951753\n",
      "epoch= 719 iteration= 34553 loss= 0.00018312004976905882\n",
      "test_data MSELoss:(pred-real)/real= 0.0001543871381727513\n",
      "epoch= 720 iteration= 34561 loss= 0.0006770578911527991\n",
      "epoch= 720 iteration= 34581 loss= 0.0003937419969588518\n",
      "epoch= 720 iteration= 34601 loss= 0.0001825741201173514\n",
      "test_data MSELoss:(pred-real)/real= 0.00015361898149421905\n",
      "epoch= 721 iteration= 34609 loss= 0.0006770986365154386\n",
      "epoch= 721 iteration= 34629 loss= 0.00039464724250137806\n",
      "epoch= 721 iteration= 34649 loss= 0.0001815294672269374\n",
      "test_data MSELoss:(pred-real)/real= 0.00015299776605388616\n",
      "epoch= 722 iteration= 34657 loss= 0.0006776480586268008\n",
      "epoch= 722 iteration= 34677 loss= 0.00039337470661848783\n",
      "epoch= 722 iteration= 34697 loss= 0.00018060824368149042\n",
      "test_data MSELoss:(pred-real)/real= 0.0001525586507341359\n",
      "epoch= 723 iteration= 34705 loss= 0.0006779045797884464\n",
      "epoch= 723 iteration= 34725 loss= 0.0003910528030246496\n",
      "epoch= 723 iteration= 34745 loss= 0.00017956401279661804\n",
      "test_data MSELoss:(pred-real)/real= 0.00015239402746374252\n",
      "epoch= 724 iteration= 34753 loss= 0.0006783520220778883\n",
      "epoch= 724 iteration= 34773 loss= 0.00038706231862306595\n",
      "epoch= 724 iteration= 34793 loss= 0.0001785229833330959\n",
      "test_data MSELoss:(pred-real)/real= 0.00015243975212797523\n",
      "epoch= 725 iteration= 34801 loss= 0.0006789484759792686\n",
      "epoch= 725 iteration= 34821 loss= 0.0003823714214377105\n",
      "epoch= 725 iteration= 34841 loss= 0.0001775714918039739\n",
      "test_data MSELoss:(pred-real)/real= 0.0001526852534880163\n",
      "epoch= 726 iteration= 34849 loss= 0.0006791660562157631\n",
      "epoch= 726 iteration= 34869 loss= 0.0003769807517528534\n",
      "epoch= 726 iteration= 34889 loss= 0.0001765941851772368\n",
      "test_data MSELoss:(pred-real)/real= 0.00015310208837036044\n",
      "epoch= 727 iteration= 34897 loss= 0.0006788985338062048\n",
      "epoch= 727 iteration= 34917 loss= 0.0003715252969413996\n",
      "epoch= 727 iteration= 34937 loss= 0.00017563134315423667\n",
      "test_data MSELoss:(pred-real)/real= 0.00015369278880825732\n",
      "epoch= 728 iteration= 34945 loss= 0.000678920594509691\n",
      "epoch= 728 iteration= 34965 loss= 0.0003665282274596393\n",
      "epoch= 728 iteration= 34985 loss= 0.00017481633403804153\n",
      "test_data MSELoss:(pred-real)/real= 0.00015435666282428428\n",
      "epoch= 729 iteration= 34993 loss= 0.0006785646546632051\n",
      "epoch= 729 iteration= 35013 loss= 0.00036179914604872465\n",
      "epoch= 729 iteration= 35033 loss= 0.00017403814126737416\n",
      "test_data MSELoss:(pred-real)/real= 0.00015503509421250784\n",
      "epoch= 730 iteration= 35041 loss= 0.0006785772857256234\n",
      "epoch= 730 iteration= 35061 loss= 0.00035764099447987974\n",
      "epoch= 730 iteration= 35081 loss= 0.0001735808327794075\n",
      "test_data MSELoss:(pred-real)/real= 0.00015568182134302334\n",
      "epoch= 731 iteration= 35089 loss= 0.0006776624359190464\n",
      "epoch= 731 iteration= 35109 loss= 0.000354176590917632\n",
      "epoch= 731 iteration= 35129 loss= 0.00017288037633989006\n",
      "test_data MSELoss:(pred-real)/real= 0.0001563950485433452\n",
      "epoch= 732 iteration= 35137 loss= 0.0006770375184714794\n",
      "epoch= 732 iteration= 35157 loss= 0.0003514430718496442\n",
      "epoch= 732 iteration= 35177 loss= 0.0001724456815281883\n",
      "test_data MSELoss:(pred-real)/real= 0.0001569937914609909\n",
      "epoch= 733 iteration= 35185 loss= 0.0006764817517250776\n",
      "epoch= 733 iteration= 35205 loss= 0.0003493520198389888\n",
      "epoch= 733 iteration= 35225 loss= 0.00017215966363437474\n",
      "test_data MSELoss:(pred-real)/real= 0.00015742238974780776\n",
      "epoch= 734 iteration= 35233 loss= 0.0006757744122296572\n",
      "epoch= 734 iteration= 35253 loss= 0.00034824281465262175\n",
      "epoch= 734 iteration= 35273 loss= 0.00017156568355858326\n",
      "test_data MSELoss:(pred-real)/real= 0.0001578002247697441\n",
      "epoch= 735 iteration= 35281 loss= 0.0006751022301614285\n",
      "epoch= 735 iteration= 35301 loss= 0.00034747138852253556\n",
      "epoch= 735 iteration= 35321 loss= 0.0001713446545181796\n",
      "test_data MSELoss:(pred-real)/real= 0.00015807673844392411\n",
      "epoch= 736 iteration= 35329 loss= 0.0006743952399119735\n",
      "epoch= 736 iteration= 35349 loss= 0.0003471693489700556\n",
      "epoch= 736 iteration= 35369 loss= 0.00017109562759287655\n",
      "test_data MSELoss:(pred-real)/real= 0.00015831015225558075\n",
      "epoch= 737 iteration= 35377 loss= 0.0006737455842085183\n",
      "epoch= 737 iteration= 35397 loss= 0.0003473276738077402\n",
      "epoch= 737 iteration= 35417 loss= 0.00017063578707166016\n",
      "test_data MSELoss:(pred-real)/real= 0.00015838240506127477\n",
      "epoch= 738 iteration= 35425 loss= 0.0006731490138918161\n",
      "epoch= 738 iteration= 35445 loss= 0.0003478323924355209\n",
      "epoch= 738 iteration= 35465 loss= 0.00017037535144481808\n",
      "test_data MSELoss:(pred-real)/real= 0.0001583395973284496\n",
      "epoch= 739 iteration= 35473 loss= 0.000672312336973846\n",
      "epoch= 739 iteration= 35493 loss= 0.00034834141843020916\n",
      "epoch= 739 iteration= 35513 loss= 0.00016996776685118675\n",
      "test_data MSELoss:(pred-real)/real= 0.00015827005699975416\n",
      "epoch= 740 iteration= 35521 loss= 0.0006718066870234907\n",
      "epoch= 740 iteration= 35541 loss= 0.0003490136587060988\n",
      "epoch= 740 iteration= 35561 loss= 0.00016967780538834631\n",
      "test_data MSELoss:(pred-real)/real= 0.0001580526051839115\n",
      "epoch= 741 iteration= 35569 loss= 0.0006710524903610349\n",
      "epoch= 741 iteration= 35589 loss= 0.00034961337223649025\n",
      "epoch= 741 iteration= 35609 loss= 0.00016937904001679271\n",
      "test_data MSELoss:(pred-real)/real= 0.00015778157830936834\n",
      "epoch= 742 iteration= 35617 loss= 0.0006707828724756837\n",
      "epoch= 742 iteration= 35637 loss= 0.0003502258041407913\n",
      "epoch= 742 iteration= 35657 loss= 0.00016910136037040502\n",
      "test_data MSELoss:(pred-real)/real= 0.00015743463809485546\n",
      "epoch= 743 iteration= 35665 loss= 0.0006702528335154057\n",
      "epoch= 743 iteration= 35685 loss= 0.0003503947809804231\n",
      "epoch= 743 iteration= 35705 loss= 0.00016889057587832212\n",
      "test_data MSELoss:(pred-real)/real= 0.00015711576888861601\n",
      "epoch= 744 iteration= 35713 loss= 0.0006697403150610626\n",
      "epoch= 744 iteration= 35733 loss= 0.0003508585796225816\n",
      "epoch= 744 iteration= 35753 loss= 0.0001686397154117003\n",
      "test_data MSELoss:(pred-real)/real= 0.00015676082875870634\n",
      "epoch= 745 iteration= 35761 loss= 0.000669232802465558\n",
      "epoch= 745 iteration= 35781 loss= 0.0003509267116896808\n",
      "epoch= 745 iteration= 35801 loss= 0.0001681671419646591\n",
      "test_data MSELoss:(pred-real)/real= 0.00015639666089555248\n",
      "epoch= 746 iteration= 35809 loss= 0.0006685516564175487\n",
      "epoch= 746 iteration= 35829 loss= 0.0003509430680423975\n",
      "epoch= 746 iteration= 35849 loss= 0.00016795078408904374\n",
      "test_data MSELoss:(pred-real)/real= 0.00015607367058692034\n",
      "epoch= 747 iteration= 35857 loss= 0.0006680293008685112\n",
      "epoch= 747 iteration= 35877 loss= 0.0003507773799356073\n",
      "epoch= 747 iteration= 35897 loss= 0.00016764047904871404\n",
      "test_data MSELoss:(pred-real)/real= 0.00015573442578897811\n",
      "epoch= 748 iteration= 35905 loss= 0.0006676171906292439\n",
      "epoch= 748 iteration= 35925 loss= 0.00035044719697907567\n",
      "epoch= 748 iteration= 35945 loss= 0.0001672635116847232\n",
      "test_data MSELoss:(pred-real)/real= 0.00015542147848464084\n",
      "epoch= 749 iteration= 35953 loss= 0.0006667269626632333\n",
      "epoch= 749 iteration= 35973 loss= 0.00034980056807398796\n",
      "epoch= 749 iteration= 35993 loss= 0.000167069083545357\n",
      "test_data MSELoss:(pred-real)/real= 0.00015516366802330593\n",
      "epoch= 750 iteration= 36001 loss= 0.0006661223014816642\n",
      "epoch= 750 iteration= 36021 loss= 0.0003495354612823576\n",
      "epoch= 750 iteration= 36041 loss= 0.0001667366159381345\n",
      "test_data MSELoss:(pred-real)/real= 0.0001549272896227194\n",
      "epoch= 751 iteration= 36049 loss= 0.0006656404584646225\n",
      "epoch= 751 iteration= 36069 loss= 0.000348891771864146\n",
      "epoch= 751 iteration= 36089 loss= 0.00016641740512568504\n",
      "test_data MSELoss:(pred-real)/real= 0.0001547025367472088\n",
      "epoch= 752 iteration= 36097 loss= 0.0006646941765211523\n",
      "epoch= 752 iteration= 36117 loss= 0.0003482239553704858\n",
      "epoch= 752 iteration= 36137 loss= 0.00016637190128676593\n",
      "test_data MSELoss:(pred-real)/real= 0.0001545444392831996\n",
      "epoch= 753 iteration= 36145 loss= 0.0006643850356340408\n",
      "epoch= 753 iteration= 36165 loss= 0.00034770547063089907\n",
      "epoch= 753 iteration= 36185 loss= 0.00016601575771346688\n",
      "test_data MSELoss:(pred-real)/real= 0.00015440002098330297\n",
      "epoch= 754 iteration= 36193 loss= 0.000663217157125473\n",
      "epoch= 754 iteration= 36213 loss= 0.00034721067640930414\n",
      "epoch= 754 iteration= 36233 loss= 0.00016589103324804455\n",
      "test_data MSELoss:(pred-real)/real= 0.00015430510175065137\n",
      "epoch= 755 iteration= 36241 loss= 0.0006627432885579765\n",
      "epoch= 755 iteration= 36261 loss= 0.0003467759524937719\n",
      "epoch= 755 iteration= 36281 loss= 0.00016541712102480233\n",
      "test_data MSELoss:(pred-real)/real= 0.00015423462718899827\n",
      "epoch= 756 iteration= 36289 loss= 0.0006621610373258591\n",
      "epoch= 756 iteration= 36309 loss= 0.00034663942642509937\n",
      "epoch= 756 iteration= 36329 loss= 0.00016523411613889039\n",
      "test_data MSELoss:(pred-real)/real= 0.000154180813478888\n",
      "epoch= 757 iteration= 36337 loss= 0.0006617086473852396\n",
      "epoch= 757 iteration= 36357 loss= 0.00034627728746272624\n",
      "epoch= 757 iteration= 36377 loss= 0.00016504999075550586\n",
      "test_data MSELoss:(pred-real)/real= 0.00015414453300763853\n",
      "epoch= 758 iteration= 36385 loss= 0.0006609299452975392\n",
      "epoch= 758 iteration= 36405 loss= 0.0003458511782810092\n",
      "epoch= 758 iteration= 36425 loss= 0.00016486557433381677\n",
      "test_data MSELoss:(pred-real)/real= 0.00015413207838719246\n",
      "epoch= 759 iteration= 36433 loss= 0.0006603324436582625\n",
      "epoch= 759 iteration= 36453 loss= 0.0003457450948189944\n",
      "epoch= 759 iteration= 36473 loss= 0.00016470131231471896\n",
      "test_data MSELoss:(pred-real)/real= 0.00015414866284118033\n",
      "epoch= 760 iteration= 36481 loss= 0.0006597383762709796\n",
      "epoch= 760 iteration= 36501 loss= 0.0003454223333392292\n",
      "epoch= 760 iteration= 36521 loss= 0.00016437047452200204\n",
      "test_data MSELoss:(pred-real)/real= 0.00015415764319186563\n",
      "epoch= 761 iteration= 36529 loss= 0.0006594611331820488\n",
      "epoch= 761 iteration= 36549 loss= 0.0003454606921877712\n",
      "epoch= 761 iteration= 36569 loss= 0.00016400357708334923\n",
      "test_data MSELoss:(pred-real)/real= 0.00015416188180097378\n",
      "epoch= 762 iteration= 36577 loss= 0.0006592549616470933\n",
      "epoch= 762 iteration= 36597 loss= 0.00034528999822214246\n",
      "epoch= 762 iteration= 36617 loss= 0.00016404462803620845\n",
      "test_data MSELoss:(pred-real)/real= 0.00015417059257742948\n",
      "epoch= 763 iteration= 36625 loss= 0.0006590010598301888\n",
      "epoch= 763 iteration= 36645 loss= 0.00034511726698838174\n",
      "epoch= 763 iteration= 36665 loss= 0.00016369692457374185\n",
      "test_data MSELoss:(pred-real)/real= 0.000154198949894635\n",
      "epoch= 764 iteration= 36673 loss= 0.0006585186347365379\n",
      "epoch= 764 iteration= 36693 loss= 0.00034512553247623146\n",
      "epoch= 764 iteration= 36713 loss= 0.00016369835066143423\n",
      "test_data MSELoss:(pred-real)/real= 0.00015422538817801978\n",
      "epoch= 765 iteration= 36721 loss= 0.0006579904002137482\n",
      "epoch= 765 iteration= 36741 loss= 0.00034488580422475934\n",
      "epoch= 765 iteration= 36761 loss= 0.0001633752981433645\n",
      "test_data MSELoss:(pred-real)/real= 0.0001542602953122696\n",
      "epoch= 766 iteration= 36769 loss= 0.0006574051221832633\n",
      "epoch= 766 iteration= 36789 loss= 0.0003448477073106915\n",
      "epoch= 766 iteration= 36809 loss= 0.00016320403665304184\n",
      "test_data MSELoss:(pred-real)/real= 0.00015425802375830245\n",
      "epoch= 767 iteration= 36817 loss= 0.0006567601813003421\n",
      "epoch= 767 iteration= 36837 loss= 0.0003446163609623909\n",
      "epoch= 767 iteration= 36857 loss= 0.00016311710351146758\n",
      "test_data MSELoss:(pred-real)/real= 0.00015432657819474115\n",
      "epoch= 768 iteration= 36865 loss= 0.0006559715839102864\n",
      "epoch= 768 iteration= 36885 loss= 0.0003444523026701063\n",
      "epoch= 768 iteration= 36905 loss= 0.00016296633111778647\n",
      "test_data MSELoss:(pred-real)/real= 0.00015432771215273533\n",
      "epoch= 769 iteration= 36913 loss= 0.0006548734963871539\n",
      "epoch= 769 iteration= 36933 loss= 0.000344235566444695\n",
      "epoch= 769 iteration= 36953 loss= 0.00016270365449599922\n",
      "test_data MSELoss:(pred-real)/real= 0.0001543598307762295\n",
      "epoch= 770 iteration= 36961 loss= 0.000654003000818193\n",
      "epoch= 770 iteration= 36981 loss= 0.0003440056461840868\n",
      "epoch= 770 iteration= 37001 loss= 0.00016261302516795695\n",
      "test_data MSELoss:(pred-real)/real= 0.00015435271961905528\n",
      "epoch= 771 iteration= 37009 loss= 0.0006527616060338914\n",
      "epoch= 771 iteration= 37029 loss= 0.0003438867861405015\n",
      "epoch= 771 iteration= 37049 loss= 0.00016220309771597385\n",
      "test_data MSELoss:(pred-real)/real= 0.00015432358741236386\n",
      "epoch= 772 iteration= 37057 loss= 0.0006516987923532724\n",
      "epoch= 772 iteration= 37077 loss= 0.00034360657446086407\n",
      "epoch= 772 iteration= 37097 loss= 0.0001622678537387401\n",
      "test_data MSELoss:(pred-real)/real= 0.00015429180202772841\n",
      "epoch= 773 iteration= 37105 loss= 0.000650427769869566\n",
      "epoch= 773 iteration= 37125 loss= 0.0003433997044339776\n",
      "epoch= 773 iteration= 37145 loss= 0.00016201740072574466\n",
      "test_data MSELoss:(pred-real)/real= 0.0001542124769912334\n",
      "epoch= 774 iteration= 37153 loss= 0.00064965890487656\n",
      "epoch= 774 iteration= 37173 loss= 0.0003431952791288495\n",
      "epoch= 774 iteration= 37193 loss= 0.00016166214481927454\n",
      "test_data MSELoss:(pred-real)/real= 0.00015419110204675234\n",
      "epoch= 775 iteration= 37201 loss= 0.0006487984210252762\n",
      "epoch= 775 iteration= 37221 loss= 0.00034305828739888966\n",
      "epoch= 775 iteration= 37241 loss= 0.00016136323392856866\n",
      "test_data MSELoss:(pred-real)/real= 0.00015417130671266933\n",
      "epoch= 776 iteration= 37249 loss= 0.0006481751915998757\n",
      "epoch= 776 iteration= 37269 loss= 0.00034318797406740487\n",
      "epoch= 776 iteration= 37289 loss= 0.00016096884792204946\n",
      "test_data MSELoss:(pred-real)/real= 0.00015414268636959605\n",
      "epoch= 777 iteration= 37297 loss= 0.0006472475361078978\n",
      "epoch= 777 iteration= 37317 loss= 0.0003432192315813154\n",
      "epoch= 777 iteration= 37337 loss= 0.00016091846919152886\n",
      "test_data MSELoss:(pred-real)/real= 0.00015417934700963088\n",
      "epoch= 778 iteration= 37345 loss= 0.0006466524791903794\n",
      "epoch= 778 iteration= 37365 loss= 0.0003432107041589916\n",
      "epoch= 778 iteration= 37385 loss= 0.000160690673510544\n",
      "test_data MSELoss:(pred-real)/real= 0.0001542017445899546\n",
      "epoch= 779 iteration= 37393 loss= 0.0006458931602537632\n",
      "epoch= 779 iteration= 37413 loss= 0.0003436962724663317\n",
      "epoch= 779 iteration= 37433 loss= 0.00016037370369303972\n",
      "test_data MSELoss:(pred-real)/real= 0.00015427133548655546\n",
      "epoch= 780 iteration= 37441 loss= 0.0006455471739172935\n",
      "epoch= 780 iteration= 37461 loss= 0.0003440649015828967\n",
      "epoch= 780 iteration= 37481 loss= 0.00016028287063818425\n",
      "test_data MSELoss:(pred-real)/real= 0.0001542591824545525\n",
      "epoch= 781 iteration= 37489 loss= 0.0006450657965615392\n",
      "epoch= 781 iteration= 37509 loss= 0.00034458329901099205\n",
      "epoch= 781 iteration= 37529 loss= 0.0001601223339093849\n",
      "test_data MSELoss:(pred-real)/real= 0.00015430131315952167\n",
      "epoch= 782 iteration= 37537 loss= 0.0006442746380344033\n",
      "epoch= 782 iteration= 37557 loss= 0.00034501595655456185\n",
      "epoch= 782 iteration= 37577 loss= 0.00015994944260455668\n",
      "test_data MSELoss:(pred-real)/real= 0.00015431196443387306\n",
      "epoch= 783 iteration= 37585 loss= 0.0006437323754653335\n",
      "epoch= 783 iteration= 37605 loss= 0.0003453145327512175\n",
      "epoch= 783 iteration= 37625 loss= 0.0001598780509084463\n",
      "test_data MSELoss:(pred-real)/real= 0.00015432940017490182\n",
      "epoch= 784 iteration= 37633 loss= 0.0006430515786632895\n",
      "epoch= 784 iteration= 37653 loss= 0.00034583822707645595\n",
      "epoch= 784 iteration= 37673 loss= 0.00015962761244736612\n",
      "test_data MSELoss:(pred-real)/real= 0.00015430104722327087\n",
      "epoch= 785 iteration= 37681 loss= 0.0006423504091799259\n",
      "epoch= 785 iteration= 37701 loss= 0.00034611846785992384\n",
      "epoch= 785 iteration= 37721 loss= 0.00015953124966472387\n",
      "test_data MSELoss:(pred-real)/real= 0.00015418639122799505\n",
      "epoch= 786 iteration= 37729 loss= 0.0006413434166461229\n",
      "epoch= 786 iteration= 37749 loss= 0.00034642836544662714\n",
      "epoch= 786 iteration= 37769 loss= 0.00015934350085444748\n",
      "test_data MSELoss:(pred-real)/real= 0.00015403964098368306\n",
      "epoch= 787 iteration= 37777 loss= 0.0006402480648830533\n",
      "epoch= 787 iteration= 37797 loss= 0.000346967251971364\n",
      "epoch= 787 iteration= 37817 loss= 0.00015909536159597337\n",
      "test_data MSELoss:(pred-real)/real= 0.000153847277033492\n",
      "epoch= 788 iteration= 37825 loss= 0.0006390665657818317\n",
      "epoch= 788 iteration= 37845 loss= 0.0003477638238109648\n",
      "epoch= 788 iteration= 37865 loss= 0.00015871133655309677\n",
      "test_data MSELoss:(pred-real)/real= 0.0001536930758447852\n",
      "epoch= 789 iteration= 37873 loss= 0.0006382836727425456\n",
      "epoch= 789 iteration= 37893 loss= 0.00034874663106165826\n",
      "epoch= 789 iteration= 37913 loss= 0.0001585089194122702\n",
      "test_data MSELoss:(pred-real)/real= 0.00015348325650847982\n",
      "epoch= 790 iteration= 37921 loss= 0.0006372592179104686\n",
      "epoch= 790 iteration= 37941 loss= 0.0003501003375276923\n",
      "epoch= 790 iteration= 37961 loss= 0.0001582364784553647\n",
      "test_data MSELoss:(pred-real)/real= 0.00015323728148359806\n",
      "epoch= 791 iteration= 37969 loss= 0.0006362177082337439\n",
      "epoch= 791 iteration= 37989 loss= 0.0003517839650157839\n",
      "epoch= 791 iteration= 38009 loss= 0.0001580221432959661\n",
      "test_data MSELoss:(pred-real)/real= 0.00015299550505005756\n",
      "epoch= 792 iteration= 38017 loss= 0.0006353026255965233\n",
      "epoch= 792 iteration= 38037 loss= 0.00035356523585505784\n",
      "epoch= 792 iteration= 38057 loss= 0.00015790926408953965\n",
      "test_data MSELoss:(pred-real)/real= 0.00015280610932677519\n",
      "epoch= 793 iteration= 38065 loss= 0.0006346596637740731\n",
      "epoch= 793 iteration= 38085 loss= 0.00035557319642975926\n",
      "epoch= 793 iteration= 38105 loss= 0.00015765336866024882\n",
      "test_data MSELoss:(pred-real)/real= 0.00015263620116456877\n",
      "epoch= 794 iteration= 38113 loss= 0.0006335789803415537\n",
      "epoch= 794 iteration= 38133 loss= 0.00035778951132670045\n",
      "epoch= 794 iteration= 38153 loss= 0.00015711630112491548\n",
      "test_data MSELoss:(pred-real)/real= 0.00015241438231896609\n",
      "epoch= 795 iteration= 38161 loss= 0.0006328286253847182\n",
      "epoch= 795 iteration= 38181 loss= 0.00035984875285066664\n",
      "epoch= 795 iteration= 38201 loss= 0.00015710739535279572\n",
      "test_data MSELoss:(pred-real)/real= 0.00015224939998006448\n",
      "epoch= 796 iteration= 38209 loss= 0.00063228519866243\n",
      "epoch= 796 iteration= 38229 loss= 0.0003619222261477262\n",
      "epoch= 796 iteration= 38249 loss= 0.00015687322593294084\n",
      "test_data MSELoss:(pred-real)/real= 0.00015202427821350283\n",
      "epoch= 797 iteration= 38257 loss= 0.0006312559125944972\n",
      "epoch= 797 iteration= 38277 loss= 0.0003638751804828644\n",
      "epoch= 797 iteration= 38297 loss= 0.00015660698409192264\n",
      "test_data MSELoss:(pred-real)/real= 0.00015177621571638156\n",
      "epoch= 798 iteration= 38305 loss= 0.0006303010159172118\n",
      "epoch= 798 iteration= 38325 loss= 0.0003656957414932549\n",
      "epoch= 798 iteration= 38345 loss= 0.00015620450722053647\n",
      "test_data MSELoss:(pred-real)/real= 0.00015150939543673303\n",
      "epoch= 799 iteration= 38353 loss= 0.0006294866325333714\n",
      "epoch= 799 iteration= 38373 loss= 0.0003670916776172817\n",
      "epoch= 799 iteration= 38393 loss= 0.00015603762585669756\n",
      "test_data MSELoss:(pred-real)/real= 0.0001512337643362116\n",
      "epoch= 800 iteration= 38401 loss= 0.0006284595001488924\n",
      "epoch= 800 iteration= 38421 loss= 0.0003689563600346446\n",
      "epoch= 800 iteration= 38441 loss= 0.00015588669339194894\n",
      "test_data MSELoss:(pred-real)/real= 0.0001509928570158081\n",
      "epoch= 801 iteration= 38449 loss= 0.0006272912723943591\n",
      "epoch= 801 iteration= 38469 loss= 0.00037047197110950947\n",
      "epoch= 801 iteration= 38489 loss= 0.00015561387408524752\n",
      "test_data MSELoss:(pred-real)/real= 0.0001507289500295883\n",
      "epoch= 802 iteration= 38497 loss= 0.0006260701920837164\n",
      "epoch= 802 iteration= 38517 loss= 0.0003722878755070269\n",
      "epoch= 802 iteration= 38537 loss= 0.0001553294132463634\n",
      "test_data MSELoss:(pred-real)/real= 0.00015043719176901504\n",
      "epoch= 803 iteration= 38545 loss= 0.0006246953271329403\n",
      "epoch= 803 iteration= 38565 loss= 0.0003741783439181745\n",
      "epoch= 803 iteration= 38585 loss= 0.0001550601446069777\n",
      "test_data MSELoss:(pred-real)/real= 0.00015013682168500963\n",
      "epoch= 804 iteration= 38593 loss= 0.0006233968306332827\n",
      "epoch= 804 iteration= 38613 loss= 0.00037610885920003057\n",
      "epoch= 804 iteration= 38633 loss= 0.0001547886204207316\n",
      "test_data MSELoss:(pred-real)/real= 0.00014987544309406076\n",
      "epoch= 805 iteration= 38641 loss= 0.0006219313945621252\n",
      "epoch= 805 iteration= 38661 loss= 0.00037840279401279986\n",
      "epoch= 805 iteration= 38681 loss= 0.0001544904225738719\n",
      "test_data MSELoss:(pred-real)/real= 0.00014968302712077276\n",
      "epoch= 806 iteration= 38689 loss= 0.0006205220124684274\n",
      "epoch= 806 iteration= 38709 loss= 0.0003814752562902868\n",
      "epoch= 806 iteration= 38729 loss= 0.000154326728079468\n",
      "test_data MSELoss:(pred-real)/real= 0.00014951531156839337\n",
      "epoch= 807 iteration= 38737 loss= 0.0006192532018758357\n",
      "epoch= 807 iteration= 38757 loss= 0.00038499332731589675\n",
      "epoch= 807 iteration= 38777 loss= 0.00015407594037242234\n",
      "test_data MSELoss:(pred-real)/real= 0.00014938987187633755\n",
      "epoch= 808 iteration= 38785 loss= 0.0006181766511872411\n",
      "epoch= 808 iteration= 38805 loss= 0.00038827001117169857\n",
      "epoch= 808 iteration= 38825 loss= 0.00015363063721451908\n",
      "test_data MSELoss:(pred-real)/real= 0.00014946586779842618\n",
      "epoch= 809 iteration= 38833 loss= 0.0006169489352032542\n",
      "epoch= 809 iteration= 38853 loss= 0.00039239710895344615\n",
      "epoch= 809 iteration= 38873 loss= 0.00015304636326618493\n",
      "test_data MSELoss:(pred-real)/real= 0.0001496271801443072\n",
      "epoch= 810 iteration= 38881 loss= 0.0006166223320178688\n",
      "epoch= 810 iteration= 38901 loss= 0.00039513641968369484\n",
      "epoch= 810 iteration= 38921 loss= 0.00015279356739483774\n",
      "test_data MSELoss:(pred-real)/real= 0.00014999649283709005\n",
      "epoch= 811 iteration= 38929 loss= 0.0006161578930914402\n",
      "epoch= 811 iteration= 38949 loss= 0.0003960976027883589\n",
      "epoch= 811 iteration= 38969 loss= 0.0001519753277534619\n",
      "test_data MSELoss:(pred-real)/real= 0.00015058726821735036\n",
      "epoch= 812 iteration= 38977 loss= 0.0006166900275275111\n",
      "epoch= 812 iteration= 38997 loss= 0.0003938892623409629\n",
      "epoch= 812 iteration= 39017 loss= 0.00015125086065381765\n",
      "test_data MSELoss:(pred-real)/real= 0.00015149199061852413\n",
      "epoch= 813 iteration= 39025 loss= 0.0006174108712002635\n",
      "epoch= 813 iteration= 39045 loss= 0.0003883476310875267\n",
      "epoch= 813 iteration= 39065 loss= 0.00015049238572828472\n",
      "test_data MSELoss:(pred-real)/real= 0.0001528606124338694\n",
      "epoch= 814 iteration= 39073 loss= 0.000618007208686322\n",
      "epoch= 814 iteration= 39093 loss= 0.0003797069366555661\n",
      "epoch= 814 iteration= 39113 loss= 0.00014948417083360255\n",
      "test_data MSELoss:(pred-real)/real= 0.00015462574010598472\n",
      "epoch= 815 iteration= 39121 loss= 0.0006191084976308048\n",
      "epoch= 815 iteration= 39141 loss= 0.00036917300894856453\n",
      "epoch= 815 iteration= 39161 loss= 0.0001486759283579886\n",
      "test_data MSELoss:(pred-real)/real= 0.00015691077169321943\n",
      "epoch= 816 iteration= 39169 loss= 0.0006193864974193275\n",
      "epoch= 816 iteration= 39189 loss= 0.0003586192615330219\n",
      "epoch= 816 iteration= 39209 loss= 0.00014791544526815414\n",
      "test_data MSELoss:(pred-real)/real= 0.00015947265674185474\n",
      "epoch= 817 iteration= 39217 loss= 0.0006200454663485289\n",
      "epoch= 817 iteration= 39237 loss= 0.0003489809460006654\n",
      "epoch= 817 iteration= 39257 loss= 0.00014753072173334658\n",
      "test_data MSELoss:(pred-real)/real= 0.000162059311332996\n",
      "epoch= 818 iteration= 39265 loss= 0.0006202944787219167\n",
      "epoch= 818 iteration= 39285 loss= 0.00034088827669620514\n",
      "epoch= 818 iteration= 39305 loss= 0.00014716724399477243\n",
      "test_data MSELoss:(pred-real)/real= 0.0001646336713747587\n",
      "epoch= 819 iteration= 39313 loss= 0.0006210748688317835\n",
      "epoch= 819 iteration= 39333 loss= 0.0003361610579304397\n",
      "epoch= 819 iteration= 39353 loss= 0.00014734483556821942\n",
      "test_data MSELoss:(pred-real)/real= 0.0001668889744905755\n",
      "epoch= 820 iteration= 39361 loss= 0.0006211366271600127\n",
      "epoch= 820 iteration= 39381 loss= 0.0003354556974954903\n",
      "epoch= 820 iteration= 39401 loss= 0.00014781556092202663\n",
      "test_data MSELoss:(pred-real)/real= 0.00016870496510819067\n",
      "epoch= 821 iteration= 39409 loss= 0.0006214205641299486\n",
      "epoch= 821 iteration= 39429 loss= 0.00033963797613978386\n",
      "epoch= 821 iteration= 39449 loss= 0.0001485257234890014\n",
      "test_data MSELoss:(pred-real)/real= 0.00016989546129480003\n",
      "epoch= 822 iteration= 39457 loss= 0.000621854211203754\n",
      "epoch= 822 iteration= 39477 loss= 0.00034867506474256516\n",
      "epoch= 822 iteration= 39497 loss= 0.00014919858949724585\n",
      "test_data MSELoss:(pred-real)/real= 0.00017019783990690485\n",
      "epoch= 823 iteration= 39505 loss= 0.0006220887298695743\n",
      "epoch= 823 iteration= 39525 loss= 0.0003622631193138659\n",
      "epoch= 823 iteration= 39545 loss= 0.00014996227400843054\n",
      "test_data MSELoss:(pred-real)/real= 0.0001695405582722742\n",
      "epoch= 824 iteration= 39553 loss= 0.0006227368721738458\n",
      "epoch= 824 iteration= 39573 loss= 0.00037969188997521996\n",
      "epoch= 824 iteration= 39593 loss= 0.00015072536189109087\n",
      "test_data MSELoss:(pred-real)/real= 0.0001678211981925415\n",
      "epoch= 825 iteration= 39601 loss= 0.0006236823974177241\n",
      "epoch= 825 iteration= 39621 loss= 0.00039784732507541776\n",
      "epoch= 825 iteration= 39641 loss= 0.00015086635539773852\n",
      "test_data MSELoss:(pred-real)/real= 0.0001649003545026062\n",
      "epoch= 826 iteration= 39649 loss= 0.0006247104611247778\n",
      "epoch= 826 iteration= 39669 loss= 0.0004145274870097637\n",
      "epoch= 826 iteration= 39689 loss= 0.00015036409604363143\n",
      "test_data MSELoss:(pred-real)/real= 0.00016124081193993333\n",
      "epoch= 827 iteration= 39697 loss= 0.0006266834679991007\n",
      "epoch= 827 iteration= 39717 loss= 0.00042602611938491464\n",
      "epoch= 827 iteration= 39737 loss= 0.00014943641144782305\n",
      "test_data MSELoss:(pred-real)/real= 0.00015762112016091124\n",
      "epoch= 828 iteration= 39745 loss= 0.0006291285390034318\n",
      "epoch= 828 iteration= 39765 loss= 0.00042788253631442785\n",
      "epoch= 828 iteration= 39785 loss= 0.00014790770364925265\n",
      "test_data MSELoss:(pred-real)/real= 0.00015443749580299482\n",
      "epoch= 829 iteration= 39793 loss= 0.0006330378819257021\n",
      "epoch= 829 iteration= 39813 loss= 0.0004195479559712112\n",
      "epoch= 829 iteration= 39833 loss= 0.0001465791865484789\n",
      "test_data MSELoss:(pred-real)/real= 0.00015270185722329188\n",
      "epoch= 830 iteration= 39841 loss= 0.0006374531658366323\n",
      "epoch= 830 iteration= 39861 loss= 0.0004028840339742601\n",
      "epoch= 830 iteration= 39881 loss= 0.0001457597390981391\n",
      "test_data MSELoss:(pred-real)/real= 0.0001524610368505819\n",
      "epoch= 831 iteration= 39889 loss= 0.000643012230284512\n",
      "epoch= 831 iteration= 39909 loss= 0.00038049978320486844\n",
      "epoch= 831 iteration= 39929 loss= 0.00014588328485842794\n",
      "test_data MSELoss:(pred-real)/real= 0.0001532429701910587\n",
      "epoch= 832 iteration= 39937 loss= 0.0006450578803196549\n",
      "epoch= 832 iteration= 39957 loss= 0.00035837903851643205\n",
      "epoch= 832 iteration= 39977 loss= 0.0001470574934501201\n",
      "test_data MSELoss:(pred-real)/real= 0.00015449763086508028\n",
      "epoch= 833 iteration= 39985 loss= 0.0006430298089981079\n",
      "epoch= 833 iteration= 40005 loss= 0.00034207114367745817\n",
      "epoch= 833 iteration= 40025 loss= 0.0001484969980083406\n",
      "test_data MSELoss:(pred-real)/real= 0.0001553635756863514\n",
      "epoch= 834 iteration= 40033 loss= 0.0006380808772519231\n",
      "epoch= 834 iteration= 40053 loss= 0.00033371488098055124\n",
      "epoch= 834 iteration= 40073 loss= 0.00014979120169300586\n",
      "test_data MSELoss:(pred-real)/real= 0.0001557183997647371\n",
      "epoch= 835 iteration= 40081 loss= 0.0006297254003584385\n",
      "epoch= 835 iteration= 40101 loss= 0.0003332998894620687\n",
      "epoch= 835 iteration= 40121 loss= 0.00015050936781335622\n",
      "test_data MSELoss:(pred-real)/real= 0.00015555942627543118\n",
      "epoch= 836 iteration= 40129 loss= 0.0006202006479725242\n",
      "epoch= 836 iteration= 40149 loss= 0.00033955465187318623\n",
      "epoch= 836 iteration= 40169 loss= 0.00015123054618015885\n",
      "test_data MSELoss:(pred-real)/real= 0.00015490288860746658\n",
      "epoch= 837 iteration= 40177 loss= 0.0006120241596363485\n",
      "epoch= 837 iteration= 40197 loss= 0.00034910967224277556\n",
      "epoch= 837 iteration= 40217 loss= 0.0001511193986516446\n",
      "test_data MSELoss:(pred-real)/real= 0.00015385820079245606\n",
      "epoch= 838 iteration= 40225 loss= 0.0006056116544641554\n",
      "epoch= 838 iteration= 40245 loss= 0.0003596974129322916\n",
      "epoch= 838 iteration= 40265 loss= 0.0001508038694737479\n",
      "test_data MSELoss:(pred-real)/real= 0.00015275215155270417\n",
      "epoch= 839 iteration= 40273 loss= 0.0006013896781951189\n",
      "epoch= 839 iteration= 40293 loss= 0.0003691624151542783\n",
      "epoch= 839 iteration= 40313 loss= 0.00015010136121418327\n",
      "test_data MSELoss:(pred-real)/real= 0.00015160145740082952\n",
      "epoch= 840 iteration= 40321 loss= 0.0005989636993035674\n",
      "epoch= 840 iteration= 40341 loss= 0.00037519418401643634\n",
      "epoch= 840 iteration= 40361 loss= 0.00014900135283824056\n",
      "test_data MSELoss:(pred-real)/real= 0.00015058172903081868\n",
      "epoch= 841 iteration= 40369 loss= 0.0005982833681628108\n",
      "epoch= 841 iteration= 40389 loss= 0.000377861550077796\n",
      "epoch= 841 iteration= 40409 loss= 0.00014788314001634717\n",
      "test_data MSELoss:(pred-real)/real= 0.00014977417267800775\n",
      "epoch= 842 iteration= 40417 loss= 0.0005992277874611318\n",
      "epoch= 842 iteration= 40437 loss= 0.00037631954182870686\n",
      "epoch= 842 iteration= 40457 loss= 0.00014651045785285532\n",
      "test_data MSELoss:(pred-real)/real= 0.00014929180870240088\n",
      "epoch= 843 iteration= 40465 loss= 0.0005996855907142162\n",
      "epoch= 843 iteration= 40485 loss= 0.000371587579138577\n",
      "epoch= 843 iteration= 40505 loss= 0.00014513068890664726\n",
      "test_data MSELoss:(pred-real)/real= 0.0001491689239628613\n",
      "epoch= 844 iteration= 40513 loss= 0.0006008222699165344\n",
      "epoch= 844 iteration= 40533 loss= 0.00036489288322627544\n",
      "epoch= 844 iteration= 40553 loss= 0.00014378255582414567\n",
      "test_data MSELoss:(pred-real)/real= 0.00014929451608622913\n",
      "epoch= 845 iteration= 40561 loss= 0.0006016216357238591\n",
      "epoch= 845 iteration= 40581 loss= 0.0003571104316506535\n",
      "epoch= 845 iteration= 40601 loss= 0.00014274389832280576\n",
      "test_data MSELoss:(pred-real)/real= 0.00014977783466747497\n",
      "epoch= 846 iteration= 40609 loss= 0.00060144008602947\n",
      "epoch= 846 iteration= 40629 loss= 0.00034906191285699606\n",
      "epoch= 846 iteration= 40649 loss= 0.0001418020110577345\n",
      "test_data MSELoss:(pred-real)/real= 0.0001503959807450883\n",
      "epoch= 847 iteration= 40657 loss= 0.000601436011493206\n",
      "epoch= 847 iteration= 40677 loss= 0.0003418062115088105\n",
      "epoch= 847 iteration= 40697 loss= 0.00014088736497797072\n",
      "test_data MSELoss:(pred-real)/real= 0.00015110666099644733\n",
      "epoch= 848 iteration= 40705 loss= 0.0006007425836287439\n",
      "epoch= 848 iteration= 40725 loss= 0.00033574510598555207\n",
      "epoch= 848 iteration= 40745 loss= 0.00014044226554688066\n",
      "test_data MSELoss:(pred-real)/real= 0.00015179872352746315\n",
      "epoch= 849 iteration= 40753 loss= 0.000599822262302041\n",
      "epoch= 849 iteration= 40773 loss= 0.00033148907823488116\n",
      "epoch= 849 iteration= 40793 loss= 0.0001399088796461001\n",
      "test_data MSELoss:(pred-real)/real= 0.00015244416790665126\n",
      "epoch= 850 iteration= 40801 loss= 0.0005985621828585863\n",
      "epoch= 850 iteration= 40821 loss= 0.0003288252046331763\n",
      "epoch= 850 iteration= 40841 loss= 0.00013944868987891823\n",
      "test_data MSELoss:(pred-real)/real= 0.00015289816037693526\n",
      "epoch= 851 iteration= 40849 loss= 0.0005975777748972178\n",
      "epoch= 851 iteration= 40869 loss= 0.00032747775549069047\n",
      "epoch= 851 iteration= 40889 loss= 0.0001391053810948506\n",
      "test_data MSELoss:(pred-real)/real= 0.00015328308872994967\n",
      "epoch= 852 iteration= 40897 loss= 0.0005967477336525917\n",
      "epoch= 852 iteration= 40917 loss= 0.0003271544410381466\n",
      "epoch= 852 iteration= 40937 loss= 0.00013880558253731579\n",
      "test_data MSELoss:(pred-real)/real= 0.00015356815747509246\n",
      "epoch= 853 iteration= 40945 loss= 0.000595546152908355\n",
      "epoch= 853 iteration= 40965 loss= 0.0003277375944890082\n",
      "epoch= 853 iteration= 40985 loss= 0.00013841153122484684\n",
      "test_data MSELoss:(pred-real)/real= 0.00015360837714979426\n",
      "epoch= 854 iteration= 40993 loss= 0.0005950761260464787\n",
      "epoch= 854 iteration= 41013 loss= 0.00032845677924342453\n",
      "epoch= 854 iteration= 41033 loss= 0.00013831461546942592\n",
      "test_data MSELoss:(pred-real)/real= 0.00015350193971244152\n",
      "epoch= 855 iteration= 41041 loss= 0.000594387180171907\n",
      "epoch= 855 iteration= 41061 loss= 0.00032958044903352857\n",
      "epoch= 855 iteration= 41081 loss= 0.00013784915790893137\n",
      "test_data MSELoss:(pred-real)/real= 0.00015338843331846874\n",
      "epoch= 856 iteration= 41089 loss= 0.0005942108109593391\n",
      "epoch= 856 iteration= 41109 loss= 0.0003301852266304195\n",
      "epoch= 856 iteration= 41129 loss= 0.00013761487207375467\n",
      "test_data MSELoss:(pred-real)/real= 0.00015307540270441676\n",
      "epoch= 857 iteration= 41137 loss= 0.0005940094124525785\n",
      "epoch= 857 iteration= 41157 loss= 0.0003307252482045442\n",
      "epoch= 857 iteration= 41177 loss= 0.0001374201092403382\n",
      "test_data MSELoss:(pred-real)/real= 0.0001527106975117931\n",
      "epoch= 858 iteration= 41185 loss= 0.000593450153246522\n",
      "epoch= 858 iteration= 41205 loss= 0.0003307760343886912\n",
      "epoch= 858 iteration= 41225 loss= 0.00013703954755328596\n",
      "test_data MSELoss:(pred-real)/real= 0.00015240413667925168\n",
      "epoch= 859 iteration= 41233 loss= 0.0005931377527303994\n",
      "epoch= 859 iteration= 41253 loss= 0.00033054169034585357\n",
      "epoch= 859 iteration= 41273 loss= 0.00013686151942238212\n",
      "test_data MSELoss:(pred-real)/real= 0.00015204965748125688\n",
      "epoch= 860 iteration= 41281 loss= 0.000592775468248874\n",
      "epoch= 860 iteration= 41301 loss= 0.0003298352821730077\n",
      "epoch= 860 iteration= 41321 loss= 0.00013661890989169478\n",
      "test_data MSELoss:(pred-real)/real= 0.00015172778839769307\n",
      "epoch= 861 iteration= 41329 loss= 0.0005922960699535906\n",
      "epoch= 861 iteration= 41349 loss= 0.00032914106850512326\n",
      "epoch= 861 iteration= 41369 loss= 0.0001362205803161487\n",
      "test_data MSELoss:(pred-real)/real= 0.00015146636433200912\n",
      "epoch= 862 iteration= 41377 loss= 0.0005917103844694793\n",
      "epoch= 862 iteration= 41397 loss= 0.0003283013356849551\n",
      "epoch= 862 iteration= 41417 loss= 0.00013607987784780562\n",
      "test_data MSELoss:(pred-real)/real= 0.00015123618068173527\n",
      "epoch= 863 iteration= 41425 loss= 0.0005907132290303707\n",
      "epoch= 863 iteration= 41445 loss= 0.00032730825478211045\n",
      "epoch= 863 iteration= 41465 loss= 0.0001358402951154858\n",
      "test_data MSELoss:(pred-real)/real= 0.0001510607104137307\n",
      "epoch= 864 iteration= 41473 loss= 0.000589589646551758\n",
      "epoch= 864 iteration= 41493 loss= 0.00032643869053572416\n",
      "epoch= 864 iteration= 41513 loss= 0.0001354743872070685\n",
      "test_data MSELoss:(pred-real)/real= 0.00015092807661858386\n",
      "epoch= 865 iteration= 41521 loss= 0.0005888547748327255\n",
      "epoch= 865 iteration= 41541 loss= 0.0003254703478887677\n",
      "epoch= 865 iteration= 41561 loss= 0.00013549358118325472\n",
      "test_data MSELoss:(pred-real)/real= 0.00015090071537997573\n",
      "epoch= 866 iteration= 41569 loss= 0.0005882528494112194\n",
      "epoch= 866 iteration= 41589 loss= 0.0003249166766181588\n",
      "epoch= 866 iteration= 41609 loss= 0.0001351217506453395\n",
      "test_data MSELoss:(pred-real)/real= 0.0001508036169980187\n",
      "epoch= 867 iteration= 41617 loss= 0.0005870466120541096\n",
      "epoch= 867 iteration= 41637 loss= 0.0003246097476221621\n",
      "epoch= 867 iteration= 41657 loss= 0.0001349424128420651\n",
      "test_data MSELoss:(pred-real)/real= 0.00015078692413226236\n",
      "epoch= 868 iteration= 41665 loss= 0.0005860939854755998\n",
      "epoch= 868 iteration= 41685 loss= 0.00032405793899670243\n",
      "epoch= 868 iteration= 41705 loss= 0.00013486323587130755\n",
      "test_data MSELoss:(pred-real)/real= 0.00015076117997523398\n",
      "epoch= 869 iteration= 41713 loss= 0.0005851062596775591\n",
      "epoch= 869 iteration= 41733 loss= 0.00032382074277848005\n",
      "epoch= 869 iteration= 41753 loss= 0.0001345179625786841\n",
      "test_data MSELoss:(pred-real)/real= 0.00015075598421390168\n",
      "epoch= 870 iteration= 41761 loss= 0.0005842575337737799\n",
      "epoch= 870 iteration= 41781 loss= 0.00032358034513890743\n",
      "epoch= 870 iteration= 41801 loss= 0.00013437362213153392\n",
      "test_data MSELoss:(pred-real)/real= 0.00015076339441293384\n",
      "epoch= 871 iteration= 41809 loss= 0.0005830808659084141\n",
      "epoch= 871 iteration= 41829 loss= 0.00032355860457755625\n",
      "epoch= 871 iteration= 41849 loss= 0.00013416761066764593\n",
      "test_data MSELoss:(pred-real)/real= 0.00015078477626957466\n",
      "epoch= 872 iteration= 41857 loss= 0.0005824852269142866\n",
      "epoch= 872 iteration= 41877 loss= 0.00032353767892345786\n",
      "epoch= 872 iteration= 41897 loss= 0.00013381661847233772\n",
      "test_data MSELoss:(pred-real)/real= 0.00015077627322170883\n",
      "epoch= 873 iteration= 41905 loss= 0.0005817870842292905\n",
      "epoch= 873 iteration= 41925 loss= 0.00032335228752344847\n",
      "epoch= 873 iteration= 41945 loss= 0.00013362923345994204\n",
      "test_data MSELoss:(pred-real)/real= 0.00015074886141519528\n",
      "epoch= 874 iteration= 41953 loss= 0.0005813628667965531\n",
      "epoch= 874 iteration= 41973 loss= 0.00032311369432136416\n",
      "epoch= 874 iteration= 41993 loss= 0.0001334246771875769\n",
      "test_data MSELoss:(pred-real)/real= 0.000150788956307224\n",
      "epoch= 875 iteration= 42001 loss= 0.0005803717649541795\n",
      "epoch= 875 iteration= 42021 loss= 0.00032297230791300535\n",
      "epoch= 875 iteration= 42041 loss= 0.00013298717385623604\n",
      "test_data MSELoss:(pred-real)/real= 0.00015073750801093412\n",
      "epoch= 876 iteration= 42049 loss= 0.0005794052267447114\n",
      "epoch= 876 iteration= 42069 loss= 0.00032280024606734514\n",
      "epoch= 876 iteration= 42089 loss= 0.00013285560999065638\n",
      "test_data MSELoss:(pred-real)/real= 0.00015066551677591633\n",
      "epoch= 877 iteration= 42097 loss= 0.0005789119750261307\n",
      "epoch= 877 iteration= 42117 loss= 0.0003225835971534252\n",
      "epoch= 877 iteration= 42137 loss= 0.00013250533083919436\n",
      "test_data MSELoss:(pred-real)/real= 0.00015059980178193654\n",
      "epoch= 878 iteration= 42145 loss= 0.0005779437487944961\n",
      "epoch= 878 iteration= 42165 loss= 0.000322300533298403\n",
      "epoch= 878 iteration= 42185 loss= 0.0001323955220868811\n",
      "test_data MSELoss:(pred-real)/real= 0.00015057760210765992\n",
      "epoch= 879 iteration= 42193 loss= 0.0005771958967670798\n",
      "epoch= 879 iteration= 42213 loss= 0.000322073872666806\n",
      "epoch= 879 iteration= 42233 loss= 0.00013187230797484517\n",
      "test_data MSELoss:(pred-real)/real= 0.00015051884583954233\n",
      "epoch= 880 iteration= 42241 loss= 0.0005763254011981189\n",
      "epoch= 880 iteration= 42261 loss= 0.00032175122760236263\n",
      "epoch= 880 iteration= 42281 loss= 0.0001317402784479782\n",
      "test_data MSELoss:(pred-real)/real= 0.00015040674988995307\n",
      "epoch= 881 iteration= 42289 loss= 0.0005753105506300926\n",
      "epoch= 881 iteration= 42309 loss= 0.00032156810630112886\n",
      "epoch= 881 iteration= 42329 loss= 0.0001314213004661724\n",
      "test_data MSELoss:(pred-real)/real= 0.00015036585318739526\n",
      "epoch= 882 iteration= 42337 loss= 0.0005746412789449096\n",
      "epoch= 882 iteration= 42357 loss= 0.0003213408053852618\n",
      "epoch= 882 iteration= 42377 loss= 0.00013111087901052088\n",
      "test_data MSELoss:(pred-real)/real= 0.0001502816940046614\n",
      "epoch= 883 iteration= 42385 loss= 0.0005739070475101471\n",
      "epoch= 883 iteration= 42405 loss= 0.00032103111152537167\n",
      "epoch= 883 iteration= 42425 loss= 0.0001308155187871307\n",
      "test_data MSELoss:(pred-real)/real= 0.00015022512161522172\n",
      "epoch= 884 iteration= 42433 loss= 0.000573212222661823\n",
      "epoch= 884 iteration= 42453 loss= 0.0003209285205230117\n",
      "epoch= 884 iteration= 42473 loss= 0.00013044214574620128\n",
      "test_data MSELoss:(pred-real)/real= 0.00015014375167083928\n",
      "epoch= 885 iteration= 42481 loss= 0.000572147429920733\n",
      "epoch= 885 iteration= 42501 loss= 0.0003208079724572599\n",
      "epoch= 885 iteration= 42521 loss= 0.00013023795327171683\n",
      "test_data MSELoss:(pred-real)/real= 0.00015005852073954885\n",
      "epoch= 886 iteration= 42529 loss= 0.0005713975988328457\n",
      "epoch= 886 iteration= 42549 loss= 0.0003204129170626402\n",
      "epoch= 886 iteration= 42569 loss= 0.00012984791828785092\n",
      "test_data MSELoss:(pred-real)/real= 0.00015004476772446652\n",
      "epoch= 887 iteration= 42577 loss= 0.0005708703538402915\n",
      "epoch= 887 iteration= 42597 loss= 0.00032032732269726694\n",
      "epoch= 887 iteration= 42617 loss= 0.00012976315338164568\n",
      "test_data MSELoss:(pred-real)/real= 0.00014993900731496979\n",
      "epoch= 888 iteration= 42625 loss= 0.0005695867002941668\n",
      "epoch= 888 iteration= 42645 loss= 0.00031997368205338717\n",
      "epoch= 888 iteration= 42665 loss= 0.0001294194662477821\n",
      "test_data MSELoss:(pred-real)/real= 0.00014990778727224096\n",
      "epoch= 889 iteration= 42673 loss= 0.0005687691736966372\n",
      "epoch= 889 iteration= 42693 loss= 0.0003195941972080618\n",
      "epoch= 889 iteration= 42713 loss= 0.00012909482757095248\n",
      "test_data MSELoss:(pred-real)/real= 0.00014982858519942965\n",
      "epoch= 890 iteration= 42721 loss= 0.0005677675362676382\n",
      "epoch= 890 iteration= 42741 loss= 0.0003194333694409579\n",
      "epoch= 890 iteration= 42761 loss= 0.0001287504710489884\n",
      "test_data MSELoss:(pred-real)/real= 0.00014974657533457504\n",
      "epoch= 891 iteration= 42769 loss= 0.0005670491373166442\n",
      "epoch= 891 iteration= 42789 loss= 0.000319089915137738\n",
      "epoch= 891 iteration= 42809 loss= 0.0001285929756704718\n",
      "test_data MSELoss:(pred-real)/real= 0.0001497026391007239\n",
      "epoch= 892 iteration= 42817 loss= 0.0005662129842676222\n",
      "epoch= 892 iteration= 42837 loss= 0.00031899919849820435\n",
      "epoch= 892 iteration= 42857 loss= 0.0001280398719245568\n",
      "test_data MSELoss:(pred-real)/real= 0.00014961096312617883\n",
      "epoch= 893 iteration= 42865 loss= 0.0005652678664773703\n",
      "epoch= 893 iteration= 42885 loss= 0.00031858845613896847\n",
      "epoch= 893 iteration= 42905 loss= 0.00012771738693118095\n",
      "test_data MSELoss:(pred-real)/real= 0.0001495241987868212\n",
      "epoch= 894 iteration= 42913 loss= 0.000564337067771703\n",
      "epoch= 894 iteration= 42933 loss= 0.00031853083055466413\n",
      "epoch= 894 iteration= 42953 loss= 0.00012737757060676813\n",
      "test_data MSELoss:(pred-real)/real= 0.00014945225702831522\n",
      "epoch= 895 iteration= 42961 loss= 0.0005636076093651354\n",
      "epoch= 895 iteration= 42981 loss= 0.00031834375113248825\n",
      "epoch= 895 iteration= 43001 loss= 0.00012715053162537515\n",
      "test_data MSELoss:(pred-real)/real= 0.00014938580789021217\n",
      "epoch= 896 iteration= 43009 loss= 0.0005629583611153066\n",
      "epoch= 896 iteration= 43029 loss= 0.00031815501279197633\n",
      "epoch= 896 iteration= 43049 loss= 0.00012676736514549702\n",
      "test_data MSELoss:(pred-real)/real= 0.00014933667662262451\n",
      "epoch= 897 iteration= 43057 loss= 0.0005620996234938502\n",
      "epoch= 897 iteration= 43077 loss= 0.0003177194157615304\n",
      "epoch= 897 iteration= 43097 loss= 0.00012638058979064226\n",
      "test_data MSELoss:(pred-real)/real= 0.00014928273485566025\n",
      "epoch= 898 iteration= 43105 loss= 0.000561491004191339\n",
      "epoch= 898 iteration= 43125 loss= 0.0003174820449203253\n",
      "epoch= 898 iteration= 43145 loss= 0.00012606498785316944\n",
      "test_data MSELoss:(pred-real)/real= 0.0001492280571255833\n",
      "epoch= 899 iteration= 43153 loss= 0.0005605132319033146\n",
      "epoch= 899 iteration= 43173 loss= 0.0003173598670400679\n",
      "epoch= 899 iteration= 43193 loss= 0.00012572815467137843\n",
      "test_data MSELoss:(pred-real)/real= 0.00014917081607563888\n",
      "epoch= 900 iteration= 43201 loss= 0.0005597646231763065\n",
      "epoch= 900 iteration= 43221 loss= 0.00031685055000707507\n",
      "epoch= 900 iteration= 43241 loss= 0.0001254116796189919\n",
      "test_data MSELoss:(pred-real)/real= 0.00014914461607986595\n",
      "epoch= 901 iteration= 43249 loss= 0.0005590243963524699\n",
      "epoch= 901 iteration= 43269 loss= 0.0003162870998494327\n",
      "epoch= 901 iteration= 43289 loss= 0.00012513194815255702\n",
      "test_data MSELoss:(pred-real)/real= 0.00014908252269378862\n",
      "epoch= 902 iteration= 43297 loss= 0.0005577874253503978\n",
      "epoch= 902 iteration= 43317 loss= 0.00031616457272320986\n",
      "epoch= 902 iteration= 43337 loss= 0.00012473243987187743\n",
      "test_data MSELoss:(pred-real)/real= 0.00014904152558301576\n",
      "epoch= 903 iteration= 43345 loss= 0.0005574107053689659\n",
      "epoch= 903 iteration= 43365 loss= 0.00031533799483440816\n",
      "epoch= 903 iteration= 43385 loss= 0.00012439177953638136\n",
      "test_data MSELoss:(pred-real)/real= 0.00014901931790518576\n",
      "epoch= 904 iteration= 43393 loss= 0.0005564324092119932\n",
      "epoch= 904 iteration= 43413 loss= 0.00031506308005191386\n",
      "epoch= 904 iteration= 43433 loss= 0.00012398921535350382\n",
      "test_data MSELoss:(pred-real)/real= 0.00014895315216563177\n",
      "epoch= 905 iteration= 43441 loss= 0.0005555906100198627\n",
      "epoch= 905 iteration= 43461 loss= 0.0003144601359963417\n",
      "epoch= 905 iteration= 43481 loss= 0.00012387277092784643\n",
      "test_data MSELoss:(pred-real)/real= 0.0001489120757469209\n",
      "epoch= 906 iteration= 43489 loss= 0.0005548297194764018\n",
      "epoch= 906 iteration= 43509 loss= 0.0003138377796858549\n",
      "epoch= 906 iteration= 43529 loss= 0.000123617282952182\n",
      "test_data MSELoss:(pred-real)/real= 0.00014891628343320916\n",
      "epoch= 907 iteration= 43537 loss= 0.0005533107905648649\n",
      "epoch= 907 iteration= 43557 loss= 0.0003133892605546862\n",
      "epoch= 907 iteration= 43577 loss= 0.0001232223876286298\n",
      "test_data MSELoss:(pred-real)/real= 0.0001488241192419082\n",
      "epoch= 908 iteration= 43585 loss= 0.0005526408785954118\n",
      "epoch= 908 iteration= 43605 loss= 0.0003129878605250269\n",
      "epoch= 908 iteration= 43625 loss= 0.00012300678645260632\n",
      "test_data MSELoss:(pred-real)/real= 0.00014880139169690665\n",
      "epoch= 909 iteration= 43633 loss= 0.0005516334786079824\n",
      "epoch= 909 iteration= 43653 loss= 0.00031235243659466505\n",
      "epoch= 909 iteration= 43673 loss= 0.00012264862016309053\n",
      "test_data MSELoss:(pred-real)/real= 0.0001487343655753648\n",
      "epoch= 910 iteration= 43681 loss= 0.0005509232869371772\n",
      "epoch= 910 iteration= 43701 loss= 0.00031211323221214116\n",
      "epoch= 910 iteration= 43721 loss= 0.00012225477257743478\n",
      "test_data MSELoss:(pred-real)/real= 0.00014872617284709123\n",
      "epoch= 911 iteration= 43729 loss= 0.0005498980754055083\n",
      "epoch= 911 iteration= 43749 loss= 0.0003117327287327498\n",
      "epoch= 911 iteration= 43769 loss= 0.00012206236715428531\n",
      "test_data MSELoss:(pred-real)/real= 0.00014865607336105312\n",
      "epoch= 912 iteration= 43777 loss= 0.0005487629678100348\n",
      "epoch= 912 iteration= 43797 loss= 0.0003113583370577544\n",
      "epoch= 912 iteration= 43817 loss= 0.00012170683476142585\n",
      "test_data MSELoss:(pred-real)/real= 0.0001485915418015793\n",
      "epoch= 913 iteration= 43825 loss= 0.0005479812971316278\n",
      "epoch= 913 iteration= 43845 loss= 0.0003111956757493317\n",
      "epoch= 913 iteration= 43865 loss= 0.0001212567585753277\n",
      "test_data MSELoss:(pred-real)/real= 0.00014854680994176307\n",
      "epoch= 914 iteration= 43873 loss= 0.0005471149925142527\n",
      "epoch= 914 iteration= 43893 loss= 0.0003107115044258535\n",
      "epoch= 914 iteration= 43913 loss= 0.00012094007979612797\n",
      "test_data MSELoss:(pred-real)/real= 0.00014849571416561958\n",
      "epoch= 915 iteration= 43921 loss= 0.0005455765640363097\n",
      "epoch= 915 iteration= 43941 loss= 0.00031026179203763604\n",
      "epoch= 915 iteration= 43961 loss= 0.00012064706243108958\n",
      "test_data MSELoss:(pred-real)/real= 0.000148464167068596\n",
      "epoch= 916 iteration= 43969 loss= 0.0005445098504424095\n",
      "epoch= 916 iteration= 43989 loss= 0.0003101181937381625\n",
      "epoch= 916 iteration= 44009 loss= 0.00012018583947792649\n",
      "test_data MSELoss:(pred-real)/real= 0.00014838807401247324\n",
      "epoch= 917 iteration= 44017 loss= 0.0005440698587335646\n",
      "epoch= 917 iteration= 44037 loss= 0.0003098818997386843\n",
      "epoch= 917 iteration= 44057 loss= 0.00011997198453173041\n",
      "test_data MSELoss:(pred-real)/real= 0.0001483435527916299\n",
      "epoch= 918 iteration= 44065 loss= 0.000543663336429745\n",
      "epoch= 918 iteration= 44085 loss= 0.00030987907666713\n",
      "epoch= 918 iteration= 44105 loss= 0.00011957067908952013\n",
      "test_data MSELoss:(pred-real)/real= 0.00014828576458967291\n",
      "epoch= 919 iteration= 44113 loss= 0.000542354304343462\n",
      "epoch= 919 iteration= 44133 loss= 0.0003094174899160862\n",
      "epoch= 919 iteration= 44153 loss= 0.00011915147479157895\n",
      "test_data MSELoss:(pred-real)/real= 0.00014819573916611262\n",
      "epoch= 920 iteration= 44161 loss= 0.0005413781618699431\n",
      "epoch= 920 iteration= 44181 loss= 0.0003091525286436081\n",
      "epoch= 920 iteration= 44201 loss= 0.00011875570635311306\n",
      "test_data MSELoss:(pred-real)/real= 0.00014815927388553974\n",
      "epoch= 921 iteration= 44209 loss= 0.0005409394507296383\n",
      "epoch= 921 iteration= 44229 loss= 0.00030899839475750923\n",
      "epoch= 921 iteration= 44249 loss= 0.0001185194996651262\n",
      "test_data MSELoss:(pred-real)/real= 0.00014814160167588852\n",
      "epoch= 922 iteration= 44257 loss= 0.0005406992277130485\n",
      "epoch= 922 iteration= 44277 loss= 0.00030872461502440274\n",
      "epoch= 922 iteration= 44297 loss= 0.0001181204424938187\n",
      "test_data MSELoss:(pred-real)/real= 0.00014810853026574476\n",
      "epoch= 923 iteration= 44305 loss= 0.0005398442735895514\n",
      "epoch= 923 iteration= 44325 loss= 0.00030813668854534626\n",
      "epoch= 923 iteration= 44345 loss= 0.00011779501801356673\n",
      "test_data MSELoss:(pred-real)/real= 0.00014812380686635152\n",
      "epoch= 924 iteration= 44353 loss= 0.0005393492756411433\n",
      "epoch= 924 iteration= 44373 loss= 0.0003075709391850978\n",
      "epoch= 924 iteration= 44393 loss= 0.0001175418437924236\n",
      "test_data MSELoss:(pred-real)/real= 0.0001481011673604371\n",
      "epoch= 925 iteration= 44401 loss= 0.0005385138792917132\n",
      "epoch= 925 iteration= 44421 loss= 0.0003067831275984645\n",
      "epoch= 925 iteration= 44441 loss= 0.00011715087748598307\n",
      "test_data MSELoss:(pred-real)/real= 0.00014812430381425657\n",
      "epoch= 926 iteration= 44449 loss= 0.0005380456568673253\n",
      "epoch= 926 iteration= 44469 loss= 0.0003059356822632253\n",
      "epoch= 926 iteration= 44489 loss= 0.00011694664863171056\n",
      "test_data MSELoss:(pred-real)/real= 0.0001481388222600799\n",
      "epoch= 927 iteration= 44497 loss= 0.0005371863953769207\n",
      "epoch= 927 iteration= 44517 loss= 0.00030522653833031654\n",
      "epoch= 927 iteration= 44537 loss= 0.00011686128709698096\n",
      "test_data MSELoss:(pred-real)/real= 0.00014821280565229243\n",
      "epoch= 928 iteration= 44545 loss= 0.0005368303973227739\n",
      "epoch= 928 iteration= 44565 loss= 0.00030454699299298227\n",
      "epoch= 928 iteration= 44585 loss= 0.00011655925482045859\n",
      "test_data MSELoss:(pred-real)/real= 0.00014828916573605966\n",
      "epoch= 929 iteration= 44593 loss= 0.0005350230494514108\n",
      "epoch= 929 iteration= 44613 loss= 0.0003036877897102386\n",
      "epoch= 929 iteration= 44633 loss= 0.00011667353101074696\n",
      "test_data MSELoss:(pred-real)/real= 0.0001483979805925628\n",
      "epoch= 930 iteration= 44641 loss= 0.0005342255462892354\n",
      "epoch= 930 iteration= 44661 loss= 0.0003034119145013392\n",
      "epoch= 930 iteration= 44681 loss= 0.00011645344784483314\n",
      "test_data MSELoss:(pred-real)/real= 0.00014851793021080083\n",
      "epoch= 931 iteration= 44689 loss= 0.0005333186709322035\n",
      "epoch= 931 iteration= 44709 loss= 0.00030337547650560737\n",
      "epoch= 931 iteration= 44729 loss= 0.00011649061343632638\n",
      "test_data MSELoss:(pred-real)/real= 0.0001485285054513952\n",
      "epoch= 932 iteration= 44737 loss= 0.0005322156939655542\n",
      "epoch= 932 iteration= 44757 loss= 0.00030289156711660326\n",
      "epoch= 932 iteration= 44777 loss= 0.0001164001296274364\n",
      "test_data MSELoss:(pred-real)/real= 0.0001485930395574542\n",
      "epoch= 933 iteration= 44785 loss= 0.0005323943914845586\n",
      "epoch= 933 iteration= 44805 loss= 0.00030299677746370435\n",
      "epoch= 933 iteration= 44825 loss= 0.00011662353063002229\n",
      "test_data MSELoss:(pred-real)/real= 0.0001485903725551907\n",
      "epoch= 934 iteration= 44833 loss= 0.0005333655863068998\n",
      "epoch= 934 iteration= 44853 loss= 0.00030220882035791874\n",
      "epoch= 934 iteration= 44873 loss= 0.00011618360440479591\n",
      "test_data MSELoss:(pred-real)/real= 0.00014848213832010514\n",
      "epoch= 935 iteration= 44881 loss= 0.0005344751989468932\n",
      "epoch= 935 iteration= 44901 loss= 0.0003015870170202106\n",
      "epoch= 935 iteration= 44921 loss= 0.00011599608114920557\n",
      "test_data MSELoss:(pred-real)/real= 0.00014832513152214234\n",
      "epoch= 936 iteration= 44929 loss= 0.0005351071013137698\n",
      "epoch= 936 iteration= 44949 loss= 0.00030012568458914757\n",
      "epoch= 936 iteration= 44969 loss= 0.00011579686542972922\n",
      "test_data MSELoss:(pred-real)/real= 0.00014819474672549403\n",
      "epoch= 937 iteration= 44977 loss= 0.0005347690312191844\n",
      "epoch= 937 iteration= 44997 loss= 0.0002991106011904776\n",
      "epoch= 937 iteration= 45017 loss= 0.00011527155584190041\n",
      "test_data MSELoss:(pred-real)/real= 0.0001480248240113724\n",
      "epoch= 938 iteration= 45025 loss= 0.0005329276900738478\n",
      "epoch= 938 iteration= 45045 loss= 0.00029869936406612396\n",
      "epoch= 938 iteration= 45065 loss= 0.00011484025890240446\n",
      "test_data MSELoss:(pred-real)/real= 0.00014779770754103083\n",
      "epoch= 939 iteration= 45073 loss= 0.0005298119504004717\n",
      "epoch= 939 iteration= 45093 loss= 0.00029984815046191216\n",
      "epoch= 939 iteration= 45113 loss= 0.00011434633779572323\n",
      "test_data MSELoss:(pred-real)/real= 0.00014758089528186247\n",
      "epoch= 940 iteration= 45121 loss= 0.0005257247248664498\n",
      "epoch= 940 iteration= 45141 loss= 0.00030276988400146365\n",
      "epoch= 940 iteration= 45161 loss= 0.00011379284842405468\n",
      "test_data MSELoss:(pred-real)/real= 0.00014727726338605862\n",
      "epoch= 941 iteration= 45169 loss= 0.0005217590951360762\n",
      "epoch= 941 iteration= 45189 loss= 0.0003076177672483027\n",
      "epoch= 941 iteration= 45209 loss= 0.0001132999750552699\n",
      "test_data MSELoss:(pred-real)/real= 0.00014704936329508201\n",
      "epoch= 942 iteration= 45217 loss= 0.0005190264200791717\n",
      "epoch= 942 iteration= 45237 loss= 0.00031469319947063923\n",
      "epoch= 942 iteration= 45257 loss= 0.0001127423020079732\n",
      "test_data MSELoss:(pred-real)/real= 0.00014678211373393425\n",
      "epoch= 943 iteration= 45265 loss= 0.0005182244349271059\n",
      "epoch= 943 iteration= 45285 loss= 0.0003236626507714391\n",
      "epoch= 943 iteration= 45305 loss= 0.00011203953908989206\n",
      "test_data MSELoss:(pred-real)/real= 0.0001465460856707068\n",
      "epoch= 944 iteration= 45313 loss= 0.0005201887106522918\n",
      "epoch= 944 iteration= 45333 loss= 0.0003342261188663542\n",
      "epoch= 944 iteration= 45353 loss= 0.00011182099115103483\n",
      "test_data MSELoss:(pred-real)/real= 0.00014644492330262437\n",
      "epoch= 945 iteration= 45361 loss= 0.0005254849093034863\n",
      "epoch= 945 iteration= 45381 loss= 0.0003445458132773638\n",
      "epoch= 945 iteration= 45401 loss= 0.00011181252193637192\n",
      "test_data MSELoss:(pred-real)/real= 0.00014665924172732047\n",
      "epoch= 946 iteration= 45409 loss= 0.0005323226796463132\n",
      "epoch= 946 iteration= 45429 loss= 0.00035072147147729993\n",
      "epoch= 946 iteration= 45449 loss= 0.00011217178689548746\n",
      "test_data MSELoss:(pred-real)/real= 0.00014749023794138338\n",
      "epoch= 947 iteration= 45457 loss= 0.0005394569598138332\n",
      "epoch= 947 iteration= 45477 loss= 0.0003481007879599929\n",
      "epoch= 947 iteration= 45497 loss= 0.00011276647273916751\n",
      "test_data MSELoss:(pred-real)/real= 0.0001488274625444319\n",
      "epoch= 948 iteration= 45505 loss= 0.0005393828614614904\n",
      "epoch= 948 iteration= 45525 loss= 0.00033523712772876024\n",
      "epoch= 948 iteration= 45545 loss= 0.00011322913633193821\n",
      "test_data MSELoss:(pred-real)/real= 0.00014946865230740513\n",
      "epoch= 949 iteration= 45553 loss= 0.0005301099736243486\n",
      "epoch= 949 iteration= 45573 loss= 0.0003192850563209504\n",
      "epoch= 949 iteration= 45593 loss= 0.00011320660269120708\n",
      "test_data MSELoss:(pred-real)/real= 0.00014857712558296042\n",
      "epoch= 950 iteration= 45601 loss= 0.000518123502843082\n",
      "epoch= 950 iteration= 45621 loss= 0.0003084001364186406\n",
      "epoch= 950 iteration= 45641 loss= 0.00011264658678555861\n",
      "test_data MSELoss:(pred-real)/real= 0.00014707577392982784\n",
      "epoch= 951 iteration= 45649 loss= 0.0005097027169540524\n",
      "epoch= 951 iteration= 45669 loss= 0.0003034997789654881\n",
      "epoch= 951 iteration= 45689 loss= 0.00011182512389495969\n",
      "test_data MSELoss:(pred-real)/real= 0.00014599712812923826\n",
      "epoch= 952 iteration= 45697 loss= 0.0005071352934464812\n",
      "epoch= 952 iteration= 45717 loss= 0.0003031336236745119\n",
      "epoch= 952 iteration= 45737 loss= 0.00011112545325886458\n",
      "test_data MSELoss:(pred-real)/real= 0.00014538369650836104\n",
      "epoch= 953 iteration= 45745 loss= 0.0005066116573289037\n",
      "epoch= 953 iteration= 45765 loss= 0.00030615937430411577\n",
      "epoch= 953 iteration= 45785 loss= 0.00011051594628952444\n",
      "test_data MSELoss:(pred-real)/real= 0.000145086225529667\n",
      "epoch= 954 iteration= 45793 loss= 0.0005051984917372465\n",
      "epoch= 954 iteration= 45813 loss= 0.0003123423084616661\n",
      "epoch= 954 iteration= 45833 loss= 0.00011017004726454616\n",
      "test_data MSELoss:(pred-real)/real= 0.00014493205853796098\n",
      "epoch= 955 iteration= 45841 loss= 0.0005019651725888252\n",
      "epoch= 955 iteration= 45861 loss= 0.000322992040310055\n",
      "epoch= 955 iteration= 45881 loss= 0.00010977312922477722\n",
      "test_data MSELoss:(pred-real)/real= 0.00014480439385806677\n",
      "epoch= 956 iteration= 45889 loss= 0.0004990437300875783\n",
      "epoch= 956 iteration= 45909 loss= 0.0003360341361258179\n",
      "epoch= 956 iteration= 45929 loss= 0.00010949917486868799\n",
      "test_data MSELoss:(pred-real)/real= 0.00014477501790679525\n",
      "epoch= 957 iteration= 45937 loss= 0.000497882254421711\n",
      "epoch= 957 iteration= 45957 loss= 0.0003510981914587319\n",
      "epoch= 957 iteration= 45977 loss= 0.0001092928578145802\n",
      "test_data MSELoss:(pred-real)/real= 0.00014463701299973763\n",
      "epoch= 958 iteration= 45985 loss= 0.0005013151094317436\n",
      "epoch= 958 iteration= 46005 loss= 0.0003630879509728402\n",
      "epoch= 958 iteration= 46025 loss= 0.00010903847578447312\n",
      "test_data MSELoss:(pred-real)/real= 0.0001445686251827283\n",
      "epoch= 959 iteration= 46033 loss= 0.0005083705764263868\n",
      "epoch= 959 iteration= 46053 loss= 0.00036577691207639873\n",
      "epoch= 959 iteration= 46073 loss= 0.00010889983241213486\n",
      "test_data MSELoss:(pred-real)/real= 0.0001446703387046\n",
      "epoch= 960 iteration= 46081 loss= 0.0005138003616593778\n",
      "epoch= 960 iteration= 46101 loss= 0.0003568048996385187\n",
      "epoch= 960 iteration= 46121 loss= 0.00010846537770703435\n",
      "test_data MSELoss:(pred-real)/real= 0.00014517220115521922\n",
      "epoch= 961 iteration= 46129 loss= 0.000512967468239367\n",
      "epoch= 961 iteration= 46149 loss= 0.00033942260779440403\n",
      "epoch= 961 iteration= 46169 loss= 0.00010764383478090167\n",
      "test_data MSELoss:(pred-real)/real= 0.0001464150656829588\n",
      "epoch= 962 iteration= 46177 loss= 0.0005070890765637159\n",
      "epoch= 962 iteration= 46197 loss= 0.00032174107036553323\n",
      "epoch= 962 iteration= 46217 loss= 0.00010692553769331425\n",
      "test_data MSELoss:(pred-real)/real= 0.00014864762488286942\n",
      "epoch= 963 iteration= 46225 loss= 0.0004991656169295311\n",
      "epoch= 963 iteration= 46245 loss= 0.00030827545560896397\n",
      "epoch= 963 iteration= 46265 loss= 0.0001061620278051123\n",
      "test_data MSELoss:(pred-real)/real= 0.00015167389319685752\n",
      "epoch= 964 iteration= 46273 loss= 0.0004945349646732211\n",
      "epoch= 964 iteration= 46293 loss= 0.0002997724513988942\n",
      "epoch= 964 iteration= 46313 loss= 0.00010576657950878143\n",
      "test_data MSELoss:(pred-real)/real= 0.00015479343928745948\n",
      "epoch= 965 iteration= 46321 loss= 0.0004923741798847914\n",
      "epoch= 965 iteration= 46341 loss= 0.0002945318119600415\n",
      "epoch= 965 iteration= 46361 loss= 0.00010547881538514048\n",
      "test_data MSELoss:(pred-real)/real= 0.00015767199729452842\n",
      "epoch= 966 iteration= 46369 loss= 0.0004911941359750926\n",
      "epoch= 966 iteration= 46389 loss= 0.00029105960857123137\n",
      "epoch= 966 iteration= 46409 loss= 0.00010536153422435746\n",
      "test_data MSELoss:(pred-real)/real= 0.000159992396220332\n",
      "epoch= 967 iteration= 46417 loss= 0.0004913079901598394\n",
      "epoch= 967 iteration= 46437 loss= 0.00028870831010863185\n",
      "epoch= 967 iteration= 46457 loss= 0.00010512721928535029\n",
      "test_data MSELoss:(pred-real)/real= 0.00016140768420882523\n",
      "epoch= 968 iteration= 46465 loss= 0.0004920355277135968\n",
      "epoch= 968 iteration= 46485 loss= 0.00028800059226341546\n",
      "epoch= 968 iteration= 46505 loss= 0.0001052417210303247\n",
      "test_data MSELoss:(pred-real)/real= 0.00016228680142376105\n",
      "epoch= 969 iteration= 46513 loss= 0.0004928682465106249\n",
      "epoch= 969 iteration= 46533 loss= 0.0002901759871747345\n",
      "epoch= 969 iteration= 46553 loss= 0.00010552324238233268\n",
      "test_data MSELoss:(pred-real)/real= 0.00016306892284774223\n",
      "epoch= 970 iteration= 46561 loss= 0.000495038169901818\n",
      "epoch= 970 iteration= 46581 loss= 0.00029634524253197014\n",
      "epoch= 970 iteration= 46601 loss= 0.00010592355101834983\n",
      "test_data MSELoss:(pred-real)/real= 0.0001637500485230703\n",
      "epoch= 971 iteration= 46609 loss= 0.0004980789381079376\n",
      "epoch= 971 iteration= 46629 loss= 0.0003065320779569447\n",
      "epoch= 971 iteration= 46649 loss= 0.00010626696894178167\n",
      "test_data MSELoss:(pred-real)/real= 0.00016390437740483322\n",
      "epoch= 972 iteration= 46657 loss= 0.0005020902026444674\n",
      "epoch= 972 iteration= 46677 loss= 0.00031931884586811066\n",
      "epoch= 972 iteration= 46697 loss= 0.00010677868704078719\n",
      "test_data MSELoss:(pred-real)/real= 0.0001631253253435716\n",
      "epoch= 973 iteration= 46705 loss= 0.0005067687015980482\n",
      "epoch= 973 iteration= 46725 loss= 0.0003337255329824984\n",
      "epoch= 973 iteration= 46745 loss= 0.00010694412048906088\n",
      "test_data MSELoss:(pred-real)/real= 0.0001610039093066007\n",
      "epoch= 974 iteration= 46753 loss= 0.0005120019777677953\n",
      "epoch= 974 iteration= 46773 loss= 0.00034744080039672554\n",
      "epoch= 974 iteration= 46793 loss= 0.00010683688014978543\n",
      "test_data MSELoss:(pred-real)/real= 0.0001580772761371918\n",
      "epoch= 975 iteration= 46801 loss= 0.0005176098784431815\n",
      "epoch= 975 iteration= 46821 loss= 0.00035800307523459196\n",
      "epoch= 975 iteration= 46841 loss= 0.00010655715595930815\n",
      "test_data MSELoss:(pred-real)/real= 0.00015455687680514528\n",
      "epoch= 976 iteration= 46849 loss= 0.0005236875731498003\n",
      "epoch= 976 iteration= 46869 loss= 0.00036318483762443066\n",
      "epoch= 976 iteration= 46889 loss= 0.00010583590483292937\n",
      "test_data MSELoss:(pred-real)/real= 0.00015120551142899785\n",
      "epoch= 977 iteration= 46897 loss= 0.0005304012447595596\n",
      "epoch= 977 iteration= 46917 loss= 0.000360924459528178\n",
      "epoch= 977 iteration= 46937 loss= 0.00010524440585868433\n",
      "test_data MSELoss:(pred-real)/real= 0.00014884700503898786\n",
      "epoch= 978 iteration= 46945 loss= 0.0005359206697903574\n",
      "epoch= 978 iteration= 46965 loss= 0.0003486280038487166\n",
      "epoch= 978 iteration= 46985 loss= 0.00010496993490960449\n",
      "test_data MSELoss:(pred-real)/real= 0.0001478714151744498\n",
      "epoch= 979 iteration= 46993 loss= 0.0005392018938437104\n",
      "epoch= 979 iteration= 47013 loss= 0.00032976322108879685\n",
      "epoch= 979 iteration= 47033 loss= 0.0001054604072123766\n",
      "test_data MSELoss:(pred-real)/real= 0.00014843896751699505\n",
      "epoch= 980 iteration= 47041 loss= 0.0005363470409065485\n",
      "epoch= 980 iteration= 47061 loss= 0.00030891981441527605\n",
      "epoch= 980 iteration= 47081 loss= 0.00010667679453035817\n",
      "test_data MSELoss:(pred-real)/real= 0.00015002264044596813\n",
      "epoch= 981 iteration= 47089 loss= 0.0005293638678267598\n",
      "epoch= 981 iteration= 47109 loss= 0.0002922210842370987\n",
      "epoch= 981 iteration= 47129 loss= 0.00010809372179210186\n",
      "test_data MSELoss:(pred-real)/real= 0.00015181807102635503\n",
      "epoch= 982 iteration= 47137 loss= 0.0005181306041777134\n",
      "epoch= 982 iteration= 47157 loss= 0.0002829954610206187\n",
      "epoch= 982 iteration= 47177 loss= 0.00010989922884618863\n",
      "test_data MSELoss:(pred-real)/real= 0.00015310041308111977\n",
      "epoch= 983 iteration= 47185 loss= 0.0005057252128608525\n",
      "epoch= 983 iteration= 47205 loss= 0.00028299560653977096\n",
      "epoch= 983 iteration= 47225 loss= 0.00011090196494478732\n",
      "test_data MSELoss:(pred-real)/real= 0.00015361621663032566\n",
      "epoch= 984 iteration= 47233 loss= 0.0004942445084452629\n",
      "epoch= 984 iteration= 47253 loss= 0.00029213025118224323\n",
      "epoch= 984 iteration= 47273 loss= 0.00011147059558425099\n",
      "test_data MSELoss:(pred-real)/real= 0.0001532266294816509\n",
      "epoch= 985 iteration= 47281 loss= 0.00048593126120977104\n",
      "epoch= 985 iteration= 47301 loss= 0.0003078489098697901\n",
      "epoch= 985 iteration= 47321 loss= 0.00011166198237333447\n",
      "test_data MSELoss:(pred-real)/real= 0.00015228803167701698\n",
      "epoch= 986 iteration= 47329 loss= 0.0004820676986128092\n",
      "epoch= 986 iteration= 47349 loss= 0.00032495451159775257\n",
      "epoch= 986 iteration= 47369 loss= 0.00011108537728432566\n",
      "test_data MSELoss:(pred-real)/real= 0.00015043196035549044\n",
      "epoch= 987 iteration= 47377 loss= 0.0004824092029593885\n",
      "epoch= 987 iteration= 47397 loss= 0.00034035459975712\n",
      "epoch= 987 iteration= 47417 loss= 0.00011025815911125392\n",
      "test_data MSELoss:(pred-real)/real= 0.00014843204407952726\n",
      "epoch= 988 iteration= 47425 loss= 0.0004849287506658584\n",
      "epoch= 988 iteration= 47445 loss= 0.00034991221036762\n",
      "epoch= 988 iteration= 47465 loss= 0.00010831306281033903\n",
      "test_data MSELoss:(pred-real)/real= 0.00014628469907620456\n",
      "epoch= 989 iteration= 47473 loss= 0.0004891419084742665\n",
      "epoch= 989 iteration= 47493 loss= 0.00035135640064254403\n",
      "epoch= 989 iteration= 47513 loss= 0.00010626774746924639\n",
      "test_data MSELoss:(pred-real)/real= 0.00014473904557235073\n",
      "epoch= 990 iteration= 47521 loss= 0.0004922999069094658\n",
      "epoch= 990 iteration= 47541 loss= 0.0003451333031989634\n",
      "epoch= 990 iteration= 47561 loss= 0.0001042536023305729\n",
      "test_data MSELoss:(pred-real)/real= 0.00014404438297788147\n",
      "epoch= 991 iteration= 47569 loss= 0.0004939347272738814\n",
      "epoch= 991 iteration= 47589 loss= 0.0003325261641293764\n",
      "epoch= 991 iteration= 47609 loss= 0.00010252714855596423\n",
      "test_data MSELoss:(pred-real)/real= 0.00014437904283113313\n",
      "epoch= 992 iteration= 47617 loss= 0.000493676750920713\n",
      "epoch= 992 iteration= 47637 loss= 0.0003175711608491838\n",
      "epoch= 992 iteration= 47657 loss= 0.00010127591667696834\n",
      "test_data MSELoss:(pred-real)/real= 0.00014547715290973428\n",
      "epoch= 993 iteration= 47665 loss= 0.000490188249386847\n",
      "epoch= 993 iteration= 47685 loss= 0.0003021617594640702\n",
      "epoch= 993 iteration= 47705 loss= 0.00010051388380816206\n",
      "test_data MSELoss:(pred-real)/real= 0.00014700725078000687\n",
      "epoch= 994 iteration= 47713 loss= 0.00048637407599017024\n",
      "epoch= 994 iteration= 47733 loss= 0.00028928439132869244\n",
      "epoch= 994 iteration= 47753 loss= 0.0001000974589260295\n",
      "test_data MSELoss:(pred-real)/real= 0.0001485404143750202\n",
      "epoch= 995 iteration= 47761 loss= 0.00048144871834665537\n",
      "epoch= 995 iteration= 47781 loss= 0.00028072865097783506\n",
      "epoch= 995 iteration= 47801 loss= 9.99698750092648e-05\n",
      "test_data MSELoss:(pred-real)/real= 0.00014993749900895636\n",
      "epoch= 996 iteration= 47809 loss= 0.00047709138016216457\n",
      "epoch= 996 iteration= 47829 loss= 0.00027668793336488307\n",
      "epoch= 996 iteration= 47849 loss= 9.990494436351582e-05\n",
      "test_data MSELoss:(pred-real)/real= 0.00015087988722370938\n",
      "epoch= 997 iteration= 47857 loss= 0.0004752310924232006\n",
      "epoch= 997 iteration= 47877 loss= 0.0002761951764114201\n",
      "epoch= 997 iteration= 47897 loss= 9.988123929360881e-05\n",
      "test_data MSELoss:(pred-real)/real= 0.00015148261372814885\n",
      "epoch= 998 iteration= 47905 loss= 0.00047440873458981514\n",
      "epoch= 998 iteration= 47925 loss= 0.00027884228620678186\n",
      "epoch= 998 iteration= 47945 loss= 9.980845788959414e-05\n",
      "test_data MSELoss:(pred-real)/real= 0.0001515645933977794\n",
      "epoch= 999 iteration= 47953 loss= 0.00047532704775221646\n",
      "epoch= 999 iteration= 47973 loss= 0.0002827512798830867\n",
      "epoch= 999 iteration= 47993 loss= 9.951945685315877e-05\n",
      "test_data MSELoss:(pred-real)/real= 0.00015115461719688027\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "if __name__==\"__main__\":   \n",
    "    period = 100\n",
    "    iteration=0\n",
    "    loss_list=[]\n",
    "    #开始训练神经网络\n",
    "    for epoch in range(1000):         \n",
    "        predict_list=[]\n",
    "        accuracy_list=[]\n",
    "        train(epoch)\n",
    "        test()\n",
    "    #绘制损失函数下降曲线    \n",
    "    loss_curve(loss_list)\n",
    "    #绘制测试集pred-real对比曲线\n",
    "    contrast_lines(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7714800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
